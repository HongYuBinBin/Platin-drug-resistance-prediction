{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils \n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('./Platin_Data/Semi_Final/common_patient.csv', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLATINUM_STATUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1331</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1332</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1362</th>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1364</th>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2110</th>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2111</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2113</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PLATINUM_STATUS\n",
       "PATIENT_ID                  \n",
       "TCGA-04-1331       Sensitive\n",
       "TCGA-04-1332       Sensitive\n",
       "TCGA-04-1347       Sensitive\n",
       "TCGA-04-1362       Resistant\n",
       "TCGA-04-1364       Resistant\n",
       "...                      ...\n",
       "TCGA-61-2098       Sensitive\n",
       "TCGA-61-2109       Sensitive\n",
       "TCGA-61-2110       Resistant\n",
       "TCGA-61-2111       Sensitive\n",
       "TCGA-61-2113       Sensitive\n",
       "\n",
       "[210 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.loc[df_label['PLATINUM_STATUS'] == 'Sensitive', 'label'] = 0\n",
    "df_label.loc[df_label['PLATINUM_STATUS'] == 'Resistant', 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLATINUM_STATUS</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1331</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1332</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1362</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1364</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2110</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2111</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2113</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PLATINUM_STATUS  label\n",
       "PATIENT_ID                         \n",
       "TCGA-04-1331       Sensitive    0.0\n",
       "TCGA-04-1332       Sensitive    0.0\n",
       "TCGA-04-1347       Sensitive    0.0\n",
       "TCGA-04-1362       Resistant    1.0\n",
       "TCGA-04-1364       Resistant    1.0\n",
       "...                      ...    ...\n",
       "TCGA-61-2098       Sensitive    0.0\n",
       "TCGA-61-2109       Sensitive    0.0\n",
       "TCGA-61-2110       Resistant    1.0\n",
       "TCGA-61-2111       Sensitive    0.0\n",
       "TCGA-61-2113       Sensitive    0.0\n",
       "\n",
       "[210 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('./Platin_Data/Semi_Final/PC_tpm_250_log.csv', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-04-1331</th>\n",
       "      <th>TCGA-04-1332</th>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <th>TCGA-04-1362</th>\n",
       "      <th>TCGA-04-1364</th>\n",
       "      <th>TCGA-04-1365</th>\n",
       "      <th>TCGA-04-1514</th>\n",
       "      <th>TCGA-04-1530</th>\n",
       "      <th>TCGA-04-1536</th>\n",
       "      <th>TCGA-04-1542</th>\n",
       "      <th>...</th>\n",
       "      <th>TCGA-61-2000</th>\n",
       "      <th>TCGA-61-2008</th>\n",
       "      <th>TCGA-61-2009</th>\n",
       "      <th>TCGA-61-2092</th>\n",
       "      <th>TCGA-61-2097</th>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <th>TCGA-61-2110</th>\n",
       "      <th>TCGA-61-2111</th>\n",
       "      <th>TCGA-61-2113</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000131096</th>\n",
       "      <td>-6.366282</td>\n",
       "      <td>-4.488628</td>\n",
       "      <td>-7.601309</td>\n",
       "      <td>-4.173178</td>\n",
       "      <td>-2.754576</td>\n",
       "      <td>-6.551323</td>\n",
       "      <td>-3.519839</td>\n",
       "      <td>4.837497</td>\n",
       "      <td>-4.235542</td>\n",
       "      <td>-4.968484</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.525348</td>\n",
       "      <td>-6.816355</td>\n",
       "      <td>-6.354592</td>\n",
       "      <td>-5.572676</td>\n",
       "      <td>-4.620647</td>\n",
       "      <td>-3.424341</td>\n",
       "      <td>-6.197002</td>\n",
       "      <td>-6.249893</td>\n",
       "      <td>2.055320</td>\n",
       "      <td>-6.890379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187581</th>\n",
       "      <td>-0.442050</td>\n",
       "      <td>-3.216314</td>\n",
       "      <td>-3.024444</td>\n",
       "      <td>-1.696708</td>\n",
       "      <td>6.288751</td>\n",
       "      <td>-0.008033</td>\n",
       "      <td>1.893721</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.684334</td>\n",
       "      <td>0.541251</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.135552</td>\n",
       "      <td>-1.936841</td>\n",
       "      <td>4.180240</td>\n",
       "      <td>-1.913023</td>\n",
       "      <td>-1.649955</td>\n",
       "      <td>5.523327</td>\n",
       "      <td>0.155893</td>\n",
       "      <td>-1.092131</td>\n",
       "      <td>4.107675</td>\n",
       "      <td>-0.801170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000047936</th>\n",
       "      <td>0.566665</td>\n",
       "      <td>-2.666762</td>\n",
       "      <td>-8.117399</td>\n",
       "      <td>-4.539869</td>\n",
       "      <td>-8.817501</td>\n",
       "      <td>-0.929409</td>\n",
       "      <td>-7.235335</td>\n",
       "      <td>-3.298323</td>\n",
       "      <td>-8.099063</td>\n",
       "      <td>-6.139259</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.248044</td>\n",
       "      <td>-7.028077</td>\n",
       "      <td>-5.286896</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.774663</td>\n",
       "      <td>-3.943922</td>\n",
       "      <td>-4.107782</td>\n",
       "      <td>-7.348430</td>\n",
       "      <td>-8.332655</td>\n",
       "      <td>-7.245962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000186198</th>\n",
       "      <td>-2.268812</td>\n",
       "      <td>-1.536532</td>\n",
       "      <td>-2.476620</td>\n",
       "      <td>-3.195451</td>\n",
       "      <td>0.696030</td>\n",
       "      <td>-1.582880</td>\n",
       "      <td>-1.970906</td>\n",
       "      <td>-2.797395</td>\n",
       "      <td>-4.170106</td>\n",
       "      <td>-2.897393</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.671383</td>\n",
       "      <td>-2.043819</td>\n",
       "      <td>-2.117368</td>\n",
       "      <td>-2.359486</td>\n",
       "      <td>-2.096747</td>\n",
       "      <td>-1.316318</td>\n",
       "      <td>-1.873511</td>\n",
       "      <td>-5.601148</td>\n",
       "      <td>-1.699904</td>\n",
       "      <td>-2.786461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000179914</th>\n",
       "      <td>-3.569415</td>\n",
       "      <td>2.119767</td>\n",
       "      <td>-4.083801</td>\n",
       "      <td>-5.261526</td>\n",
       "      <td>-5.056427</td>\n",
       "      <td>-3.801708</td>\n",
       "      <td>-2.079691</td>\n",
       "      <td>-3.225063</td>\n",
       "      <td>-0.174631</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.079852</td>\n",
       "      <td>-2.590863</td>\n",
       "      <td>-2.664269</td>\n",
       "      <td>-6.267381</td>\n",
       "      <td>-1.360455</td>\n",
       "      <td>-1.269543</td>\n",
       "      <td>1.355935</td>\n",
       "      <td>1.190012</td>\n",
       "      <td>-1.504873</td>\n",
       "      <td>-5.427190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000203859</th>\n",
       "      <td>-2.559716</td>\n",
       "      <td>-2.424260</td>\n",
       "      <td>-5.743966</td>\n",
       "      <td>-3.790421</td>\n",
       "      <td>-0.057156</td>\n",
       "      <td>-5.137312</td>\n",
       "      <td>-2.676033</td>\n",
       "      <td>-4.527592</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.219806</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.387894</td>\n",
       "      <td>-1.101986</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.376231</td>\n",
       "      <td>1.592210</td>\n",
       "      <td>3.395194</td>\n",
       "      <td>-2.303537</td>\n",
       "      <td>-3.861291</td>\n",
       "      <td>-3.788814</td>\n",
       "      <td>-4.773279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000164270</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.681085</td>\n",
       "      <td>-9.569261</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.511735</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.773356</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.563134</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.821315</td>\n",
       "      <td>-9.422141</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.398801</td>\n",
       "      <td>-9.205281</td>\n",
       "      <td>-9.252905</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000185823</th>\n",
       "      <td>-0.891385</td>\n",
       "      <td>-2.015031</td>\n",
       "      <td>-2.334598</td>\n",
       "      <td>-4.369244</td>\n",
       "      <td>-6.382877</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.802130</td>\n",
       "      <td>-0.124686</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.058232</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.631388</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.175109</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>-0.308931</td>\n",
       "      <td>-3.306644</td>\n",
       "      <td>-3.128442</td>\n",
       "      <td>0.756916</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000142789</th>\n",
       "      <td>-6.136564</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.044777</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.479767</td>\n",
       "      <td>-5.732535</td>\n",
       "      <td>-5.504813</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.772654</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.552707</td>\n",
       "      <td>-5.572844</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.207623</td>\n",
       "      <td>-6.669049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000183715</th>\n",
       "      <td>-9.791117</td>\n",
       "      <td>-8.039971</td>\n",
       "      <td>-9.876247</td>\n",
       "      <td>-9.790471</td>\n",
       "      <td>-9.673470</td>\n",
       "      <td>-8.769101</td>\n",
       "      <td>-9.845798</td>\n",
       "      <td>-9.579352</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.741288</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.568124</td>\n",
       "      <td>-9.101848</td>\n",
       "      <td>-6.873064</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.228188</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.510953</td>\n",
       "      <td>-8.363088</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.634738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TCGA-04-1331  TCGA-04-1332  TCGA-04-1347  TCGA-04-1362  \\\n",
       "ID                                                                        \n",
       "ENSG00000131096     -6.366282     -4.488628     -7.601309     -4.173178   \n",
       "ENSG00000187581     -0.442050     -3.216314     -3.024444     -1.696708   \n",
       "ENSG00000047936      0.566665     -2.666762     -8.117399     -4.539869   \n",
       "ENSG00000186198     -2.268812     -1.536532     -2.476620     -3.195451   \n",
       "ENSG00000179914     -3.569415      2.119767     -4.083801     -5.261526   \n",
       "...                       ...           ...           ...           ...   \n",
       "ENSG00000203859     -2.559716     -2.424260     -5.743966     -3.790421   \n",
       "ENSG00000164270     -9.965784     -7.681085     -9.569261     -9.965784   \n",
       "ENSG00000185823     -0.891385     -2.015031     -2.334598     -4.369244   \n",
       "ENSG00000142789     -6.136564     -9.965784     -7.044777     -9.965784   \n",
       "ENSG00000183715     -9.791117     -8.039971     -9.876247     -9.790471   \n",
       "\n",
       "                 TCGA-04-1364  TCGA-04-1365  TCGA-04-1514  TCGA-04-1530  \\\n",
       "ID                                                                        \n",
       "ENSG00000131096     -2.754576     -6.551323     -3.519839      4.837497   \n",
       "ENSG00000187581      6.288751     -0.008033      1.893721     -9.965784   \n",
       "ENSG00000047936     -8.817501     -0.929409     -7.235335     -3.298323   \n",
       "ENSG00000186198      0.696030     -1.582880     -1.970906     -2.797395   \n",
       "ENSG00000179914     -5.056427     -3.801708     -2.079691     -3.225063   \n",
       "...                       ...           ...           ...           ...   \n",
       "ENSG00000203859     -0.057156     -5.137312     -2.676033     -4.527592   \n",
       "ENSG00000164270     -9.511735     -9.965784     -8.773356     -9.965784   \n",
       "ENSG00000185823     -6.382877     -9.965784     -0.802130     -0.124686   \n",
       "ENSG00000142789     -9.965784     -6.479767     -5.732535     -5.504813   \n",
       "ENSG00000183715     -9.673470     -8.769101     -9.845798     -9.579352   \n",
       "\n",
       "                 TCGA-04-1536  TCGA-04-1542  ...  TCGA-61-2000  TCGA-61-2008  \\\n",
       "ID                                           ...                               \n",
       "ENSG00000131096     -4.235542     -4.968484  ...     -8.525348     -6.816355   \n",
       "ENSG00000187581     -1.684334      0.541251  ...     -2.135552     -1.936841   \n",
       "ENSG00000047936     -8.099063     -6.139259  ...     -9.248044     -7.028077   \n",
       "ENSG00000186198     -4.170106     -2.897393  ...     -3.671383     -2.043819   \n",
       "ENSG00000179914     -0.174631     -9.965784  ...     -1.079852     -2.590863   \n",
       "...                       ...           ...  ...           ...           ...   \n",
       "ENSG00000203859     -9.965784     -4.219806  ...     -6.387894     -1.101986   \n",
       "ENSG00000164270     -9.563134     -9.965784  ...     -9.965784     -9.965784   \n",
       "ENSG00000185823     -9.965784     -6.058232  ...     -9.965784     -2.631388   \n",
       "ENSG00000142789     -9.965784     -9.965784  ...     -6.772654     -9.965784   \n",
       "ENSG00000183715     -9.965784     -8.741288  ...     -9.568124     -9.101848   \n",
       "\n",
       "                 TCGA-61-2009  TCGA-61-2092  TCGA-61-2097  TCGA-61-2098  \\\n",
       "ID                                                                        \n",
       "ENSG00000131096     -6.354592     -5.572676     -4.620647     -3.424341   \n",
       "ENSG00000187581      4.180240     -1.913023     -1.649955      5.523327   \n",
       "ENSG00000047936     -5.286896     -9.965784     -6.774663     -3.943922   \n",
       "ENSG00000186198     -2.117368     -2.359486     -2.096747     -1.316318   \n",
       "ENSG00000179914     -2.664269     -6.267381     -1.360455     -1.269543   \n",
       "...                       ...           ...           ...           ...   \n",
       "ENSG00000203859     -9.965784     -2.376231      1.592210      3.395194   \n",
       "ENSG00000164270     -7.821315     -9.422141     -9.965784     -9.965784   \n",
       "ENSG00000185823     -9.965784     -4.175109      0.006519     -0.308931   \n",
       "ENSG00000142789     -9.965784     -9.965784     -9.965784     -3.552707   \n",
       "ENSG00000183715     -6.873064     -9.965784     -9.228188     -9.965784   \n",
       "\n",
       "                 TCGA-61-2109  TCGA-61-2110  TCGA-61-2111  TCGA-61-2113  \n",
       "ID                                                                       \n",
       "ENSG00000131096     -6.197002     -6.249893      2.055320     -6.890379  \n",
       "ENSG00000187581      0.155893     -1.092131      4.107675     -0.801170  \n",
       "ENSG00000047936     -4.107782     -7.348430     -8.332655     -7.245962  \n",
       "ENSG00000186198     -1.873511     -5.601148     -1.699904     -2.786461  \n",
       "ENSG00000179914      1.355935      1.190012     -1.504873     -5.427190  \n",
       "...                       ...           ...           ...           ...  \n",
       "ENSG00000203859     -2.303537     -3.861291     -3.788814     -4.773279  \n",
       "ENSG00000164270     -9.398801     -9.205281     -9.252905     -9.965784  \n",
       "ENSG00000185823     -3.306644     -3.128442      0.756916     -9.965784  \n",
       "ENSG00000142789     -5.572844     -9.965784     -4.207623     -6.669049  \n",
       "ENSG00000183715     -7.510953     -8.363088     -9.965784     -9.634738  \n",
       "\n",
       "[250 rows x 210 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_mod = df_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>ENSG00000131096</th>\n",
       "      <th>ENSG00000187581</th>\n",
       "      <th>ENSG00000047936</th>\n",
       "      <th>ENSG00000186198</th>\n",
       "      <th>ENSG00000179914</th>\n",
       "      <th>ENSG00000186897</th>\n",
       "      <th>ENSG00000138136</th>\n",
       "      <th>ENSG00000139219</th>\n",
       "      <th>ENSG00000136944</th>\n",
       "      <th>ENSG00000182870</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000077327</th>\n",
       "      <th>ENSG00000196131</th>\n",
       "      <th>ENSG00000136110</th>\n",
       "      <th>ENSG00000171053</th>\n",
       "      <th>ENSG00000150361</th>\n",
       "      <th>ENSG00000203859</th>\n",
       "      <th>ENSG00000164270</th>\n",
       "      <th>ENSG00000185823</th>\n",
       "      <th>ENSG00000142789</th>\n",
       "      <th>ENSG00000183715</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1331</th>\n",
       "      <td>-6.366282</td>\n",
       "      <td>-0.442050</td>\n",
       "      <td>0.566665</td>\n",
       "      <td>-2.268812</td>\n",
       "      <td>-3.569415</td>\n",
       "      <td>1.882780</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.441449</td>\n",
       "      <td>-0.677656</td>\n",
       "      <td>-5.400592</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.053987</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.816989</td>\n",
       "      <td>-3.622838</td>\n",
       "      <td>-7.966778</td>\n",
       "      <td>-2.559716</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.891385</td>\n",
       "      <td>-6.136564</td>\n",
       "      <td>-9.791117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1332</th>\n",
       "      <td>-4.488628</td>\n",
       "      <td>-3.216314</td>\n",
       "      <td>-2.666762</td>\n",
       "      <td>-1.536532</td>\n",
       "      <td>2.119767</td>\n",
       "      <td>1.832807</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.130959</td>\n",
       "      <td>1.164030</td>\n",
       "      <td>-4.032188</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.210435</td>\n",
       "      <td>-4.783838</td>\n",
       "      <td>-5.536844</td>\n",
       "      <td>-2.511355</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.424260</td>\n",
       "      <td>-7.681085</td>\n",
       "      <td>-2.015031</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.039971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <td>-7.601309</td>\n",
       "      <td>-3.024444</td>\n",
       "      <td>-8.117399</td>\n",
       "      <td>-2.476620</td>\n",
       "      <td>-4.083801</td>\n",
       "      <td>5.096513</td>\n",
       "      <td>-5.581598</td>\n",
       "      <td>-3.766292</td>\n",
       "      <td>-8.563616</td>\n",
       "      <td>-8.580961</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.072122</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.441578</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.198811</td>\n",
       "      <td>-5.743966</td>\n",
       "      <td>-9.569261</td>\n",
       "      <td>-2.334598</td>\n",
       "      <td>-7.044777</td>\n",
       "      <td>-9.876247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1362</th>\n",
       "      <td>-4.173178</td>\n",
       "      <td>-1.696708</td>\n",
       "      <td>-4.539869</td>\n",
       "      <td>-3.195451</td>\n",
       "      <td>-5.261526</td>\n",
       "      <td>-1.795652</td>\n",
       "      <td>-4.030746</td>\n",
       "      <td>0.032396</td>\n",
       "      <td>-2.371091</td>\n",
       "      <td>-5.497429</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.027688</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.392890</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.790421</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.369244</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.790471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1364</th>\n",
       "      <td>-2.754576</td>\n",
       "      <td>6.288751</td>\n",
       "      <td>-8.817501</td>\n",
       "      <td>0.696030</td>\n",
       "      <td>-5.056427</td>\n",
       "      <td>4.264846</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.344290</td>\n",
       "      <td>-6.559042</td>\n",
       "      <td>-6.982357</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.762673</td>\n",
       "      <td>-1.494008</td>\n",
       "      <td>-3.203281</td>\n",
       "      <td>-5.361784</td>\n",
       "      <td>-9.696609</td>\n",
       "      <td>-0.057156</td>\n",
       "      <td>-9.511735</td>\n",
       "      <td>-6.382877</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.673470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <td>-3.424341</td>\n",
       "      <td>5.523327</td>\n",
       "      <td>-3.943922</td>\n",
       "      <td>-1.316318</td>\n",
       "      <td>-1.269543</td>\n",
       "      <td>2.324090</td>\n",
       "      <td>-1.967411</td>\n",
       "      <td>6.121391</td>\n",
       "      <td>-0.534620</td>\n",
       "      <td>-5.726127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048487</td>\n",
       "      <td>-3.669741</td>\n",
       "      <td>-2.927971</td>\n",
       "      <td>-2.475176</td>\n",
       "      <td>-9.040579</td>\n",
       "      <td>3.395194</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.308931</td>\n",
       "      <td>-3.552707</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <td>-6.197002</td>\n",
       "      <td>0.155893</td>\n",
       "      <td>-4.107782</td>\n",
       "      <td>-1.873511</td>\n",
       "      <td>1.355935</td>\n",
       "      <td>3.306055</td>\n",
       "      <td>-4.999621</td>\n",
       "      <td>-0.662207</td>\n",
       "      <td>-4.365621</td>\n",
       "      <td>-4.251542</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.964987</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.516037</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.624395</td>\n",
       "      <td>-2.303537</td>\n",
       "      <td>-9.398801</td>\n",
       "      <td>-3.306644</td>\n",
       "      <td>-5.572844</td>\n",
       "      <td>-7.510953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2110</th>\n",
       "      <td>-6.249893</td>\n",
       "      <td>-1.092131</td>\n",
       "      <td>-7.348430</td>\n",
       "      <td>-5.601148</td>\n",
       "      <td>1.190012</td>\n",
       "      <td>-3.328315</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.209943</td>\n",
       "      <td>-2.838656</td>\n",
       "      <td>-0.623255</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.311607</td>\n",
       "      <td>-3.907536</td>\n",
       "      <td>-9.495995</td>\n",
       "      <td>-3.861291</td>\n",
       "      <td>-9.205281</td>\n",
       "      <td>-3.128442</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.363088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2111</th>\n",
       "      <td>2.055320</td>\n",
       "      <td>4.107675</td>\n",
       "      <td>-8.332655</td>\n",
       "      <td>-1.699904</td>\n",
       "      <td>-1.504873</td>\n",
       "      <td>-1.043990</td>\n",
       "      <td>1.917116</td>\n",
       "      <td>-2.633256</td>\n",
       "      <td>-5.097214</td>\n",
       "      <td>-5.531636</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.773895</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.528129</td>\n",
       "      <td>-3.788814</td>\n",
       "      <td>-9.252905</td>\n",
       "      <td>0.756916</td>\n",
       "      <td>-4.207623</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2113</th>\n",
       "      <td>-6.890379</td>\n",
       "      <td>-0.801170</td>\n",
       "      <td>-7.245962</td>\n",
       "      <td>-2.786461</td>\n",
       "      <td>-5.427190</td>\n",
       "      <td>2.910769</td>\n",
       "      <td>-1.899883</td>\n",
       "      <td>-2.266447</td>\n",
       "      <td>-4.828494</td>\n",
       "      <td>-5.889639</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.046230</td>\n",
       "      <td>-3.192148</td>\n",
       "      <td>-8.106484</td>\n",
       "      <td>-5.169895</td>\n",
       "      <td>-7.785237</td>\n",
       "      <td>-4.773279</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.669049</td>\n",
       "      <td>-9.634738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID            ENSG00000131096  ENSG00000187581  ENSG00000047936  \\\n",
       "TCGA-04-1331        -6.366282        -0.442050         0.566665   \n",
       "TCGA-04-1332        -4.488628        -3.216314        -2.666762   \n",
       "TCGA-04-1347        -7.601309        -3.024444        -8.117399   \n",
       "TCGA-04-1362        -4.173178        -1.696708        -4.539869   \n",
       "TCGA-04-1364        -2.754576         6.288751        -8.817501   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-61-2098        -3.424341         5.523327        -3.943922   \n",
       "TCGA-61-2109        -6.197002         0.155893        -4.107782   \n",
       "TCGA-61-2110        -6.249893        -1.092131        -7.348430   \n",
       "TCGA-61-2111         2.055320         4.107675        -8.332655   \n",
       "TCGA-61-2113        -6.890379        -0.801170        -7.245962   \n",
       "\n",
       "ID            ENSG00000186198  ENSG00000179914  ENSG00000186897  \\\n",
       "TCGA-04-1331        -2.268812        -3.569415         1.882780   \n",
       "TCGA-04-1332        -1.536532         2.119767         1.832807   \n",
       "TCGA-04-1347        -2.476620        -4.083801         5.096513   \n",
       "TCGA-04-1362        -3.195451        -5.261526        -1.795652   \n",
       "TCGA-04-1364         0.696030        -5.056427         4.264846   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-61-2098        -1.316318        -1.269543         2.324090   \n",
       "TCGA-61-2109        -1.873511         1.355935         3.306055   \n",
       "TCGA-61-2110        -5.601148         1.190012        -3.328315   \n",
       "TCGA-61-2111        -1.699904        -1.504873        -1.043990   \n",
       "TCGA-61-2113        -2.786461        -5.427190         2.910769   \n",
       "\n",
       "ID            ENSG00000138136  ENSG00000139219  ENSG00000136944  \\\n",
       "TCGA-04-1331        -9.965784        -0.441449        -0.677656   \n",
       "TCGA-04-1332        -9.965784        -1.130959         1.164030   \n",
       "TCGA-04-1347        -5.581598        -3.766292        -8.563616   \n",
       "TCGA-04-1362        -4.030746         0.032396        -2.371091   \n",
       "TCGA-04-1364        -9.965784        -0.344290        -6.559042   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-61-2098        -1.967411         6.121391        -0.534620   \n",
       "TCGA-61-2109        -4.999621        -0.662207        -4.365621   \n",
       "TCGA-61-2110        -9.965784         0.209943        -2.838656   \n",
       "TCGA-61-2111         1.917116        -2.633256        -5.097214   \n",
       "TCGA-61-2113        -1.899883        -2.266447        -4.828494   \n",
       "\n",
       "ID            ENSG00000182870  ...  ENSG00000077327  ENSG00000196131  \\\n",
       "TCGA-04-1331        -5.400592  ...        -1.053987        -9.965784   \n",
       "TCGA-04-1332        -4.032188  ...        -7.210435        -4.783838   \n",
       "TCGA-04-1347        -8.580961  ...        -2.072122        -9.965784   \n",
       "TCGA-04-1362        -5.497429  ...        -2.027688        -9.965784   \n",
       "TCGA-04-1364        -6.982357  ...        -0.762673        -1.494008   \n",
       "...                       ...  ...              ...              ...   \n",
       "TCGA-61-2098        -5.726127  ...         0.048487        -3.669741   \n",
       "TCGA-61-2109        -4.251542  ...        -8.964987        -9.965784   \n",
       "TCGA-61-2110        -0.623255  ...        -9.965784        -9.965784   \n",
       "TCGA-61-2111        -5.531636  ...        -5.773895        -9.965784   \n",
       "TCGA-61-2113        -5.889639  ...        -6.046230        -3.192148   \n",
       "\n",
       "ID            ENSG00000136110  ENSG00000171053  ENSG00000150361  \\\n",
       "TCGA-04-1331        -6.816989        -3.622838        -7.966778   \n",
       "TCGA-04-1332        -5.536844        -2.511355        -9.965784   \n",
       "TCGA-04-1347        -4.441578        -9.965784        -9.198811   \n",
       "TCGA-04-1362        -8.392890        -9.965784        -9.965784   \n",
       "TCGA-04-1364        -3.203281        -5.361784        -9.696609   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-61-2098        -2.927971        -2.475176        -9.040579   \n",
       "TCGA-61-2109        -5.516037        -9.965784        -9.624395   \n",
       "TCGA-61-2110        -8.311607        -3.907536        -9.495995   \n",
       "TCGA-61-2111        -9.965784        -9.965784        -9.528129   \n",
       "TCGA-61-2113        -8.106484        -5.169895        -7.785237   \n",
       "\n",
       "ID            ENSG00000203859  ENSG00000164270  ENSG00000185823  \\\n",
       "TCGA-04-1331        -2.559716        -9.965784        -0.891385   \n",
       "TCGA-04-1332        -2.424260        -7.681085        -2.015031   \n",
       "TCGA-04-1347        -5.743966        -9.569261        -2.334598   \n",
       "TCGA-04-1362        -3.790421        -9.965784        -4.369244   \n",
       "TCGA-04-1364        -0.057156        -9.511735        -6.382877   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-61-2098         3.395194        -9.965784        -0.308931   \n",
       "TCGA-61-2109        -2.303537        -9.398801        -3.306644   \n",
       "TCGA-61-2110        -3.861291        -9.205281        -3.128442   \n",
       "TCGA-61-2111        -3.788814        -9.252905         0.756916   \n",
       "TCGA-61-2113        -4.773279        -9.965784        -9.965784   \n",
       "\n",
       "ID            ENSG00000142789  ENSG00000183715  \n",
       "TCGA-04-1331        -6.136564        -9.791117  \n",
       "TCGA-04-1332        -9.965784        -8.039971  \n",
       "TCGA-04-1347        -7.044777        -9.876247  \n",
       "TCGA-04-1362        -9.965784        -9.790471  \n",
       "TCGA-04-1364        -9.965784        -9.673470  \n",
       "...                       ...              ...  \n",
       "TCGA-61-2098        -3.552707        -9.965784  \n",
       "TCGA-61-2109        -5.572844        -7.510953  \n",
       "TCGA-61-2110        -9.965784        -8.363088  \n",
       "TCGA-61-2111        -4.207623        -9.965784  \n",
       "TCGA-61-2113        -6.669049        -9.634738  \n",
       "\n",
       "[210 rows x 250 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_label_mi = pd.read_csv('./Platin_Data/miRNA_patient.csv', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_mi = pd.read_csv('./Platin_Data/Semi_Final/MIR_rpm_100_log.csv', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_mi = df_data_mi.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_lnc = pd.read_csv('./Platin_Data/Semi_Final/LNC_tpm_50_log.csv', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-04-1331</th>\n",
       "      <th>TCGA-04-1332</th>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <th>TCGA-04-1362</th>\n",
       "      <th>TCGA-04-1364</th>\n",
       "      <th>TCGA-04-1365</th>\n",
       "      <th>TCGA-04-1514</th>\n",
       "      <th>TCGA-04-1530</th>\n",
       "      <th>TCGA-04-1536</th>\n",
       "      <th>TCGA-04-1542</th>\n",
       "      <th>...</th>\n",
       "      <th>TCGA-61-2000</th>\n",
       "      <th>TCGA-61-2008</th>\n",
       "      <th>TCGA-61-2009</th>\n",
       "      <th>TCGA-61-2092</th>\n",
       "      <th>TCGA-61-2097</th>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <th>TCGA-61-2110</th>\n",
       "      <th>TCGA-61-2111</th>\n",
       "      <th>TCGA-61-2113</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000233048</th>\n",
       "      <td>-7.207620</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.797716</td>\n",
       "      <td>-8.781751</td>\n",
       "      <td>-8.888570</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.813903</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.850686</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.098053</td>\n",
       "      <td>-7.110620</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.035556</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000083622</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.786606</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.722537</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.115396</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.869315</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.850643</td>\n",
       "      <td>-7.259768</td>\n",
       "      <td>-4.471057</td>\n",
       "      <td>-5.553862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000269994</th>\n",
       "      <td>-8.325863</td>\n",
       "      <td>-5.686705</td>\n",
       "      <td>-6.729526</td>\n",
       "      <td>-6.184552</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.051607</td>\n",
       "      <td>-8.020065</td>\n",
       "      <td>-5.808990</td>\n",
       "      <td>-7.563521</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.907724</td>\n",
       "      <td>-7.967025</td>\n",
       "      <td>-8.022048</td>\n",
       "      <td>-7.949062</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.406115</td>\n",
       "      <td>-6.557792</td>\n",
       "      <td>-6.609472</td>\n",
       "      <td>-1.229587</td>\n",
       "      <td>-6.343955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000258752</th>\n",
       "      <td>-0.500069</td>\n",
       "      <td>-3.869310</td>\n",
       "      <td>-6.173850</td>\n",
       "      <td>-5.772887</td>\n",
       "      <td>0.101508</td>\n",
       "      <td>-5.179247</td>\n",
       "      <td>0.664458</td>\n",
       "      <td>-3.996567</td>\n",
       "      <td>-6.684953</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.024313</td>\n",
       "      <td>-5.766190</td>\n",
       "      <td>-1.121523</td>\n",
       "      <td>-5.421963</td>\n",
       "      <td>-0.779119</td>\n",
       "      <td>-7.055175</td>\n",
       "      <td>-4.529617</td>\n",
       "      <td>-5.771347</td>\n",
       "      <td>-5.380351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000249790</th>\n",
       "      <td>-6.567569</td>\n",
       "      <td>-3.572952</td>\n",
       "      <td>-4.681104</td>\n",
       "      <td>-6.562452</td>\n",
       "      <td>-4.460856</td>\n",
       "      <td>-5.989466</td>\n",
       "      <td>-3.936696</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.378901</td>\n",
       "      <td>-5.157279</td>\n",
       "      <td>-3.679993</td>\n",
       "      <td>-3.843015</td>\n",
       "      <td>-2.160467</td>\n",
       "      <td>-2.891021</td>\n",
       "      <td>-6.016198</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.265393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000261399</th>\n",
       "      <td>0.844999</td>\n",
       "      <td>1.141537</td>\n",
       "      <td>2.071746</td>\n",
       "      <td>-2.230827</td>\n",
       "      <td>0.435589</td>\n",
       "      <td>2.165586</td>\n",
       "      <td>1.579985</td>\n",
       "      <td>2.181894</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.930124</td>\n",
       "      <td>-0.417775</td>\n",
       "      <td>-1.810424</td>\n",
       "      <td>1.675046</td>\n",
       "      <td>-0.282066</td>\n",
       "      <td>-1.887774</td>\n",
       "      <td>3.213477</td>\n",
       "      <td>0.054455</td>\n",
       "      <td>1.224064</td>\n",
       "      <td>0.345725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000232721</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.077274</td>\n",
       "      <td>-5.519466</td>\n",
       "      <td>-1.248935</td>\n",
       "      <td>-0.604508</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.173711</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.544945</td>\n",
       "      <td>-4.964940</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.222931</td>\n",
       "      <td>-0.827823</td>\n",
       "      <td>-0.395389</td>\n",
       "      <td>1.116185</td>\n",
       "      <td>0.495997</td>\n",
       "      <td>-3.626908</td>\n",
       "      <td>-2.969993</td>\n",
       "      <td>-3.119024</td>\n",
       "      <td>-2.243889</td>\n",
       "      <td>-4.136419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000243479</th>\n",
       "      <td>-6.179796</td>\n",
       "      <td>-5.425791</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.028888</td>\n",
       "      <td>-5.976203</td>\n",
       "      <td>-6.522107</td>\n",
       "      <td>-4.816674</td>\n",
       "      <td>-4.583403</td>\n",
       "      <td>-2.676088</td>\n",
       "      <td>-3.121561</td>\n",
       "      <td>...</td>\n",
       "      <td>1.380614</td>\n",
       "      <td>-2.776810</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>2.101699</td>\n",
       "      <td>3.953488</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.223574</td>\n",
       "      <td>-5.111212</td>\n",
       "      <td>-0.471729</td>\n",
       "      <td>-3.051074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000248554</th>\n",
       "      <td>-1.826764</td>\n",
       "      <td>-2.248224</td>\n",
       "      <td>-3.752458</td>\n",
       "      <td>-3.118508</td>\n",
       "      <td>-1.830784</td>\n",
       "      <td>0.104746</td>\n",
       "      <td>-1.397632</td>\n",
       "      <td>-2.843421</td>\n",
       "      <td>-4.012739</td>\n",
       "      <td>-2.558986</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.102304</td>\n",
       "      <td>-4.370490</td>\n",
       "      <td>-3.776527</td>\n",
       "      <td>-2.880645</td>\n",
       "      <td>-2.670585</td>\n",
       "      <td>-0.317675</td>\n",
       "      <td>-0.868077</td>\n",
       "      <td>-3.620514</td>\n",
       "      <td>-0.892318</td>\n",
       "      <td>-1.756998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000250432</th>\n",
       "      <td>-4.418532</td>\n",
       "      <td>-2.366232</td>\n",
       "      <td>-3.285301</td>\n",
       "      <td>-1.978935</td>\n",
       "      <td>-2.480781</td>\n",
       "      <td>-3.622465</td>\n",
       "      <td>-5.338202</td>\n",
       "      <td>-3.464192</td>\n",
       "      <td>-6.213497</td>\n",
       "      <td>-3.395735</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.897508</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.350046</td>\n",
       "      <td>-4.205433</td>\n",
       "      <td>-7.489817</td>\n",
       "      <td>-2.981221</td>\n",
       "      <td>-3.079868</td>\n",
       "      <td>-3.873170</td>\n",
       "      <td>-5.491503</td>\n",
       "      <td>-6.586462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000226956</th>\n",
       "      <td>1.340473</td>\n",
       "      <td>5.072901</td>\n",
       "      <td>-1.364075</td>\n",
       "      <td>1.943173</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.856281</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.273797</td>\n",
       "      <td>0.828268</td>\n",
       "      <td>-2.368795</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.634267</td>\n",
       "      <td>-1.192495</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.562468</td>\n",
       "      <td>-3.578021</td>\n",
       "      <td>7.672012</td>\n",
       "      <td>8.009448</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000228058</th>\n",
       "      <td>-5.973825</td>\n",
       "      <td>-2.261350</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.151719</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.320159</td>\n",
       "      <td>-4.028322</td>\n",
       "      <td>-5.337950</td>\n",
       "      <td>-0.587804</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.314316</td>\n",
       "      <td>-4.030956</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.674450</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.873291</td>\n",
       "      <td>-5.855043</td>\n",
       "      <td>-5.012842</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000226203</th>\n",
       "      <td>-5.879200</td>\n",
       "      <td>-4.399784</td>\n",
       "      <td>-3.542034</td>\n",
       "      <td>-6.417148</td>\n",
       "      <td>-3.729100</td>\n",
       "      <td>-6.227202</td>\n",
       "      <td>-3.108728</td>\n",
       "      <td>-6.720901</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.642390</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.434400</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.781994</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.858527</td>\n",
       "      <td>-5.309722</td>\n",
       "      <td>-1.272037</td>\n",
       "      <td>-6.415658</td>\n",
       "      <td>-4.515408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000233705</th>\n",
       "      <td>-4.751401</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.719932</td>\n",
       "      <td>-6.255447</td>\n",
       "      <td>-6.964881</td>\n",
       "      <td>-7.467558</td>\n",
       "      <td>-2.414031</td>\n",
       "      <td>-3.519237</td>\n",
       "      <td>-2.029857</td>\n",
       "      <td>-5.727956</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.791890</td>\n",
       "      <td>-6.780023</td>\n",
       "      <td>-3.137024</td>\n",
       "      <td>-4.385829</td>\n",
       "      <td>-4.979366</td>\n",
       "      <td>-4.423914</td>\n",
       "      <td>-3.532120</td>\n",
       "      <td>-5.310071</td>\n",
       "      <td>-6.788781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000249096</th>\n",
       "      <td>-4.548797</td>\n",
       "      <td>-5.056866</td>\n",
       "      <td>-5.827789</td>\n",
       "      <td>-4.856819</td>\n",
       "      <td>-6.005759</td>\n",
       "      <td>-2.683462</td>\n",
       "      <td>-3.648875</td>\n",
       "      <td>-2.582415</td>\n",
       "      <td>-4.844764</td>\n",
       "      <td>-4.967862</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.927249</td>\n",
       "      <td>-2.267014</td>\n",
       "      <td>-3.994508</td>\n",
       "      <td>-3.196142</td>\n",
       "      <td>-3.058906</td>\n",
       "      <td>-5.882088</td>\n",
       "      <td>-4.466674</td>\n",
       "      <td>-4.739424</td>\n",
       "      <td>-3.708700</td>\n",
       "      <td>-1.575765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000174171</th>\n",
       "      <td>-3.367747</td>\n",
       "      <td>-1.165252</td>\n",
       "      <td>-5.493399</td>\n",
       "      <td>-3.530224</td>\n",
       "      <td>-4.711031</td>\n",
       "      <td>-2.827728</td>\n",
       "      <td>-2.414040</td>\n",
       "      <td>-2.290647</td>\n",
       "      <td>-2.938510</td>\n",
       "      <td>-2.515703</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.647382</td>\n",
       "      <td>-2.870492</td>\n",
       "      <td>-0.663150</td>\n",
       "      <td>0.497486</td>\n",
       "      <td>-0.269528</td>\n",
       "      <td>-0.527990</td>\n",
       "      <td>0.091714</td>\n",
       "      <td>-2.331491</td>\n",
       "      <td>-3.528614</td>\n",
       "      <td>-0.351509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000240990</th>\n",
       "      <td>-5.010595</td>\n",
       "      <td>-2.925747</td>\n",
       "      <td>-1.812123</td>\n",
       "      <td>-4.028477</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.369774</td>\n",
       "      <td>-5.557804</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.456605</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.679842</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.926908</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>2.085140</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.427868</td>\n",
       "      <td>-3.331897</td>\n",
       "      <td>3.015682</td>\n",
       "      <td>1.479523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000255910</th>\n",
       "      <td>-8.818642</td>\n",
       "      <td>-7.440700</td>\n",
       "      <td>-6.678500</td>\n",
       "      <td>-8.061237</td>\n",
       "      <td>-9.529290</td>\n",
       "      <td>-9.011134</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.673285</td>\n",
       "      <td>-8.309243</td>\n",
       "      <td>-8.264034</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.506952</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.872206</td>\n",
       "      <td>-6.337488</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.233455</td>\n",
       "      <td>-7.739622</td>\n",
       "      <td>-9.232002</td>\n",
       "      <td>-7.947065</td>\n",
       "      <td>-7.879736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000241657</th>\n",
       "      <td>1.665234</td>\n",
       "      <td>1.005255</td>\n",
       "      <td>1.842348</td>\n",
       "      <td>-0.786509</td>\n",
       "      <td>1.124807</td>\n",
       "      <td>-1.164244</td>\n",
       "      <td>1.543186</td>\n",
       "      <td>1.576227</td>\n",
       "      <td>-2.766734</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.488493</td>\n",
       "      <td>-0.291250</td>\n",
       "      <td>1.441008</td>\n",
       "      <td>-1.265636</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.121010</td>\n",
       "      <td>0.127205</td>\n",
       "      <td>-2.659103</td>\n",
       "      <td>1.020696</td>\n",
       "      <td>0.794037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000265179</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.631302</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.477282</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.276576</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.371888</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>3.223159</td>\n",
       "      <td>-4.715687</td>\n",
       "      <td>-3.328883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000228723</th>\n",
       "      <td>0.040364</td>\n",
       "      <td>0.889554</td>\n",
       "      <td>-2.184118</td>\n",
       "      <td>-0.117320</td>\n",
       "      <td>3.108343</td>\n",
       "      <td>-1.050768</td>\n",
       "      <td>0.470455</td>\n",
       "      <td>-0.189901</td>\n",
       "      <td>-3.731043</td>\n",
       "      <td>-4.172902</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.434746</td>\n",
       "      <td>1.193304</td>\n",
       "      <td>-0.637934</td>\n",
       "      <td>1.184049</td>\n",
       "      <td>-1.068953</td>\n",
       "      <td>1.254781</td>\n",
       "      <td>-3.156862</td>\n",
       "      <td>-2.051033</td>\n",
       "      <td>-2.751365</td>\n",
       "      <td>-2.755723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000259070</th>\n",
       "      <td>-4.618729</td>\n",
       "      <td>-4.790283</td>\n",
       "      <td>-8.950255</td>\n",
       "      <td>-1.010180</td>\n",
       "      <td>-7.248854</td>\n",
       "      <td>-2.849847</td>\n",
       "      <td>-5.584915</td>\n",
       "      <td>-7.544515</td>\n",
       "      <td>-7.504905</td>\n",
       "      <td>-8.365836</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.836188</td>\n",
       "      <td>-5.879058</td>\n",
       "      <td>-6.823892</td>\n",
       "      <td>-7.981706</td>\n",
       "      <td>-7.522962</td>\n",
       "      <td>-7.429955</td>\n",
       "      <td>-7.221398</td>\n",
       "      <td>-8.647074</td>\n",
       "      <td>-0.816272</td>\n",
       "      <td>-6.909838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000235269</th>\n",
       "      <td>-9.445838</td>\n",
       "      <td>-8.638049</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.297654</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.548850</td>\n",
       "      <td>-8.226368</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.440348</td>\n",
       "      <td>-9.248754</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.916188</td>\n",
       "      <td>-5.221533</td>\n",
       "      <td>-7.074303</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.554755</td>\n",
       "      <td>-5.898069</td>\n",
       "      <td>-3.275016</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.470709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000258837</th>\n",
       "      <td>-3.831221</td>\n",
       "      <td>-1.201396</td>\n",
       "      <td>-2.174561</td>\n",
       "      <td>-0.079190</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.075019</td>\n",
       "      <td>-0.097977</td>\n",
       "      <td>-2.908043</td>\n",
       "      <td>-2.974456</td>\n",
       "      <td>-5.536054</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.600444</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.254248</td>\n",
       "      <td>-3.201057</td>\n",
       "      <td>-1.571464</td>\n",
       "      <td>-1.112669</td>\n",
       "      <td>-2.233269</td>\n",
       "      <td>-1.990878</td>\n",
       "      <td>-4.145181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000278698</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.386344</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.236805</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.876569</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.410385</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.175495</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000237928</th>\n",
       "      <td>-7.798802</td>\n",
       "      <td>-7.331960</td>\n",
       "      <td>-7.974058</td>\n",
       "      <td>-8.642734</td>\n",
       "      <td>-8.511323</td>\n",
       "      <td>-9.495771</td>\n",
       "      <td>-2.115000</td>\n",
       "      <td>-7.439573</td>\n",
       "      <td>-9.376045</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.695489</td>\n",
       "      <td>-7.455907</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.768561</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.154195</td>\n",
       "      <td>-9.338778</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.229174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000272797</th>\n",
       "      <td>-1.038244</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.631194</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.403991</td>\n",
       "      <td>-1.993245</td>\n",
       "      <td>-1.192419</td>\n",
       "      <td>-0.953420</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.222537</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.269057</td>\n",
       "      <td>-2.021694</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>3.873061</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000260676</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.819830</td>\n",
       "      <td>-3.701299</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.047550</td>\n",
       "      <td>3.507189</td>\n",
       "      <td>-3.383528</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.029691</td>\n",
       "      <td>1.352949</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000229155</th>\n",
       "      <td>-4.318382</td>\n",
       "      <td>-3.531489</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.312842</td>\n",
       "      <td>-3.116531</td>\n",
       "      <td>-4.682748</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.659158</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>2.085318</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.994434</td>\n",
       "      <td>-0.746426</td>\n",
       "      <td>-2.627145</td>\n",
       "      <td>2.747503</td>\n",
       "      <td>-0.605400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000198788</th>\n",
       "      <td>-6.494548</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.555716</td>\n",
       "      <td>-7.455913</td>\n",
       "      <td>-7.924196</td>\n",
       "      <td>-0.128456</td>\n",
       "      <td>-7.074051</td>\n",
       "      <td>-7.131777</td>\n",
       "      <td>-7.160786</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.972198</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.072567</td>\n",
       "      <td>1.680407</td>\n",
       "      <td>-5.904259</td>\n",
       "      <td>3.013609</td>\n",
       "      <td>-4.985814</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.678997</td>\n",
       "      <td>-1.788413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000230133</th>\n",
       "      <td>-8.748195</td>\n",
       "      <td>-7.689453</td>\n",
       "      <td>-9.440074</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.080620</td>\n",
       "      <td>-9.542224</td>\n",
       "      <td>-8.834228</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.043697</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.297144</td>\n",
       "      <td>-9.264819</td>\n",
       "      <td>-8.489087</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.846283</td>\n",
       "      <td>-7.548703</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.841021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000272988</th>\n",
       "      <td>-0.559492</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.355918</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.927504</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.477883</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.930163</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.446472</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000261520</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.300386</td>\n",
       "      <td>-8.233300</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.478802</td>\n",
       "      <td>-7.913929</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.215550</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.841204</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.051300</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000229228</th>\n",
       "      <td>-6.981072</td>\n",
       "      <td>-6.261563</td>\n",
       "      <td>-7.815066</td>\n",
       "      <td>-6.453021</td>\n",
       "      <td>-7.637269</td>\n",
       "      <td>-7.301131</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.877938</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.041018</td>\n",
       "      <td>-6.063324</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.187260</td>\n",
       "      <td>-6.445727</td>\n",
       "      <td>-6.342451</td>\n",
       "      <td>-5.516090</td>\n",
       "      <td>-4.033718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000259974</th>\n",
       "      <td>-5.856898</td>\n",
       "      <td>-5.307923</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.229758</td>\n",
       "      <td>-8.077678</td>\n",
       "      <td>-1.805281</td>\n",
       "      <td>0.269977</td>\n",
       "      <td>-7.734833</td>\n",
       "      <td>-8.221060</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.570676</td>\n",
       "      <td>-7.865615</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.881494</td>\n",
       "      <td>-1.847142</td>\n",
       "      <td>2.701956</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.488271</td>\n",
       "      <td>0.345494</td>\n",
       "      <td>-0.760154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000251185</th>\n",
       "      <td>-6.704551</td>\n",
       "      <td>-8.071595</td>\n",
       "      <td>-7.927612</td>\n",
       "      <td>-5.715787</td>\n",
       "      <td>-5.775339</td>\n",
       "      <td>-5.906063</td>\n",
       "      <td>-4.940549</td>\n",
       "      <td>-6.688526</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.471732</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.417254</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.912461</td>\n",
       "      <td>-8.879108</td>\n",
       "      <td>-8.369213</td>\n",
       "      <td>-8.969260</td>\n",
       "      <td>-7.780974</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.604375</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000254101</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.186090</td>\n",
       "      <td>-9.902212</td>\n",
       "      <td>-9.261865</td>\n",
       "      <td>-9.837739</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.985402</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.106148</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.805819</td>\n",
       "      <td>-9.574298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000223502</th>\n",
       "      <td>-6.261113</td>\n",
       "      <td>-4.543019</td>\n",
       "      <td>-4.758933</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.058381</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.108820</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.334106</td>\n",
       "      <td>-1.845500</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.410127</td>\n",
       "      <td>-4.738592</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.871282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000230392</th>\n",
       "      <td>-7.873946</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.703924</td>\n",
       "      <td>-7.708848</td>\n",
       "      <td>-8.288326</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.038257</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.375307</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.455613</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.343043</td>\n",
       "      <td>-6.893454</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.296921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000250584</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.066620</td>\n",
       "      <td>-5.623687</td>\n",
       "      <td>-1.876585</td>\n",
       "      <td>-8.324747</td>\n",
       "      <td>-0.967840</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.833908</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.810013</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.966718</td>\n",
       "      <td>-5.269328</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000231621</th>\n",
       "      <td>-0.066962</td>\n",
       "      <td>-1.353059</td>\n",
       "      <td>-1.573931</td>\n",
       "      <td>2.404577</td>\n",
       "      <td>1.384902</td>\n",
       "      <td>-0.526685</td>\n",
       "      <td>-0.138932</td>\n",
       "      <td>1.723909</td>\n",
       "      <td>-1.548681</td>\n",
       "      <td>0.501778</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432105</td>\n",
       "      <td>-0.844354</td>\n",
       "      <td>0.080557</td>\n",
       "      <td>0.071420</td>\n",
       "      <td>1.026609</td>\n",
       "      <td>1.838468</td>\n",
       "      <td>1.443201</td>\n",
       "      <td>1.494545</td>\n",
       "      <td>-1.559434</td>\n",
       "      <td>-2.146640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000225472</th>\n",
       "      <td>-5.118676</td>\n",
       "      <td>-4.868306</td>\n",
       "      <td>-5.125681</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.632284</td>\n",
       "      <td>-5.660294</td>\n",
       "      <td>-5.502389</td>\n",
       "      <td>-6.076972</td>\n",
       "      <td>-5.389411</td>\n",
       "      <td>-6.839963</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.967038</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.462070</td>\n",
       "      <td>-8.158638</td>\n",
       "      <td>-7.505820</td>\n",
       "      <td>-8.281702</td>\n",
       "      <td>-6.440047</td>\n",
       "      <td>-7.224599</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000231764</th>\n",
       "      <td>-4.988489</td>\n",
       "      <td>-6.719089</td>\n",
       "      <td>-8.188509</td>\n",
       "      <td>-2.756561</td>\n",
       "      <td>-7.226477</td>\n",
       "      <td>-2.012460</td>\n",
       "      <td>-0.577395</td>\n",
       "      <td>-3.985890</td>\n",
       "      <td>-8.170527</td>\n",
       "      <td>-6.013320</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.832692</td>\n",
       "      <td>-6.255257</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.437192</td>\n",
       "      <td>-7.908095</td>\n",
       "      <td>-5.668472</td>\n",
       "      <td>-5.218195</td>\n",
       "      <td>-8.092575</td>\n",
       "      <td>1.564897</td>\n",
       "      <td>-0.429289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000241388</th>\n",
       "      <td>-6.620342</td>\n",
       "      <td>-5.421926</td>\n",
       "      <td>-6.626884</td>\n",
       "      <td>-5.991210</td>\n",
       "      <td>-7.569421</td>\n",
       "      <td>-7.574461</td>\n",
       "      <td>-2.697645</td>\n",
       "      <td>-5.051156</td>\n",
       "      <td>-5.545195</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.119791</td>\n",
       "      <td>-6.229455</td>\n",
       "      <td>1.074790</td>\n",
       "      <td>-1.523223</td>\n",
       "      <td>-3.002014</td>\n",
       "      <td>-8.049145</td>\n",
       "      <td>-3.775458</td>\n",
       "      <td>1.568930</td>\n",
       "      <td>-4.552042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000233536</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.449334</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.260841</td>\n",
       "      <td>-5.014624</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.808920</td>\n",
       "      <td>-4.575615</td>\n",
       "      <td>-5.207987</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.425148</td>\n",
       "      <td>-3.884441</td>\n",
       "      <td>-4.886914</td>\n",
       "      <td>2.099915</td>\n",
       "      <td>-2.821816</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000234692</th>\n",
       "      <td>-1.983388</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.551399</td>\n",
       "      <td>0.230485</td>\n",
       "      <td>-1.772033</td>\n",
       "      <td>-0.441213</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.048360</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.036635</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.099355</td>\n",
       "      <td>-2.964156</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.130639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000224717</th>\n",
       "      <td>-0.599407</td>\n",
       "      <td>-2.453446</td>\n",
       "      <td>-1.955547</td>\n",
       "      <td>-1.369816</td>\n",
       "      <td>-4.095329</td>\n",
       "      <td>-0.801980</td>\n",
       "      <td>0.657592</td>\n",
       "      <td>-3.818036</td>\n",
       "      <td>-6.366209</td>\n",
       "      <td>2.041238</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.586336</td>\n",
       "      <td>-1.680290</td>\n",
       "      <td>0.329828</td>\n",
       "      <td>-5.338395</td>\n",
       "      <td>-1.130839</td>\n",
       "      <td>-1.296810</td>\n",
       "      <td>-3.310530</td>\n",
       "      <td>-1.917186</td>\n",
       "      <td>-3.316830</td>\n",
       "      <td>-4.473186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000262117</th>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.568657</td>\n",
       "      <td>-5.889144</td>\n",
       "      <td>-6.794607</td>\n",
       "      <td>-6.604026</td>\n",
       "      <td>-6.230265</td>\n",
       "      <td>-6.411247</td>\n",
       "      <td>-6.190649</td>\n",
       "      <td>-5.865308</td>\n",
       "      <td>-6.283772</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.596378</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>2.063655</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.602255</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.348098</td>\n",
       "      <td>-4.922699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000248646</th>\n",
       "      <td>-7.402751</td>\n",
       "      <td>-7.822638</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.976099</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.634323</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.969923</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.157100</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000258170</th>\n",
       "      <td>-4.630739</td>\n",
       "      <td>-0.787247</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.140680</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.994469</td>\n",
       "      <td>-7.180327</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.525086</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.199507</td>\n",
       "      <td>-5.674618</td>\n",
       "      <td>-5.038927</td>\n",
       "      <td>-7.098646</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.300479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TCGA-04-1331  TCGA-04-1332  TCGA-04-1347  TCGA-04-1362  \\\n",
       "ID                                                                        \n",
       "ENSG00000233048     -7.207620     -9.965784     -9.965784     -9.965784   \n",
       "ENSG00000083622     -9.965784     -4.786606     -9.965784     -6.722537   \n",
       "ENSG00000269994     -8.325863     -5.686705     -6.729526     -6.184552   \n",
       "ENSG00000258752     -0.500069     -3.869310     -6.173850     -5.772887   \n",
       "ENSG00000249790     -6.567569     -3.572952     -4.681104     -6.562452   \n",
       "ENSG00000261399      0.844999      1.141537      2.071746     -2.230827   \n",
       "ENSG00000232721     -9.965784     -1.077274     -5.519466     -1.248935   \n",
       "ENSG00000243479     -6.179796     -5.425791     -9.965784     -2.028888   \n",
       "ENSG00000248554     -1.826764     -2.248224     -3.752458     -3.118508   \n",
       "ENSG00000250432     -4.418532     -2.366232     -3.285301     -1.978935   \n",
       "ENSG00000226956      1.340473      5.072901     -1.364075      1.943173   \n",
       "ENSG00000228058     -5.973825     -2.261350     -9.965784     -1.151719   \n",
       "ENSG00000226203     -5.879200     -4.399784     -3.542034     -6.417148   \n",
       "ENSG00000233705     -4.751401     -9.965784     -5.719932     -6.255447   \n",
       "ENSG00000249096     -4.548797     -5.056866     -5.827789     -4.856819   \n",
       "ENSG00000174171     -3.367747     -1.165252     -5.493399     -3.530224   \n",
       "ENSG00000240990     -5.010595     -2.925747     -1.812123     -4.028477   \n",
       "ENSG00000255910     -8.818642     -7.440700     -6.678500     -8.061237   \n",
       "ENSG00000241657      1.665234      1.005255      1.842348     -0.786509   \n",
       "ENSG00000265179     -9.965784     -2.631302     -9.965784     -9.965784   \n",
       "ENSG00000228723      0.040364      0.889554     -2.184118     -0.117320   \n",
       "ENSG00000259070     -4.618729     -4.790283     -8.950255     -1.010180   \n",
       "ENSG00000235269     -9.445838     -8.638049     -9.965784     -8.297654   \n",
       "ENSG00000258837     -3.831221     -1.201396     -2.174561     -0.079190   \n",
       "ENSG00000278698     -9.965784     -1.386344     -9.965784     -9.965784   \n",
       "ENSG00000237928     -7.798802     -7.331960     -7.974058     -8.642734   \n",
       "ENSG00000272797     -1.038244     -9.965784     -0.631194     -9.965784   \n",
       "ENSG00000260676     -9.965784     -9.965784     -8.819830     -3.701299   \n",
       "ENSG00000229155     -4.318382     -3.531489     -9.965784     -4.312842   \n",
       "ENSG00000198788     -6.494548     -9.965784     -9.965784     -5.555716   \n",
       "ENSG00000230133     -8.748195     -7.689453     -9.440074     -9.965784   \n",
       "ENSG00000272988     -0.559492     -9.965784     -9.965784     -2.355918   \n",
       "ENSG00000261520     -9.965784     -5.300386     -8.233300     -9.965784   \n",
       "ENSG00000229228     -6.981072     -6.261563     -7.815066     -6.453021   \n",
       "ENSG00000259974     -5.856898     -5.307923     -9.965784     -8.229758   \n",
       "ENSG00000251185     -6.704551     -8.071595     -7.927612     -5.715787   \n",
       "ENSG00000254101     -9.965784     -9.965784     -9.965784     -9.965784   \n",
       "ENSG00000223502     -6.261113     -4.543019     -4.758933     -9.965784   \n",
       "ENSG00000230392     -7.873946     -9.965784     -9.965784     -9.965784   \n",
       "ENSG00000250584     -9.965784     -9.965784     -8.066620     -5.623687   \n",
       "ENSG00000231621     -0.066962     -1.353059     -1.573931      2.404577   \n",
       "ENSG00000225472     -5.118676     -4.868306     -5.125681     -9.965784   \n",
       "ENSG00000231764     -4.988489     -6.719089     -8.188509     -2.756561   \n",
       "ENSG00000241388     -6.620342     -5.421926     -6.626884     -5.991210   \n",
       "ENSG00000233536     -9.965784     -4.449334     -9.965784     -3.260841   \n",
       "ENSG00000234692     -1.983388     -9.965784     -9.965784     -3.551399   \n",
       "ENSG00000224717     -0.599407     -2.453446     -1.955547     -1.369816   \n",
       "ENSG00000262117     -9.965784     -3.568657     -5.889144     -6.794607   \n",
       "ENSG00000248646     -7.402751     -7.822638     -9.965784     -8.976099   \n",
       "ENSG00000258170     -4.630739     -0.787247     -9.965784     -6.140680   \n",
       "\n",
       "                 TCGA-04-1364  TCGA-04-1365  TCGA-04-1514  TCGA-04-1530  \\\n",
       "ID                                                                        \n",
       "ENSG00000233048     -3.797716     -8.781751     -8.888570     -9.965784   \n",
       "ENSG00000083622     -9.965784     -8.115396     -9.965784     -5.869315   \n",
       "ENSG00000269994     -9.965784     -7.051607     -8.020065     -5.808990   \n",
       "ENSG00000258752      0.101508     -5.179247      0.664458     -3.996567   \n",
       "ENSG00000249790     -4.460856     -5.989466     -3.936696     -9.965784   \n",
       "ENSG00000261399      0.435589      2.165586      1.579985      2.181894   \n",
       "ENSG00000232721     -0.604508     -9.965784      0.173711     -9.965784   \n",
       "ENSG00000243479     -5.976203     -6.522107     -4.816674     -4.583403   \n",
       "ENSG00000248554     -1.830784      0.104746     -1.397632     -2.843421   \n",
       "ENSG00000250432     -2.480781     -3.622465     -5.338202     -3.464192   \n",
       "ENSG00000226956     -9.965784     -0.856281     -9.965784     -0.273797   \n",
       "ENSG00000228058     -9.965784     -6.320159     -4.028322     -5.337950   \n",
       "ENSG00000226203     -3.729100     -6.227202     -3.108728     -6.720901   \n",
       "ENSG00000233705     -6.964881     -7.467558     -2.414031     -3.519237   \n",
       "ENSG00000249096     -6.005759     -2.683462     -3.648875     -2.582415   \n",
       "ENSG00000174171     -4.711031     -2.827728     -2.414040     -2.290647   \n",
       "ENSG00000240990     -9.965784     -5.369774     -5.557804     -9.965784   \n",
       "ENSG00000255910     -9.529290     -9.011134     -9.965784     -8.673285   \n",
       "ENSG00000241657      1.124807     -1.164244      1.543186      1.576227   \n",
       "ENSG00000265179     -5.477282     -9.965784     -9.965784     -9.965784   \n",
       "ENSG00000228723      3.108343     -1.050768      0.470455     -0.189901   \n",
       "ENSG00000259070     -7.248854     -2.849847     -5.584915     -7.544515   \n",
       "ENSG00000235269     -9.965784     -9.548850     -8.226368     -9.965784   \n",
       "ENSG00000258837     -9.965784     -3.075019     -0.097977     -2.908043   \n",
       "ENSG00000278698     -9.965784     -1.236805     -9.965784     -9.965784   \n",
       "ENSG00000237928     -8.511323     -9.495771     -2.115000     -7.439573   \n",
       "ENSG00000272797     -1.403991     -1.993245     -1.192419     -0.953420   \n",
       "ENSG00000260676     -9.965784     -9.965784     -9.965784     -9.965784   \n",
       "ENSG00000229155     -3.116531     -4.682748     -9.965784     -3.659158   \n",
       "ENSG00000198788     -7.455913     -7.924196     -0.128456     -7.074051   \n",
       "ENSG00000230133     -3.080620     -9.542224     -8.834228     -9.965784   \n",
       "ENSG00000272988     -9.965784     -9.965784     -2.927504     -9.965784   \n",
       "ENSG00000261520     -9.965784     -8.478802     -7.913929     -9.965784   \n",
       "ENSG00000229228     -7.637269     -7.301131     -9.965784     -4.877938   \n",
       "ENSG00000259974     -8.077678     -1.805281      0.269977     -7.734833   \n",
       "ENSG00000251185     -5.775339     -5.906063     -4.940549     -6.688526   \n",
       "ENSG00000254101     -5.186090     -9.902212     -9.261865     -9.837739   \n",
       "ENSG00000223502     -6.058381     -9.965784     -9.965784     -3.108820   \n",
       "ENSG00000230392     -7.703924     -7.708848     -8.288326     -9.965784   \n",
       "ENSG00000250584     -1.876585     -8.324747     -0.967840     -9.965784   \n",
       "ENSG00000231621      1.384902     -0.526685     -0.138932      1.723909   \n",
       "ENSG00000225472     -7.632284     -5.660294     -5.502389     -6.076972   \n",
       "ENSG00000231764     -7.226477     -2.012460     -0.577395     -3.985890   \n",
       "ENSG00000241388     -7.569421     -7.574461     -2.697645     -5.051156   \n",
       "ENSG00000233536     -5.014624     -9.965784     -4.808920     -4.575615   \n",
       "ENSG00000234692      0.230485     -1.772033     -0.441213     -9.965784   \n",
       "ENSG00000224717     -4.095329     -0.801980      0.657592     -3.818036   \n",
       "ENSG00000262117     -6.604026     -6.230265     -6.411247     -6.190649   \n",
       "ENSG00000248646     -9.965784     -8.634323     -9.965784     -9.965784   \n",
       "ENSG00000258170     -9.965784     -1.994469     -7.180327     -9.965784   \n",
       "\n",
       "                 TCGA-04-1536  TCGA-04-1542  ...  TCGA-61-2000  TCGA-61-2008  \\\n",
       "ID                                           ...                               \n",
       "ENSG00000233048     -9.965784     -8.813903  ...     -9.965784     -8.850686   \n",
       "ENSG00000083622     -9.965784     -9.965784  ...     -9.965784     -9.965784   \n",
       "ENSG00000269994     -7.563521     -9.965784  ...     -5.907724     -7.967025   \n",
       "ENSG00000258752     -6.684953     -9.965784  ...     -9.965784     -3.024313   \n",
       "ENSG00000249790     -9.965784     -9.965784  ...     -4.378901     -5.157279   \n",
       "ENSG00000261399     -9.965784     -9.965784  ...     -2.930124     -0.417775   \n",
       "ENSG00000232721     -3.544945     -4.964940  ...     -5.222931     -0.827823   \n",
       "ENSG00000243479     -2.676088     -3.121561  ...      1.380614     -2.776810   \n",
       "ENSG00000248554     -4.012739     -2.558986  ...     -3.102304     -4.370490   \n",
       "ENSG00000250432     -6.213497     -3.395735  ...     -4.897508     -9.965784   \n",
       "ENSG00000226956      0.828268     -2.368795  ...     -9.965784     -0.634267   \n",
       "ENSG00000228058     -0.587804     -9.965784  ...     -9.965784     -1.314316   \n",
       "ENSG00000226203     -9.965784     -3.642390  ...     -2.434400     -9.965784   \n",
       "ENSG00000233705     -2.029857     -5.727956  ...     -9.965784     -5.791890   \n",
       "ENSG00000249096     -4.844764     -4.967862  ...     -5.927249     -2.267014   \n",
       "ENSG00000174171     -2.938510     -2.515703  ...     -3.647382     -2.870492   \n",
       "ENSG00000240990     -9.965784     -4.456605  ...     -5.679842     -9.965784   \n",
       "ENSG00000255910     -8.309243     -8.264034  ...     -9.506952     -9.965784   \n",
       "ENSG00000241657     -2.766734     -9.965784  ...     -1.488493     -0.291250   \n",
       "ENSG00000265179     -9.965784     -9.965784  ...     -9.965784     -9.965784   \n",
       "ENSG00000228723     -3.731043     -4.172902  ...     -4.434746      1.193304   \n",
       "ENSG00000259070     -7.504905     -8.365836  ...     -7.836188     -5.879058   \n",
       "ENSG00000235269     -9.440348     -9.248754  ...     -8.916188     -5.221533   \n",
       "ENSG00000258837     -2.974456     -5.536054  ...     -9.965784     -5.600444   \n",
       "ENSG00000278698     -9.965784     -9.965784  ...     -2.876569     -9.965784   \n",
       "ENSG00000237928     -9.376045     -9.965784  ...     -9.965784     -8.695489   \n",
       "ENSG00000272797     -9.965784     -9.965784  ...     -9.965784     -9.965784   \n",
       "ENSG00000260676     -9.965784     -9.965784  ...     -9.965784     -9.965784   \n",
       "ENSG00000229155     -9.965784     -9.965784  ...     -9.965784     -9.965784   \n",
       "ENSG00000198788     -7.131777     -7.160786  ...     -5.972198     -9.965784   \n",
       "ENSG00000230133     -9.043697     -9.965784  ...     -8.297144     -9.264819   \n",
       "ENSG00000272988     -9.965784     -9.965784  ...     -1.477883     -9.965784   \n",
       "ENSG00000261520     -8.215550     -9.965784  ...     -9.965784     -9.965784   \n",
       "ENSG00000229228     -9.965784     -9.965784  ...     -9.965784     -5.041018   \n",
       "ENSG00000259974     -8.221060     -9.965784  ...     -5.570676     -7.865615   \n",
       "ENSG00000251185     -9.965784     -7.471732  ...     -8.417254     -9.965784   \n",
       "ENSG00000254101     -9.965784     -9.965784  ...     -9.965784     -5.985402   \n",
       "ENSG00000223502     -9.965784     -9.965784  ...     -9.965784     -9.965784   \n",
       "ENSG00000230392     -7.038257     -9.965784  ...     -8.375307     -9.965784   \n",
       "ENSG00000250584     -9.965784     -9.965784  ...     -7.833908     -9.965784   \n",
       "ENSG00000231621     -1.548681      0.501778  ...      1.432105     -0.844354   \n",
       "ENSG00000225472     -5.389411     -6.839963  ...     -5.967038     -9.965784   \n",
       "ENSG00000231764     -8.170527     -6.013320  ...     -5.832692     -6.255257   \n",
       "ENSG00000241388     -5.545195     -9.965784  ...     -9.965784     -8.119791   \n",
       "ENSG00000233536     -5.207987     -9.965784  ...     -9.965784     -9.965784   \n",
       "ENSG00000234692     -9.965784     -9.965784  ...     -9.965784     -4.048360   \n",
       "ENSG00000224717     -6.366209      2.041238  ...     -4.586336     -1.680290   \n",
       "ENSG00000262117     -5.865308     -6.283772  ...     -5.596378     -9.965784   \n",
       "ENSG00000248646     -8.969923     -9.965784  ...     -9.965784     -9.965784   \n",
       "ENSG00000258170     -7.525086     -9.965784  ...     -3.199507     -5.674618   \n",
       "\n",
       "                 TCGA-61-2009  TCGA-61-2092  TCGA-61-2097  TCGA-61-2098  \\\n",
       "ID                                                                        \n",
       "ENSG00000233048     -9.965784     -9.965784     -9.965784     -7.098053   \n",
       "ENSG00000083622     -9.965784     -9.965784     -9.965784     -9.965784   \n",
       "ENSG00000269994     -8.022048     -7.949062     -9.965784     -6.406115   \n",
       "ENSG00000258752     -5.766190     -1.121523     -5.421963     -0.779119   \n",
       "ENSG00000249790     -3.679993     -3.843015     -2.160467     -2.891021   \n",
       "ENSG00000261399     -1.810424      1.675046     -0.282066     -1.887774   \n",
       "ENSG00000232721     -0.395389      1.116185      0.495997     -3.626908   \n",
       "ENSG00000243479     -9.965784      2.101699      3.953488     -9.965784   \n",
       "ENSG00000248554     -3.776527     -2.880645     -2.670585     -0.317675   \n",
       "ENSG00000250432     -3.350046     -4.205433     -7.489817     -2.981221   \n",
       "ENSG00000226956     -1.192495     -9.965784     -2.562468     -3.578021   \n",
       "ENSG00000228058     -4.030956     -9.965784     -3.674450     -9.965784   \n",
       "ENSG00000226203     -3.781994     -9.965784     -9.965784     -3.858527   \n",
       "ENSG00000233705     -6.780023     -3.137024     -4.385829     -4.979366   \n",
       "ENSG00000249096     -3.994508     -3.196142     -3.058906     -5.882088   \n",
       "ENSG00000174171     -0.663150      0.497486     -0.269528     -0.527990   \n",
       "ENSG00000240990     -0.926908     -9.965784      2.085140     -9.965784   \n",
       "ENSG00000255910     -7.872206     -6.337488     -9.965784     -8.233455   \n",
       "ENSG00000241657      1.441008     -1.265636     -9.965784     -0.121010   \n",
       "ENSG00000265179     -5.276576     -9.965784     -3.371888     -9.965784   \n",
       "ENSG00000228723     -0.637934      1.184049     -1.068953      1.254781   \n",
       "ENSG00000259070     -6.823892     -7.981706     -7.522962     -7.429955   \n",
       "ENSG00000235269     -7.074303     -9.965784     -9.965784     -8.554755   \n",
       "ENSG00000258837     -9.965784     -0.254248     -3.201057     -1.571464   \n",
       "ENSG00000278698     -9.965784     -9.965784     -9.965784     -9.965784   \n",
       "ENSG00000237928     -7.455907     -9.965784     -8.768561     -9.965784   \n",
       "ENSG00000272797     -9.965784      0.222537     -9.965784     -2.269057   \n",
       "ENSG00000260676     -7.047550      3.507189     -3.383528     -9.965784   \n",
       "ENSG00000229155     -9.965784      2.085318     -9.965784     -0.994434   \n",
       "ENSG00000198788     -8.072567      1.680407     -5.904259      3.013609   \n",
       "ENSG00000230133     -8.489087     -9.965784     -9.965784     -9.965784   \n",
       "ENSG00000272988     -2.930163     -9.965784     -9.965784     -9.965784   \n",
       "ENSG00000261520     -9.965784     -7.841204     -9.965784     -9.965784   \n",
       "ENSG00000229228     -6.063324     -9.965784     -9.965784     -5.187260   \n",
       "ENSG00000259974     -9.965784     -3.881494     -1.847142      2.701956   \n",
       "ENSG00000251185     -7.912461     -8.879108     -8.369213     -8.969260   \n",
       "ENSG00000254101     -9.965784     -9.965784     -9.965784     -5.106148   \n",
       "ENSG00000223502     -4.334106     -1.845500     -9.965784     -4.410127   \n",
       "ENSG00000230392     -9.965784     -7.455613     -9.965784     -8.343043   \n",
       "ENSG00000250584     -1.810013     -9.965784     -9.965784     -6.966718   \n",
       "ENSG00000231621      0.080557      0.071420      1.026609      1.838468   \n",
       "ENSG00000225472     -7.462070     -8.158638     -7.505820     -8.281702   \n",
       "ENSG00000231764     -9.965784     -3.437192     -7.908095     -5.668472   \n",
       "ENSG00000241388     -6.229455      1.074790     -1.523223     -3.002014   \n",
       "ENSG00000233536     -9.965784     -2.425148     -3.884441     -4.886914   \n",
       "ENSG00000234692     -9.965784     -3.036635     -9.965784      0.099355   \n",
       "ENSG00000224717      0.329828     -5.338395     -1.130839     -1.296810   \n",
       "ENSG00000262117     -9.965784      2.063655     -9.965784     -3.602255   \n",
       "ENSG00000248646     -9.965784     -9.965784     -9.965784     -8.157100   \n",
       "ENSG00000258170     -5.038927     -7.098646     -9.965784     -9.965784   \n",
       "\n",
       "                 TCGA-61-2109  TCGA-61-2110  TCGA-61-2111  TCGA-61-2113  \n",
       "ID                                                                       \n",
       "ENSG00000233048     -7.110620     -9.965784     -7.035556     -9.965784  \n",
       "ENSG00000083622     -6.850643     -7.259768     -4.471057     -5.553862  \n",
       "ENSG00000269994     -6.557792     -6.609472     -1.229587     -6.343955  \n",
       "ENSG00000258752     -7.055175     -4.529617     -5.771347     -5.380351  \n",
       "ENSG00000249790     -6.016198     -9.965784     -9.965784     -4.265393  \n",
       "ENSG00000261399      3.213477      0.054455      1.224064      0.345725  \n",
       "ENSG00000232721     -2.969993     -3.119024     -2.243889     -4.136419  \n",
       "ENSG00000243479     -2.223574     -5.111212     -0.471729     -3.051074  \n",
       "ENSG00000248554     -0.868077     -3.620514     -0.892318     -1.756998  \n",
       "ENSG00000250432     -3.079868     -3.873170     -5.491503     -6.586462  \n",
       "ENSG00000226956      7.672012      8.009448     -9.965784     -9.965784  \n",
       "ENSG00000228058     -2.873291     -5.855043     -5.012842     -9.965784  \n",
       "ENSG00000226203     -5.309722     -1.272037     -6.415658     -4.515408  \n",
       "ENSG00000233705     -4.423914     -3.532120     -5.310071     -6.788781  \n",
       "ENSG00000249096     -4.466674     -4.739424     -3.708700     -1.575765  \n",
       "ENSG00000174171      0.091714     -2.331491     -3.528614     -0.351509  \n",
       "ENSG00000240990     -4.427868     -3.331897      3.015682      1.479523  \n",
       "ENSG00000255910     -7.739622     -9.232002     -7.947065     -7.879736  \n",
       "ENSG00000241657      0.127205     -2.659103      1.020696      0.794037  \n",
       "ENSG00000265179     -9.965784      3.223159     -4.715687     -3.328883  \n",
       "ENSG00000228723     -3.156862     -2.051033     -2.751365     -2.755723  \n",
       "ENSG00000259070     -7.221398     -8.647074     -0.816272     -6.909838  \n",
       "ENSG00000235269     -5.898069     -3.275016     -9.965784     -7.470709  \n",
       "ENSG00000258837     -1.112669     -2.233269     -1.990878     -4.145181  \n",
       "ENSG00000278698      0.410385     -9.965784     -2.175495     -9.965784  \n",
       "ENSG00000237928     -9.154195     -9.338778     -9.965784     -9.229174  \n",
       "ENSG00000272797     -2.021694     -9.965784      3.873061     -9.965784  \n",
       "ENSG00000260676     -9.965784     -7.029691      1.352949     -9.965784  \n",
       "ENSG00000229155     -0.746426     -2.627145      2.747503     -0.605400  \n",
       "ENSG00000198788     -4.985814     -9.965784     -3.678997     -1.788413  \n",
       "ENSG00000230133     -7.846283     -7.548703     -9.965784     -8.841021  \n",
       "ENSG00000272988     -0.446472     -9.965784     -9.965784     -9.965784  \n",
       "ENSG00000261520     -9.965784     -9.965784     -6.051300     -9.965784  \n",
       "ENSG00000229228     -6.445727     -6.342451     -5.516090     -4.033718  \n",
       "ENSG00000259974     -9.965784     -6.488271      0.345494     -0.760154  \n",
       "ENSG00000251185     -7.780974     -9.965784     -8.604375     -9.965784  \n",
       "ENSG00000254101     -9.965784     -9.965784     -9.805819     -9.574298  \n",
       "ENSG00000223502     -4.738592     -9.965784     -9.965784     -5.871282  \n",
       "ENSG00000230392     -6.893454     -9.965784     -9.965784     -8.296921  \n",
       "ENSG00000250584     -5.269328     -9.965784     -9.965784     -9.965784  \n",
       "ENSG00000231621      1.443201      1.494545     -1.559434     -2.146640  \n",
       "ENSG00000225472     -6.440047     -7.224599     -9.965784     -9.965784  \n",
       "ENSG00000231764     -5.218195     -8.092575      1.564897     -0.429289  \n",
       "ENSG00000241388     -8.049145     -3.775458      1.568930     -4.552042  \n",
       "ENSG00000233536      2.099915     -2.821816     -9.965784     -9.965784  \n",
       "ENSG00000234692     -2.964156     -9.965784     -9.965784     -4.130639  \n",
       "ENSG00000224717     -3.310530     -1.917186     -3.316830     -4.473186  \n",
       "ENSG00000262117     -9.965784     -9.965784     -4.348098     -4.922699  \n",
       "ENSG00000248646     -9.965784     -9.965784     -9.965784     -9.965784  \n",
       "ENSG00000258170     -9.965784     -9.965784     -9.965784     -6.300479  \n",
       "\n",
       "[50 rows x 210 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_lnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_lnc = df_data_lnc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mi = pd.concat([df_label_mi,df_data_mi], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_label,df_data_mod,df_data_mi,df_data_lnc], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLATINUM_STATUS</th>\n",
       "      <th>label</th>\n",
       "      <th>ENSG00000131096</th>\n",
       "      <th>ENSG00000187581</th>\n",
       "      <th>ENSG00000047936</th>\n",
       "      <th>ENSG00000186198</th>\n",
       "      <th>ENSG00000179914</th>\n",
       "      <th>ENSG00000186897</th>\n",
       "      <th>ENSG00000138136</th>\n",
       "      <th>ENSG00000139219</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000231621</th>\n",
       "      <th>ENSG00000225472</th>\n",
       "      <th>ENSG00000231764</th>\n",
       "      <th>ENSG00000241388</th>\n",
       "      <th>ENSG00000233536</th>\n",
       "      <th>ENSG00000234692</th>\n",
       "      <th>ENSG00000224717</th>\n",
       "      <th>ENSG00000262117</th>\n",
       "      <th>ENSG00000248646</th>\n",
       "      <th>ENSG00000258170</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1315</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.686983</td>\n",
       "      <td>0.960027</td>\n",
       "      <td>-7.704844</td>\n",
       "      <td>-0.728522</td>\n",
       "      <td>-1.069286</td>\n",
       "      <td>1.390239</td>\n",
       "      <td>-5.708668</td>\n",
       "      <td>0.628004</td>\n",
       "      <td>...</td>\n",
       "      <td>5.178812</td>\n",
       "      <td>-6.200513</td>\n",
       "      <td>-2.085854</td>\n",
       "      <td>-7.030567</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.625400</td>\n",
       "      <td>-0.932508</td>\n",
       "      <td>-1.614775</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-0979</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.813098</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.214181</td>\n",
       "      <td>0.696332</td>\n",
       "      <td>-4.119434</td>\n",
       "      <td>0.170307</td>\n",
       "      <td>-5.958588</td>\n",
       "      <td>2.285056</td>\n",
       "      <td>...</td>\n",
       "      <td>4.476964</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.024147</td>\n",
       "      <td>-8.052592</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.166303</td>\n",
       "      <td>-6.218003</td>\n",
       "      <td>-5.713393</td>\n",
       "      <td>-7.978815</td>\n",
       "      <td>-6.137611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2008</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.816355</td>\n",
       "      <td>-1.936841</td>\n",
       "      <td>-7.028077</td>\n",
       "      <td>-2.043819</td>\n",
       "      <td>-2.590863</td>\n",
       "      <td>-2.956409</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>1.944798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.844354</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.255257</td>\n",
       "      <td>-8.119791</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.048360</td>\n",
       "      <td>-1.680290</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.674618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.197002</td>\n",
       "      <td>0.155893</td>\n",
       "      <td>-4.107782</td>\n",
       "      <td>-1.873511</td>\n",
       "      <td>1.355935</td>\n",
       "      <td>3.306055</td>\n",
       "      <td>-4.999621</td>\n",
       "      <td>-0.662207</td>\n",
       "      <td>...</td>\n",
       "      <td>1.443201</td>\n",
       "      <td>-6.440047</td>\n",
       "      <td>-5.218195</td>\n",
       "      <td>-8.049145</td>\n",
       "      <td>2.099915</td>\n",
       "      <td>-2.964156</td>\n",
       "      <td>-3.310530</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1626</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.062823</td>\n",
       "      <td>-3.492144</td>\n",
       "      <td>-7.158498</td>\n",
       "      <td>-1.574098</td>\n",
       "      <td>-5.328884</td>\n",
       "      <td>2.505427</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>1.841454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950276</td>\n",
       "      <td>-5.761374</td>\n",
       "      <td>-2.844205</td>\n",
       "      <td>-6.814008</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.647855</td>\n",
       "      <td>-1.859318</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.287891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-31-1950</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.515936</td>\n",
       "      <td>-1.504317</td>\n",
       "      <td>-2.365897</td>\n",
       "      <td>-4.508600</td>\n",
       "      <td>1.745130</td>\n",
       "      <td>0.777006</td>\n",
       "      <td>-1.062668</td>\n",
       "      <td>-3.695113</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.578493</td>\n",
       "      <td>-6.175614</td>\n",
       "      <td>-6.963735</td>\n",
       "      <td>-3.011187</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.942857</td>\n",
       "      <td>-5.942840</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.222087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0905</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.464729</td>\n",
       "      <td>1.093583</td>\n",
       "      <td>0.827830</td>\n",
       "      <td>-4.394041</td>\n",
       "      <td>-0.444499</td>\n",
       "      <td>3.603272</td>\n",
       "      <td>-5.029925</td>\n",
       "      <td>-6.108373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.520381</td>\n",
       "      <td>-1.889686</td>\n",
       "      <td>-7.282487</td>\n",
       "      <td>-8.072101</td>\n",
       "      <td>-4.675745</td>\n",
       "      <td>-2.414103</td>\n",
       "      <td>-1.766353</td>\n",
       "      <td>-7.177194</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.925545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1434</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.535915</td>\n",
       "      <td>-3.933301</td>\n",
       "      <td>-6.844471</td>\n",
       "      <td>-4.688200</td>\n",
       "      <td>-5.196260</td>\n",
       "      <td>1.075179</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.686641</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.747252</td>\n",
       "      <td>-1.302654</td>\n",
       "      <td>-7.203258</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.904797</td>\n",
       "      <td>-3.609945</td>\n",
       "      <td>-6.734171</td>\n",
       "      <td>-8.942039</td>\n",
       "      <td>-6.077553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1778</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.244211</td>\n",
       "      <td>-1.214991</td>\n",
       "      <td>-5.441707</td>\n",
       "      <td>-4.155418</td>\n",
       "      <td>-3.496604</td>\n",
       "      <td>-0.749340</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.338790</td>\n",
       "      <td>...</td>\n",
       "      <td>2.573798</td>\n",
       "      <td>-5.062114</td>\n",
       "      <td>-7.074438</td>\n",
       "      <td>-8.583172</td>\n",
       "      <td>-4.438141</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.624848</td>\n",
       "      <td>-5.108739</td>\n",
       "      <td>-9.069619</td>\n",
       "      <td>-5.166117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0920</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.413750</td>\n",
       "      <td>5.261917</td>\n",
       "      <td>-7.487164</td>\n",
       "      <td>-0.013569</td>\n",
       "      <td>-3.280097</td>\n",
       "      <td>0.039594</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.552783</td>\n",
       "      <td>...</td>\n",
       "      <td>3.628496</td>\n",
       "      <td>-6.248567</td>\n",
       "      <td>-5.628717</td>\n",
       "      <td>-5.229480</td>\n",
       "      <td>-2.465363</td>\n",
       "      <td>1.756960</td>\n",
       "      <td>-2.110243</td>\n",
       "      <td>-5.112208</td>\n",
       "      <td>-8.523270</td>\n",
       "      <td>-6.852636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PLATINUM_STATUS  label  ENSG00000131096  ENSG00000187581  \\\n",
       "PATIENT_ID                                                              \n",
       "TCGA-25-1315       Resistant    1.0        -4.686983         0.960027   \n",
       "TCGA-24-0979       Sensitive    0.0        -5.813098        -9.965784   \n",
       "TCGA-61-2008       Sensitive    0.0        -6.816355        -1.936841   \n",
       "TCGA-61-2109       Sensitive    0.0        -6.197002         0.155893   \n",
       "TCGA-25-1626       Resistant    1.0        -6.062823        -3.492144   \n",
       "...                      ...    ...              ...              ...   \n",
       "TCGA-31-1950       Sensitive    0.0        -3.515936        -1.504317   \n",
       "TCGA-13-0905       Sensitive    0.0        -4.464729         1.093583   \n",
       "TCGA-24-1434       Resistant    1.0        -7.535915        -3.933301   \n",
       "TCGA-29-1778       Sensitive    0.0        -6.244211        -1.214991   \n",
       "TCGA-13-0920       Resistant    1.0        -7.413750         5.261917   \n",
       "\n",
       "              ENSG00000047936  ENSG00000186198  ENSG00000179914  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-25-1315        -7.704844        -0.728522        -1.069286   \n",
       "TCGA-24-0979        -8.214181         0.696332        -4.119434   \n",
       "TCGA-61-2008        -7.028077        -2.043819        -2.590863   \n",
       "TCGA-61-2109        -4.107782        -1.873511         1.355935   \n",
       "TCGA-25-1626        -7.158498        -1.574098        -5.328884   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-31-1950        -2.365897        -4.508600         1.745130   \n",
       "TCGA-13-0905         0.827830        -4.394041        -0.444499   \n",
       "TCGA-24-1434        -6.844471        -4.688200        -5.196260   \n",
       "TCGA-29-1778        -5.441707        -4.155418        -3.496604   \n",
       "TCGA-13-0920        -7.487164        -0.013569        -3.280097   \n",
       "\n",
       "              ENSG00000186897  ENSG00000138136  ENSG00000139219  ...  \\\n",
       "PATIENT_ID                                                       ...   \n",
       "TCGA-25-1315         1.390239        -5.708668         0.628004  ...   \n",
       "TCGA-24-0979         0.170307        -5.958588         2.285056  ...   \n",
       "TCGA-61-2008        -2.956409        -9.965784         1.944798  ...   \n",
       "TCGA-61-2109         3.306055        -4.999621        -0.662207  ...   \n",
       "TCGA-25-1626         2.505427        -9.965784         1.841454  ...   \n",
       "...                       ...              ...              ...  ...   \n",
       "TCGA-31-1950         0.777006        -1.062668        -3.695113  ...   \n",
       "TCGA-13-0905         3.603272        -5.029925        -6.108373  ...   \n",
       "TCGA-24-1434         1.075179        -9.965784        -3.686641  ...   \n",
       "TCGA-29-1778        -0.749340        -9.965784        -3.338790  ...   \n",
       "TCGA-13-0920         0.039594        -9.965784         0.552783  ...   \n",
       "\n",
       "              ENSG00000231621  ENSG00000225472  ENSG00000231764  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-25-1315         5.178812        -6.200513        -2.085854   \n",
       "TCGA-24-0979         4.476964        -9.965784        -9.024147   \n",
       "TCGA-61-2008        -0.844354        -9.965784        -6.255257   \n",
       "TCGA-61-2109         1.443201        -6.440047        -5.218195   \n",
       "TCGA-25-1626         0.950276        -5.761374        -2.844205   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-31-1950        -9.965784        -5.578493        -6.175614   \n",
       "TCGA-13-0905         1.520381        -1.889686        -7.282487   \n",
       "TCGA-24-1434        -9.965784        -7.747252        -1.302654   \n",
       "TCGA-29-1778         2.573798        -5.062114        -7.074438   \n",
       "TCGA-13-0920         3.628496        -6.248567        -5.628717   \n",
       "\n",
       "              ENSG00000241388  ENSG00000233536  ENSG00000234692  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-25-1315        -7.030567        -9.965784        -0.625400   \n",
       "TCGA-24-0979        -8.052592        -9.965784        -2.166303   \n",
       "TCGA-61-2008        -8.119791        -9.965784        -4.048360   \n",
       "TCGA-61-2109        -8.049145         2.099915        -2.964156   \n",
       "TCGA-25-1626        -6.814008        -9.965784        -9.965784   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-31-1950        -6.963735        -3.011187        -9.965784   \n",
       "TCGA-13-0905        -8.072101        -4.675745        -2.414103   \n",
       "TCGA-24-1434        -7.203258        -9.965784        -2.904797   \n",
       "TCGA-29-1778        -8.583172        -4.438141        -9.965784   \n",
       "TCGA-13-0920        -5.229480        -2.465363         1.756960   \n",
       "\n",
       "              ENSG00000224717  ENSG00000262117  ENSG00000248646  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-25-1315        -0.932508        -1.614775        -9.965784   \n",
       "TCGA-24-0979        -6.218003        -5.713393        -7.978815   \n",
       "TCGA-61-2008        -1.680290        -9.965784        -9.965784   \n",
       "TCGA-61-2109        -3.310530        -9.965784        -9.965784   \n",
       "TCGA-25-1626        -3.647855        -1.859318        -9.965784   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-31-1950        -4.942857        -5.942840        -9.965784   \n",
       "TCGA-13-0905        -1.766353        -7.177194        -9.965784   \n",
       "TCGA-24-1434        -3.609945        -6.734171        -8.942039   \n",
       "TCGA-29-1778        -5.624848        -5.108739        -9.069619   \n",
       "TCGA-13-0920        -2.110243        -5.112208        -8.523270   \n",
       "\n",
       "              ENSG00000258170  \n",
       "PATIENT_ID                     \n",
       "TCGA-25-1315        -9.965784  \n",
       "TCGA-24-0979        -6.137611  \n",
       "TCGA-61-2008        -5.674618  \n",
       "TCGA-61-2109        -9.965784  \n",
       "TCGA-25-1626        -4.287891  \n",
       "...                       ...  \n",
       "TCGA-31-1950        -2.222087  \n",
       "TCGA-13-0905        -3.925545  \n",
       "TCGA-24-1434        -6.077553  \n",
       "TCGA-29-1778        -5.166117  \n",
       "TCGA-13-0920        -6.852636  \n",
       "\n",
       "[168 rows x 402 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train_platin_total_lnc_400_log.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLATINUM_STATUS</th>\n",
       "      <th>label</th>\n",
       "      <th>ENSG00000131096</th>\n",
       "      <th>ENSG00000187581</th>\n",
       "      <th>ENSG00000047936</th>\n",
       "      <th>ENSG00000186198</th>\n",
       "      <th>ENSG00000179914</th>\n",
       "      <th>ENSG00000186897</th>\n",
       "      <th>ENSG00000138136</th>\n",
       "      <th>ENSG00000139219</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000231621</th>\n",
       "      <th>ENSG00000225472</th>\n",
       "      <th>ENSG00000231764</th>\n",
       "      <th>ENSG00000241388</th>\n",
       "      <th>ENSG00000233536</th>\n",
       "      <th>ENSG00000234692</th>\n",
       "      <th>ENSG00000224717</th>\n",
       "      <th>ENSG00000262117</th>\n",
       "      <th>ENSG00000248646</th>\n",
       "      <th>ENSG00000258170</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1027</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.135284</td>\n",
       "      <td>-3.349095</td>\n",
       "      <td>-3.863475</td>\n",
       "      <td>-3.246019</td>\n",
       "      <td>-7.532949</td>\n",
       "      <td>-0.258138</td>\n",
       "      <td>-6.434488</td>\n",
       "      <td>-4.244782</td>\n",
       "      <td>...</td>\n",
       "      <td>1.625110</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.169082</td>\n",
       "      <td>-7.999968</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.762840</td>\n",
       "      <td>-6.195148</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.473947</td>\n",
       "      <td>-1.396137</td>\n",
       "      <td>-6.964441</td>\n",
       "      <td>-1.891926</td>\n",
       "      <td>-6.705484</td>\n",
       "      <td>1.140224</td>\n",
       "      <td>-5.532685</td>\n",
       "      <td>-1.031337</td>\n",
       "      <td>...</td>\n",
       "      <td>1.616526</td>\n",
       "      <td>-6.412237</td>\n",
       "      <td>-5.747777</td>\n",
       "      <td>-7.228279</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.497043</td>\n",
       "      <td>-1.194321</td>\n",
       "      <td>-5.840806</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.104939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.476657</td>\n",
       "      <td>-1.177117</td>\n",
       "      <td>-6.966923</td>\n",
       "      <td>-3.928615</td>\n",
       "      <td>-2.467021</td>\n",
       "      <td>0.327985</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.223210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134540</td>\n",
       "      <td>-5.597427</td>\n",
       "      <td>-8.153995</td>\n",
       "      <td>-7.711185</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.204239</td>\n",
       "      <td>-7.232189</td>\n",
       "      <td>-5.843480</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.158198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1122</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.735521</td>\n",
       "      <td>-0.658595</td>\n",
       "      <td>-2.085734</td>\n",
       "      <td>-4.534910</td>\n",
       "      <td>-0.325670</td>\n",
       "      <td>4.737879</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.939584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660026</td>\n",
       "      <td>-5.296299</td>\n",
       "      <td>-1.508721</td>\n",
       "      <td>-6.987275</td>\n",
       "      <td>-2.043833</td>\n",
       "      <td>-2.336167</td>\n",
       "      <td>-3.495986</td>\n",
       "      <td>-5.968097</td>\n",
       "      <td>-8.458205</td>\n",
       "      <td>-4.200967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1474</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.167001</td>\n",
       "      <td>-1.189044</td>\n",
       "      <td>-7.722494</td>\n",
       "      <td>-3.270644</td>\n",
       "      <td>-4.047874</td>\n",
       "      <td>-0.493115</td>\n",
       "      <td>-5.080759</td>\n",
       "      <td>-3.250298</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.050279</td>\n",
       "      <td>-1.962848</td>\n",
       "      <td>-6.970814</td>\n",
       "      <td>-7.324875</td>\n",
       "      <td>-4.726960</td>\n",
       "      <td>-4.035504</td>\n",
       "      <td>-2.662685</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.699211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-10-0927</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.488306</td>\n",
       "      <td>-2.955190</td>\n",
       "      <td>-6.264053</td>\n",
       "      <td>-4.698829</td>\n",
       "      <td>1.430639</td>\n",
       "      <td>0.653075</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.464706</td>\n",
       "      <td>...</td>\n",
       "      <td>2.036249</td>\n",
       "      <td>-7.755812</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.170059</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1914</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.093100</td>\n",
       "      <td>-0.684666</td>\n",
       "      <td>-5.571586</td>\n",
       "      <td>-1.231573</td>\n",
       "      <td>-3.907345</td>\n",
       "      <td>1.061018</td>\n",
       "      <td>-2.296048</td>\n",
       "      <td>-3.235534</td>\n",
       "      <td>...</td>\n",
       "      <td>4.319977</td>\n",
       "      <td>-7.669277</td>\n",
       "      <td>-5.358908</td>\n",
       "      <td>-4.248088</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.152473</td>\n",
       "      <td>-3.618159</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.601242</td>\n",
       "      <td>-0.924891</td>\n",
       "      <td>-4.594849</td>\n",
       "      <td>-2.106812</td>\n",
       "      <td>-1.743499</td>\n",
       "      <td>4.825219</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.882055</td>\n",
       "      <td>...</td>\n",
       "      <td>4.161422</td>\n",
       "      <td>-6.514948</td>\n",
       "      <td>-1.338677</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.468727</td>\n",
       "      <td>-4.158751</td>\n",
       "      <td>-6.332438</td>\n",
       "      <td>-8.700067</td>\n",
       "      <td>-4.480549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1365</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.551323</td>\n",
       "      <td>-0.008033</td>\n",
       "      <td>-0.929409</td>\n",
       "      <td>-1.582880</td>\n",
       "      <td>-3.801708</td>\n",
       "      <td>3.537387</td>\n",
       "      <td>-2.837690</td>\n",
       "      <td>-5.286824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526685</td>\n",
       "      <td>-5.660294</td>\n",
       "      <td>-2.012460</td>\n",
       "      <td>-7.574461</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.772033</td>\n",
       "      <td>-0.801980</td>\n",
       "      <td>-6.230265</td>\n",
       "      <td>-8.634323</td>\n",
       "      <td>-1.994469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.708171</td>\n",
       "      <td>-2.203823</td>\n",
       "      <td>-6.022474</td>\n",
       "      <td>2.767550</td>\n",
       "      <td>-1.279223</td>\n",
       "      <td>-1.196826</td>\n",
       "      <td>-5.098289</td>\n",
       "      <td>-3.313627</td>\n",
       "      <td>...</td>\n",
       "      <td>6.318637</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.814412</td>\n",
       "      <td>-6.835237</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>3.382064</td>\n",
       "      <td>-6.307883</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.475712</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.262830</td>\n",
       "      <td>-2.644489</td>\n",
       "      <td>-8.073254</td>\n",
       "      <td>-3.294209</td>\n",
       "      <td>-5.068846</td>\n",
       "      <td>-0.769463</td>\n",
       "      <td>-5.773507</td>\n",
       "      <td>-5.129563</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.040566</td>\n",
       "      <td>-8.642895</td>\n",
       "      <td>-6.574040</td>\n",
       "      <td>-7.440894</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.195324</td>\n",
       "      <td>-2.068094</td>\n",
       "      <td>-3.836864</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.316899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.567728</td>\n",
       "      <td>-8.598302</td>\n",
       "      <td>-4.177275</td>\n",
       "      <td>-2.979492</td>\n",
       "      <td>3.698936</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.522540</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.234882</td>\n",
       "      <td>-7.322346</td>\n",
       "      <td>-1.907811</td>\n",
       "      <td>-5.826696</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.955776</td>\n",
       "      <td>-4.080781</td>\n",
       "      <td>-2.664684</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1911</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.801399</td>\n",
       "      <td>5.379565</td>\n",
       "      <td>-3.035292</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.606509</td>\n",
       "      <td>-0.445973</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.547517</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.532345</td>\n",
       "      <td>-6.118453</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.203712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.811399</td>\n",
       "      <td>-3.763552</td>\n",
       "      <td>-6.888778</td>\n",
       "      <td>-3.946275</td>\n",
       "      <td>-2.263617</td>\n",
       "      <td>3.194416</td>\n",
       "      <td>-3.384300</td>\n",
       "      <td>-2.665941</td>\n",
       "      <td>...</td>\n",
       "      <td>2.831426</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.530020</td>\n",
       "      <td>-6.688895</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.299677</td>\n",
       "      <td>-1.503807</td>\n",
       "      <td>-6.579327</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-1667</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.037421</td>\n",
       "      <td>-1.477243</td>\n",
       "      <td>-5.480451</td>\n",
       "      <td>-3.907888</td>\n",
       "      <td>-2.353473</td>\n",
       "      <td>3.630566</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.173621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852002</td>\n",
       "      <td>-6.486455</td>\n",
       "      <td>-3.361388</td>\n",
       "      <td>-8.086388</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.329607</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2097</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.620647</td>\n",
       "      <td>-1.649955</td>\n",
       "      <td>-6.774663</td>\n",
       "      <td>-2.096747</td>\n",
       "      <td>-1.360455</td>\n",
       "      <td>0.678687</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.026336</td>\n",
       "      <td>...</td>\n",
       "      <td>1.026609</td>\n",
       "      <td>-7.505820</td>\n",
       "      <td>-7.908095</td>\n",
       "      <td>-1.523223</td>\n",
       "      <td>-3.884441</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.130839</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.915142</td>\n",
       "      <td>-1.952854</td>\n",
       "      <td>-7.042044</td>\n",
       "      <td>-2.219584</td>\n",
       "      <td>-1.374871</td>\n",
       "      <td>3.966679</td>\n",
       "      <td>-5.108911</td>\n",
       "      <td>-0.188307</td>\n",
       "      <td>...</td>\n",
       "      <td>1.853585</td>\n",
       "      <td>-5.611799</td>\n",
       "      <td>-7.351185</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.981764</td>\n",
       "      <td>-4.064168</td>\n",
       "      <td>0.326954</td>\n",
       "      <td>-4.857076</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.135781</td>\n",
       "      <td>-1.360696</td>\n",
       "      <td>-6.131941</td>\n",
       "      <td>-5.084959</td>\n",
       "      <td>-3.900372</td>\n",
       "      <td>2.755189</td>\n",
       "      <td>-3.380504</td>\n",
       "      <td>-3.845417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679456</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.412997</td>\n",
       "      <td>-8.000365</td>\n",
       "      <td>-2.607006</td>\n",
       "      <td>-2.898700</td>\n",
       "      <td>-3.369498</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.809331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0364</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.331558</td>\n",
       "      <td>-0.482149</td>\n",
       "      <td>-9.061469</td>\n",
       "      <td>-3.460954</td>\n",
       "      <td>4.295540</td>\n",
       "      <td>4.656240</td>\n",
       "      <td>0.378828</td>\n",
       "      <td>4.830801</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.410793</td>\n",
       "      <td>-6.013934</td>\n",
       "      <td>-4.988018</td>\n",
       "      <td>3.663039</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.826345</td>\n",
       "      <td>-0.083003</td>\n",
       "      <td>-5.179329</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.003728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1651</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.385625</td>\n",
       "      <td>-0.620920</td>\n",
       "      <td>-7.475802</td>\n",
       "      <td>-3.842155</td>\n",
       "      <td>-2.379734</td>\n",
       "      <td>2.916559</td>\n",
       "      <td>2.411221</td>\n",
       "      <td>-2.479541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808715</td>\n",
       "      <td>-6.477232</td>\n",
       "      <td>-3.897752</td>\n",
       "      <td>-6.279667</td>\n",
       "      <td>-4.997638</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.595784</td>\n",
       "      <td>-4.247031</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.323834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1551</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.990609</td>\n",
       "      <td>-2.715802</td>\n",
       "      <td>-7.501875</td>\n",
       "      <td>-5.432013</td>\n",
       "      <td>-1.243937</td>\n",
       "      <td>0.181422</td>\n",
       "      <td>-5.284135</td>\n",
       "      <td>-4.735738</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.847075</td>\n",
       "      <td>-8.313559</td>\n",
       "      <td>-5.405837</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>1.023982</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.840944</td>\n",
       "      <td>-6.526802</td>\n",
       "      <td>-8.820479</td>\n",
       "      <td>-3.348497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.975501</td>\n",
       "      <td>-2.871426</td>\n",
       "      <td>-6.380981</td>\n",
       "      <td>-1.439022</td>\n",
       "      <td>-1.756737</td>\n",
       "      <td>1.450781</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.253797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007535</td>\n",
       "      <td>-4.188832</td>\n",
       "      <td>-7.010814</td>\n",
       "      <td>-6.487202</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.743629</td>\n",
       "      <td>-8.904227</td>\n",
       "      <td>-3.861426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1104</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.175730</td>\n",
       "      <td>-3.193354</td>\n",
       "      <td>-7.254954</td>\n",
       "      <td>-2.878867</td>\n",
       "      <td>-4.468940</td>\n",
       "      <td>-4.205031</td>\n",
       "      <td>-2.231024</td>\n",
       "      <td>-2.945283</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.319104</td>\n",
       "      <td>-3.068391</td>\n",
       "      <td>-6.698340</td>\n",
       "      <td>-7.414495</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.305963</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.619818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1326</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.190773</td>\n",
       "      <td>0.311345</td>\n",
       "      <td>-3.911027</td>\n",
       "      <td>-2.643788</td>\n",
       "      <td>-0.981603</td>\n",
       "      <td>-0.253942</td>\n",
       "      <td>0.052961</td>\n",
       "      <td>-4.701179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884439</td>\n",
       "      <td>-8.289263</td>\n",
       "      <td>-6.069510</td>\n",
       "      <td>-7.470804</td>\n",
       "      <td>-0.354426</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.724002</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.869922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0916</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.194684</td>\n",
       "      <td>0.056495</td>\n",
       "      <td>-5.196392</td>\n",
       "      <td>-1.181472</td>\n",
       "      <td>3.174833</td>\n",
       "      <td>4.718977</td>\n",
       "      <td>-5.259590</td>\n",
       "      <td>-1.115561</td>\n",
       "      <td>...</td>\n",
       "      <td>1.616670</td>\n",
       "      <td>-0.970391</td>\n",
       "      <td>-8.625099</td>\n",
       "      <td>-6.982482</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.231261</td>\n",
       "      <td>-2.265448</td>\n",
       "      <td>-6.503606</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.382022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1487</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-2.311075</td>\n",
       "      <td>-2.150841</td>\n",
       "      <td>-3.267309</td>\n",
       "      <td>-4.171615</td>\n",
       "      <td>5.104629</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.359508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.797977</td>\n",
       "      <td>-7.965890</td>\n",
       "      <td>-4.535809</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.160266</td>\n",
       "      <td>0.599626</td>\n",
       "      <td>-7.890598</td>\n",
       "      <td>-3.205870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.328136</td>\n",
       "      <td>-2.976050</td>\n",
       "      <td>-5.030576</td>\n",
       "      <td>-3.420359</td>\n",
       "      <td>-0.714928</td>\n",
       "      <td>0.702410</td>\n",
       "      <td>-2.012813</td>\n",
       "      <td>-6.591022</td>\n",
       "      <td>...</td>\n",
       "      <td>1.095719</td>\n",
       "      <td>-7.772266</td>\n",
       "      <td>-8.792247</td>\n",
       "      <td>-7.230442</td>\n",
       "      <td>-3.635853</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.205659</td>\n",
       "      <td>-6.762672</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.755814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1576</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.917594</td>\n",
       "      <td>-3.529268</td>\n",
       "      <td>-1.463186</td>\n",
       "      <td>-1.103834</td>\n",
       "      <td>-3.410202</td>\n",
       "      <td>3.187083</td>\n",
       "      <td>-5.111430</td>\n",
       "      <td>-1.721228</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.347382</td>\n",
       "      <td>-7.416470</td>\n",
       "      <td>-7.353368</td>\n",
       "      <td>-7.351493</td>\n",
       "      <td>-4.757867</td>\n",
       "      <td>-1.764277</td>\n",
       "      <td>-0.853001</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.985530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0795</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.237610</td>\n",
       "      <td>2.280946</td>\n",
       "      <td>-9.236117</td>\n",
       "      <td>-4.119770</td>\n",
       "      <td>-4.542218</td>\n",
       "      <td>0.545868</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.568939</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.813417</td>\n",
       "      <td>-5.198417</td>\n",
       "      <td>-6.848035</td>\n",
       "      <td>-6.073774</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.825209</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.834766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-2078</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.718156</td>\n",
       "      <td>-1.718660</td>\n",
       "      <td>-3.642262</td>\n",
       "      <td>-1.168611</td>\n",
       "      <td>0.120778</td>\n",
       "      <td>3.326128</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.469243</td>\n",
       "      <td>...</td>\n",
       "      <td>1.076304</td>\n",
       "      <td>-6.263393</td>\n",
       "      <td>-1.587628</td>\n",
       "      <td>-6.396159</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.999693</td>\n",
       "      <td>1.549778</td>\n",
       "      <td>-5.341713</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.695382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.414647</td>\n",
       "      <td>-4.205291</td>\n",
       "      <td>-8.725524</td>\n",
       "      <td>-4.644063</td>\n",
       "      <td>-6.924859</td>\n",
       "      <td>-6.151077</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.729260</td>\n",
       "      <td>...</td>\n",
       "      <td>2.255896</td>\n",
       "      <td>-8.639080</td>\n",
       "      <td>-3.012397</td>\n",
       "      <td>-7.900839</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.382201</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.546488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1770</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.640145</td>\n",
       "      <td>-1.056776</td>\n",
       "      <td>-2.844994</td>\n",
       "      <td>-2.651134</td>\n",
       "      <td>-2.928355</td>\n",
       "      <td>1.255398</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.292495</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.859571</td>\n",
       "      <td>-4.836744</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.767830</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.570187</td>\n",
       "      <td>-6.410987</td>\n",
       "      <td>-6.826973</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.564831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-2290</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.141208</td>\n",
       "      <td>-1.267232</td>\n",
       "      <td>-6.952398</td>\n",
       "      <td>-4.333620</td>\n",
       "      <td>-3.866081</td>\n",
       "      <td>-0.061817</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.469716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.717227</td>\n",
       "      <td>-7.455014</td>\n",
       "      <td>-5.978654</td>\n",
       "      <td>-8.166628</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.125087</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.468362</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0726</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.818757</td>\n",
       "      <td>-2.716895</td>\n",
       "      <td>-9.449899</td>\n",
       "      <td>-5.433066</td>\n",
       "      <td>-6.089245</td>\n",
       "      <td>-1.577451</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.147749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370134</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.377823</td>\n",
       "      <td>-6.259124</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.257640</td>\n",
       "      <td>-2.030094</td>\n",
       "      <td>-4.631262</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.765299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.776365</td>\n",
       "      <td>-0.394267</td>\n",
       "      <td>-5.214028</td>\n",
       "      <td>-2.572961</td>\n",
       "      <td>-3.989627</td>\n",
       "      <td>3.193427</td>\n",
       "      <td>-5.277196</td>\n",
       "      <td>-0.690801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.672829</td>\n",
       "      <td>-5.616320</td>\n",
       "      <td>-8.636153</td>\n",
       "      <td>-7.494022</td>\n",
       "      <td>-3.369557</td>\n",
       "      <td>-1.451878</td>\n",
       "      <td>0.751621</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.854994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0366</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.768672</td>\n",
       "      <td>-0.648797</td>\n",
       "      <td>-5.553624</td>\n",
       "      <td>-3.724166</td>\n",
       "      <td>-0.402219</td>\n",
       "      <td>-0.603754</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.695766</td>\n",
       "      <td>...</td>\n",
       "      <td>2.830987</td>\n",
       "      <td>-6.556097</td>\n",
       "      <td>-1.827696</td>\n",
       "      <td>-6.329760</td>\n",
       "      <td>-4.769472</td>\n",
       "      <td>-0.400699</td>\n",
       "      <td>-5.641650</td>\n",
       "      <td>-5.125805</td>\n",
       "      <td>-9.216894</td>\n",
       "      <td>-5.703653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1924</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.454053</td>\n",
       "      <td>-0.537846</td>\n",
       "      <td>-3.739532</td>\n",
       "      <td>-3.556274</td>\n",
       "      <td>-0.914319</td>\n",
       "      <td>0.683608</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-5.234409</td>\n",
       "      <td>...</td>\n",
       "      <td>1.363402</td>\n",
       "      <td>-3.921665</td>\n",
       "      <td>-6.993245</td>\n",
       "      <td>-6.991289</td>\n",
       "      <td>-2.560430</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-3.586975</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.766490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1105</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.205241</td>\n",
       "      <td>5.842965</td>\n",
       "      <td>-5.005040</td>\n",
       "      <td>-2.509512</td>\n",
       "      <td>-2.297939</td>\n",
       "      <td>2.092752</td>\n",
       "      <td>-6.070529</td>\n",
       "      <td>-5.645512</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.352385</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.535594</td>\n",
       "      <td>-7.696966</td>\n",
       "      <td>-5.727605</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-0.954633</td>\n",
       "      <td>-5.122701</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-20-1683</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.267341</td>\n",
       "      <td>-2.075703</td>\n",
       "      <td>-3.415195</td>\n",
       "      <td>-3.032956</td>\n",
       "      <td>-6.791958</td>\n",
       "      <td>2.890300</td>\n",
       "      <td>1.003198</td>\n",
       "      <td>-5.933300</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>0.834930</td>\n",
       "      <td>1.362927</td>\n",
       "      <td>-6.953596</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-4.591678</td>\n",
       "      <td>-4.212386</td>\n",
       "      <td>-4.976696</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.582654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1733</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.882479</td>\n",
       "      <td>0.144705</td>\n",
       "      <td>-8.525393</td>\n",
       "      <td>-4.062100</td>\n",
       "      <td>-5.143706</td>\n",
       "      <td>-0.946209</td>\n",
       "      <td>-4.888808</td>\n",
       "      <td>-3.053828</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.427391</td>\n",
       "      <td>-7.223264</td>\n",
       "      <td>-7.158568</td>\n",
       "      <td>-6.641985</td>\n",
       "      <td>-3.550445</td>\n",
       "      <td>-1.535010</td>\n",
       "      <td>-0.663973</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-8.582028</td>\n",
       "      <td>-6.935538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-1665</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.643120</td>\n",
       "      <td>6.530100</td>\n",
       "      <td>-3.274282</td>\n",
       "      <td>-4.246070</td>\n",
       "      <td>-2.729482</td>\n",
       "      <td>-1.354995</td>\n",
       "      <td>-6.022530</td>\n",
       "      <td>-4.574518</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.167627</td>\n",
       "      <td>-7.380990</td>\n",
       "      <td>-0.998084</td>\n",
       "      <td>-6.138712</td>\n",
       "      <td>-3.156867</td>\n",
       "      <td>-2.042476</td>\n",
       "      <td>-1.409159</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-6.581066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1571</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.954022</td>\n",
       "      <td>4.215384</td>\n",
       "      <td>-4.737070</td>\n",
       "      <td>0.648844</td>\n",
       "      <td>-5.705893</td>\n",
       "      <td>3.933821</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>1.165764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970138</td>\n",
       "      <td>-8.432723</td>\n",
       "      <td>-6.267931</td>\n",
       "      <td>-5.718388</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-1.123653</td>\n",
       "      <td>0.438098</td>\n",
       "      <td>-6.687729</td>\n",
       "      <td>-9.965784</td>\n",
       "      <td>-7.436983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PLATINUM_STATUS  label  ENSG00000131096  ENSG00000187581  \\\n",
       "PATIENT_ID                                                              \n",
       "TCGA-23-1027       Resistant    1.0        -6.135284        -3.349095   \n",
       "TCGA-36-1580       Resistant    1.0        -5.473947        -1.396137   \n",
       "TCGA-29-1769       Sensitive    0.0        -5.476657        -1.177117   \n",
       "TCGA-23-1122       Sensitive    0.0        -4.735521        -0.658595   \n",
       "TCGA-24-1474       Sensitive    0.0        -7.167001        -1.189044   \n",
       "TCGA-10-0927       Sensitive    0.0        -4.488306        -2.955190   \n",
       "TCGA-61-1914       Sensitive    0.0        -2.093100        -0.684666   \n",
       "TCGA-29-1703       Resistant    1.0        -0.601242        -0.924891   \n",
       "TCGA-04-1365       Sensitive    0.0        -6.551323        -0.008033   \n",
       "TCGA-29-1696       Resistant    1.0        -3.708171        -2.203823   \n",
       "TCGA-13-1483       Resistant    1.0        -6.262830        -2.644489   \n",
       "TCGA-61-1738       Resistant    1.0        -9.965784         0.567728   \n",
       "TCGA-61-1911       Sensitive    0.0        -5.801399         5.379565   \n",
       "TCGA-25-2393       Resistant    1.0        -4.811399        -3.763552   \n",
       "TCGA-09-1667       Sensitive    0.0        -6.037421        -1.477243   \n",
       "TCGA-61-2097       Sensitive    0.0        -4.620647        -1.649955   \n",
       "TCGA-29-2414       Sensitive    0.0        -5.915142        -1.952854   \n",
       "TCGA-24-1563       Sensitive    0.0        -6.135781        -1.360696   \n",
       "TCGA-09-0364       Sensitive    0.0        -1.331558        -0.482149   \n",
       "TCGA-04-1651       Sensitive    0.0        -5.385625        -0.620920   \n",
       "TCGA-24-1551       Sensitive    0.0        -6.990609        -2.715802   \n",
       "TCGA-13-0893       Resistant    1.0        -4.975501        -2.871426   \n",
       "TCGA-24-1104       Sensitive    0.0        -8.175730        -3.193354   \n",
       "TCGA-25-1326       Sensitive    0.0        -5.190773         0.311345   \n",
       "TCGA-13-0916       Sensitive    0.0        -2.194684         0.056495   \n",
       "TCGA-13-1487       Sensitive    0.0        -9.965784        -2.311075   \n",
       "TCGA-13-1403       Sensitive    0.0        -6.328136        -2.976050   \n",
       "TCGA-36-1576       Sensitive    0.0        -5.917594        -3.529268   \n",
       "TCGA-13-0795       Resistant    1.0        -6.237610         2.280946   \n",
       "TCGA-23-2078       Sensitive    0.0        -8.718156        -1.718660   \n",
       "TCGA-09-2056       Sensitive    0.0        -4.414647        -4.205291   \n",
       "TCGA-29-1770       Sensitive    0.0        -5.640145        -1.056776   \n",
       "TCGA-24-2290       Sensitive    0.0        -6.141208        -1.267232   \n",
       "TCGA-13-0726       Sensitive    0.0        -7.818757        -2.716895   \n",
       "TCGA-25-1628       Resistant    1.0        -5.776365        -0.394267   \n",
       "TCGA-09-0366       Resistant    1.0        -5.768672        -0.648797   \n",
       "TCGA-24-1924       Resistant    1.0        -6.454053        -0.537846   \n",
       "TCGA-24-1105       Sensitive    0.0        -6.205241         5.842965   \n",
       "TCGA-20-1683       Sensitive    0.0        -4.267341        -2.075703   \n",
       "TCGA-61-1733       Resistant    1.0        -5.882479         0.144705   \n",
       "TCGA-09-1665       Sensitive    0.0        -7.643120         6.530100   \n",
       "TCGA-36-1571       Sensitive    0.0        -7.954022         4.215384   \n",
       "\n",
       "              ENSG00000047936  ENSG00000186198  ENSG00000179914  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-23-1027        -3.863475        -3.246019        -7.532949   \n",
       "TCGA-36-1580        -6.964441        -1.891926        -6.705484   \n",
       "TCGA-29-1769        -6.966923        -3.928615        -2.467021   \n",
       "TCGA-23-1122        -2.085734        -4.534910        -0.325670   \n",
       "TCGA-24-1474        -7.722494        -3.270644        -4.047874   \n",
       "TCGA-10-0927        -6.264053        -4.698829         1.430639   \n",
       "TCGA-61-1914        -5.571586        -1.231573        -3.907345   \n",
       "TCGA-29-1703        -4.594849        -2.106812        -1.743499   \n",
       "TCGA-04-1365        -0.929409        -1.582880        -3.801708   \n",
       "TCGA-29-1696        -6.022474         2.767550        -1.279223   \n",
       "TCGA-13-1483        -8.073254        -3.294209        -5.068846   \n",
       "TCGA-61-1738        -8.598302        -4.177275        -2.979492   \n",
       "TCGA-61-1911        -3.035292        -9.965784        -3.606509   \n",
       "TCGA-25-2393        -6.888778        -3.946275        -2.263617   \n",
       "TCGA-09-1667        -5.480451        -3.907888        -2.353473   \n",
       "TCGA-61-2097        -6.774663        -2.096747        -1.360455   \n",
       "TCGA-29-2414        -7.042044        -2.219584        -1.374871   \n",
       "TCGA-24-1563        -6.131941        -5.084959        -3.900372   \n",
       "TCGA-09-0364        -9.061469        -3.460954         4.295540   \n",
       "TCGA-04-1651        -7.475802        -3.842155        -2.379734   \n",
       "TCGA-24-1551        -7.501875        -5.432013        -1.243937   \n",
       "TCGA-13-0893        -6.380981        -1.439022        -1.756737   \n",
       "TCGA-24-1104        -7.254954        -2.878867        -4.468940   \n",
       "TCGA-25-1326        -3.911027        -2.643788        -0.981603   \n",
       "TCGA-13-0916        -5.196392        -1.181472         3.174833   \n",
       "TCGA-13-1487        -2.150841        -3.267309        -4.171615   \n",
       "TCGA-13-1403        -5.030576        -3.420359        -0.714928   \n",
       "TCGA-36-1576        -1.463186        -1.103834        -3.410202   \n",
       "TCGA-13-0795        -9.236117        -4.119770        -4.542218   \n",
       "TCGA-23-2078        -3.642262        -1.168611         0.120778   \n",
       "TCGA-09-2056        -8.725524        -4.644063        -6.924859   \n",
       "TCGA-29-1770        -2.844994        -2.651134        -2.928355   \n",
       "TCGA-24-2290        -6.952398        -4.333620        -3.866081   \n",
       "TCGA-13-0726        -9.449899        -5.433066        -6.089245   \n",
       "TCGA-25-1628        -5.214028        -2.572961        -3.989627   \n",
       "TCGA-09-0366        -5.553624        -3.724166        -0.402219   \n",
       "TCGA-24-1924        -3.739532        -3.556274        -0.914319   \n",
       "TCGA-24-1105        -5.005040        -2.509512        -2.297939   \n",
       "TCGA-20-1683        -3.415195        -3.032956        -6.791958   \n",
       "TCGA-61-1733        -8.525393        -4.062100        -5.143706   \n",
       "TCGA-09-1665        -3.274282        -4.246070        -2.729482   \n",
       "TCGA-36-1571        -4.737070         0.648844        -5.705893   \n",
       "\n",
       "              ENSG00000186897  ENSG00000138136  ENSG00000139219  ...  \\\n",
       "PATIENT_ID                                                       ...   \n",
       "TCGA-23-1027        -0.258138        -6.434488        -4.244782  ...   \n",
       "TCGA-36-1580         1.140224        -5.532685        -1.031337  ...   \n",
       "TCGA-29-1769         0.327985        -9.965784        -5.223210  ...   \n",
       "TCGA-23-1122         4.737879        -9.965784         0.939584  ...   \n",
       "TCGA-24-1474        -0.493115        -5.080759        -3.250298  ...   \n",
       "TCGA-10-0927         0.653075        -9.965784         0.464706  ...   \n",
       "TCGA-61-1914         1.061018        -2.296048        -3.235534  ...   \n",
       "TCGA-29-1703         4.825219        -9.965784        -1.882055  ...   \n",
       "TCGA-04-1365         3.537387        -2.837690        -5.286824  ...   \n",
       "TCGA-29-1696        -1.196826        -5.098289        -3.313627  ...   \n",
       "TCGA-13-1483        -0.769463        -5.773507        -5.129563  ...   \n",
       "TCGA-61-1738         3.698936        -9.965784        -3.522540  ...   \n",
       "TCGA-61-1911        -0.445973        -9.965784        -9.965784  ...   \n",
       "TCGA-25-2393         3.194416        -3.384300        -2.665941  ...   \n",
       "TCGA-09-1667         3.630566        -9.965784        -3.173621  ...   \n",
       "TCGA-61-2097         0.678687        -9.965784        -1.026336  ...   \n",
       "TCGA-29-2414         3.966679        -5.108911        -0.188307  ...   \n",
       "TCGA-24-1563         2.755189        -3.380504        -3.845417  ...   \n",
       "TCGA-09-0364         4.656240         0.378828         4.830801  ...   \n",
       "TCGA-04-1651         2.916559         2.411221        -2.479541  ...   \n",
       "TCGA-24-1551         0.181422        -5.284135        -4.735738  ...   \n",
       "TCGA-13-0893         1.450781        -9.965784        -5.253797  ...   \n",
       "TCGA-24-1104        -4.205031        -2.231024        -2.945283  ...   \n",
       "TCGA-25-1326        -0.253942         0.052961        -4.701179  ...   \n",
       "TCGA-13-0916         4.718977        -5.259590        -1.115561  ...   \n",
       "TCGA-13-1487         5.104629        -9.965784        -6.359508  ...   \n",
       "TCGA-13-1403         0.702410        -2.012813        -6.591022  ...   \n",
       "TCGA-36-1576         3.187083        -5.111430        -1.721228  ...   \n",
       "TCGA-13-0795         0.545868        -9.965784        -5.568939  ...   \n",
       "TCGA-23-2078         3.326128        -9.965784        -1.469243  ...   \n",
       "TCGA-09-2056        -6.151077        -9.965784        -1.729260  ...   \n",
       "TCGA-29-1770         1.255398        -9.965784        -5.292495  ...   \n",
       "TCGA-24-2290        -0.061817        -9.965784        -5.469716  ...   \n",
       "TCGA-13-0726        -1.577451        -9.965784        -6.147749  ...   \n",
       "TCGA-25-1628         3.193427        -5.277196        -0.690801  ...   \n",
       "TCGA-09-0366        -0.603754        -9.965784        -1.695766  ...   \n",
       "TCGA-24-1924         0.683608        -9.965784        -5.234409  ...   \n",
       "TCGA-24-1105         2.092752        -6.070529        -5.645512  ...   \n",
       "TCGA-20-1683         2.890300         1.003198        -5.933300  ...   \n",
       "TCGA-61-1733        -0.946209        -4.888808        -3.053828  ...   \n",
       "TCGA-09-1665        -1.354995        -6.022530        -4.574518  ...   \n",
       "TCGA-36-1571         3.933821        -9.965784         1.165764  ...   \n",
       "\n",
       "              ENSG00000231621  ENSG00000225472  ENSG00000231764  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-23-1027         1.625110        -9.965784        -6.169082   \n",
       "TCGA-36-1580         1.616526        -6.412237        -5.747777   \n",
       "TCGA-29-1769         0.134540        -5.597427        -8.153995   \n",
       "TCGA-23-1122        -0.660026        -5.296299        -1.508721   \n",
       "TCGA-24-1474        -2.050279        -1.962848        -6.970814   \n",
       "TCGA-10-0927         2.036249        -7.755812        -9.965784   \n",
       "TCGA-61-1914         4.319977        -7.669277        -5.358908   \n",
       "TCGA-29-1703         4.161422        -6.514948        -1.338677   \n",
       "TCGA-04-1365        -0.526685        -5.660294        -2.012460   \n",
       "TCGA-29-1696         6.318637        -9.965784        -7.814412   \n",
       "TCGA-13-1483        -1.040566        -8.642895        -6.574040   \n",
       "TCGA-61-1738        -1.234882        -7.322346        -1.907811   \n",
       "TCGA-61-1911        -0.547517        -9.965784        -1.532345   \n",
       "TCGA-25-2393         2.831426        -9.965784        -2.530020   \n",
       "TCGA-09-1667         0.852002        -6.486455        -3.361388   \n",
       "TCGA-61-2097         1.026609        -7.505820        -7.908095   \n",
       "TCGA-29-2414         1.853585        -5.611799        -7.351185   \n",
       "TCGA-24-1563         0.679456        -9.965784        -8.412997   \n",
       "TCGA-09-0364        -2.410793        -6.013934        -4.988018   \n",
       "TCGA-04-1651         0.808715        -6.477232        -3.897752   \n",
       "TCGA-24-1551        -1.847075        -8.313559        -5.405837   \n",
       "TCGA-13-0893        -0.007535        -4.188832        -7.010814   \n",
       "TCGA-24-1104        -3.319104        -3.068391        -6.698340   \n",
       "TCGA-25-1326         0.884439        -8.289263        -6.069510   \n",
       "TCGA-13-0916         1.616670        -0.970391        -8.625099   \n",
       "TCGA-13-1487         0.947849        -9.965784        -6.797977   \n",
       "TCGA-13-1403         1.095719        -7.772266        -8.792247   \n",
       "TCGA-36-1576        -1.347382        -7.416470        -7.353368   \n",
       "TCGA-13-0795        -2.813417        -5.198417        -6.848035   \n",
       "TCGA-23-2078         1.076304        -6.263393        -1.587628   \n",
       "TCGA-09-2056         2.255896        -8.639080        -3.012397   \n",
       "TCGA-29-1770        -1.859571        -4.836744        -9.965784   \n",
       "TCGA-24-2290        -0.717227        -7.455014        -5.978654   \n",
       "TCGA-13-0726         0.370134        -9.965784        -8.377823   \n",
       "TCGA-25-1628        -0.672829        -5.616320        -8.636153   \n",
       "TCGA-09-0366         2.830987        -6.556097        -1.827696   \n",
       "TCGA-24-1924         1.363402        -3.921665        -6.993245   \n",
       "TCGA-24-1105        -2.352385        -9.965784        -8.535594   \n",
       "TCGA-20-1683        -9.965784         0.834930         1.362927   \n",
       "TCGA-61-1733        -3.427391        -7.223264        -7.158568   \n",
       "TCGA-09-1665        -1.167627        -7.380990        -0.998084   \n",
       "TCGA-36-1571         0.970138        -8.432723        -6.267931   \n",
       "\n",
       "              ENSG00000241388  ENSG00000233536  ENSG00000234692  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-23-1027        -7.999968        -9.965784        -9.965784   \n",
       "TCGA-36-1580        -7.228279        -9.965784        -4.497043   \n",
       "TCGA-29-1769        -7.711185        -9.965784        -2.204239   \n",
       "TCGA-23-1122        -6.987275        -2.043833        -2.336167   \n",
       "TCGA-24-1474        -7.324875        -4.726960        -4.035504   \n",
       "TCGA-10-0927        -9.965784        -9.965784        -9.965784   \n",
       "TCGA-61-1914        -4.248088        -9.965784        -0.152473   \n",
       "TCGA-29-1703        -9.965784        -9.965784        -1.468727   \n",
       "TCGA-04-1365        -7.574461        -9.965784        -1.772033   \n",
       "TCGA-29-1696        -6.835237        -9.965784         3.382064   \n",
       "TCGA-13-1483        -7.440894        -9.965784        -1.195324   \n",
       "TCGA-61-1738        -5.826696        -9.965784        -3.955776   \n",
       "TCGA-61-1911        -6.118453        -9.965784        -9.965784   \n",
       "TCGA-25-2393        -6.688895        -9.965784        -4.299677   \n",
       "TCGA-09-1667        -8.086388        -9.965784        -9.965784   \n",
       "TCGA-61-2097        -1.523223        -3.884441        -9.965784   \n",
       "TCGA-29-2414        -9.965784        -1.981764        -4.064168   \n",
       "TCGA-24-1563        -8.000365        -2.607006        -2.898700   \n",
       "TCGA-09-0364         3.663039        -9.965784        -2.826345   \n",
       "TCGA-04-1651        -6.279667        -4.997638        -9.965784   \n",
       "TCGA-24-1551        -9.965784         1.023982        -9.965784   \n",
       "TCGA-13-0893        -6.487202        -9.965784        -9.965784   \n",
       "TCGA-24-1104        -7.414495        -9.965784        -9.965784   \n",
       "TCGA-25-1326        -7.470804        -0.354426        -9.965784   \n",
       "TCGA-13-0916        -6.982482        -9.965784        -3.231261   \n",
       "TCGA-13-1487        -7.965890        -4.535809        -9.965784   \n",
       "TCGA-13-1403        -7.230442        -3.635853        -9.965784   \n",
       "TCGA-36-1576        -7.351493        -4.757867        -1.764277   \n",
       "TCGA-13-0795        -6.073774        -9.965784        -9.965784   \n",
       "TCGA-23-2078        -6.396159        -9.965784        -1.999693   \n",
       "TCGA-09-2056        -7.900839        -9.965784        -9.965784   \n",
       "TCGA-29-1770        -7.767830        -9.965784        -4.570187   \n",
       "TCGA-24-2290        -8.166628        -9.965784        -3.125087   \n",
       "TCGA-13-0726        -6.259124        -9.965784        -3.257640   \n",
       "TCGA-25-1628        -7.494022        -3.369557        -1.451878   \n",
       "TCGA-09-0366        -6.329760        -4.769472        -0.400699   \n",
       "TCGA-24-1924        -6.991289        -2.560430        -9.965784   \n",
       "TCGA-24-1105        -7.696966        -5.727605        -9.965784   \n",
       "TCGA-20-1683        -6.953596        -9.965784        -4.591678   \n",
       "TCGA-61-1733        -6.641985        -3.550445        -1.535010   \n",
       "TCGA-09-1665        -6.138712        -3.156867        -2.042476   \n",
       "TCGA-36-1571        -5.718388        -9.965784        -1.123653   \n",
       "\n",
       "              ENSG00000224717  ENSG00000262117  ENSG00000248646  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-23-1027        -5.762840        -6.195148        -9.965784   \n",
       "TCGA-36-1580        -1.194321        -5.840806        -9.965784   \n",
       "TCGA-29-1769        -7.232189        -5.843480        -9.965784   \n",
       "TCGA-23-1122        -3.495986        -5.968097        -8.458205   \n",
       "TCGA-24-1474        -2.662685        -9.965784        -9.965784   \n",
       "TCGA-10-0927         0.170059        -9.965784        -9.965784   \n",
       "TCGA-61-1914        -3.618159        -9.965784        -9.965784   \n",
       "TCGA-29-1703        -4.158751        -6.332438        -8.700067   \n",
       "TCGA-04-1365        -0.801980        -6.230265        -8.634323   \n",
       "TCGA-29-1696        -6.307883        -9.965784        -5.475712   \n",
       "TCGA-13-1483        -2.068094        -3.836864        -9.965784   \n",
       "TCGA-61-1738        -4.080781        -2.664684        -9.965784   \n",
       "TCGA-61-1911        -9.965784        -9.965784        -9.965784   \n",
       "TCGA-25-2393        -1.503807        -6.579327        -9.965784   \n",
       "TCGA-09-1667        -0.329607        -9.965784        -9.965784   \n",
       "TCGA-61-2097        -1.130839        -9.965784        -9.965784   \n",
       "TCGA-29-2414         0.326954        -4.857076        -9.965784   \n",
       "TCGA-24-1563        -3.369498        -9.965784        -9.965784   \n",
       "TCGA-09-0364        -0.083003        -5.179329        -9.965784   \n",
       "TCGA-04-1651        -1.595784        -4.247031        -9.965784   \n",
       "TCGA-24-1551        -4.840944        -6.526802        -8.820479   \n",
       "TCGA-13-0893        -9.965784        -5.743629        -8.904227   \n",
       "TCGA-24-1104        -5.305963        -9.965784        -9.965784   \n",
       "TCGA-25-1326        -0.724002        -9.965784        -9.965784   \n",
       "TCGA-13-0916        -2.265448        -6.503606        -9.965784   \n",
       "TCGA-13-1487        -5.160266         0.599626        -7.890598   \n",
       "TCGA-13-1403        -3.205659        -6.762672        -9.965784   \n",
       "TCGA-36-1576        -0.853001        -9.965784        -9.965784   \n",
       "TCGA-13-0795        -9.965784        -1.825209        -9.965784   \n",
       "TCGA-23-2078         1.549778        -5.341713        -9.965784   \n",
       "TCGA-09-2056         0.382201        -9.965784        -9.965784   \n",
       "TCGA-29-1770        -6.410987        -6.826973        -9.965784   \n",
       "TCGA-24-2290        -9.965784        -5.468362        -9.965784   \n",
       "TCGA-13-0726        -2.030094        -4.631262        -9.965784   \n",
       "TCGA-25-1628         0.751621        -9.965784        -9.965784   \n",
       "TCGA-09-0366        -5.641650        -5.125805        -9.216894   \n",
       "TCGA-24-1924        -3.586975        -9.965784        -9.965784   \n",
       "TCGA-24-1105        -0.954633        -5.122701        -9.965784   \n",
       "TCGA-20-1683        -4.212386        -4.976696        -9.965784   \n",
       "TCGA-61-1733        -0.663973        -9.965784        -8.582028   \n",
       "TCGA-09-1665        -1.409159        -9.965784        -9.965784   \n",
       "TCGA-36-1571         0.438098        -6.687729        -9.965784   \n",
       "\n",
       "              ENSG00000258170  \n",
       "PATIENT_ID                     \n",
       "TCGA-23-1027        -9.965784  \n",
       "TCGA-36-1580        -6.104939  \n",
       "TCGA-29-1769        -5.158198  \n",
       "TCGA-23-1122        -4.200967  \n",
       "TCGA-24-1474        -4.699211  \n",
       "TCGA-10-0927        -9.965784  \n",
       "TCGA-61-1914        -9.965784  \n",
       "TCGA-29-1703        -4.480549  \n",
       "TCGA-04-1365        -1.994469  \n",
       "TCGA-29-1696        -9.965784  \n",
       "TCGA-13-1483        -4.316899  \n",
       "TCGA-61-1738        -9.965784  \n",
       "TCGA-61-1911        -4.203712  \n",
       "TCGA-25-2393        -9.965784  \n",
       "TCGA-09-1667        -9.965784  \n",
       "TCGA-61-2097        -9.965784  \n",
       "TCGA-29-2414        -9.965784  \n",
       "TCGA-24-1563        -4.809331  \n",
       "TCGA-09-0364        -6.003728  \n",
       "TCGA-04-1651        -4.323834  \n",
       "TCGA-24-1551        -3.348497  \n",
       "TCGA-13-0893        -3.861426  \n",
       "TCGA-24-1104        -5.619818  \n",
       "TCGA-25-1326        -4.869922  \n",
       "TCGA-13-0916        -6.382022  \n",
       "TCGA-13-1487        -3.205870  \n",
       "TCGA-13-1403        -4.755814  \n",
       "TCGA-36-1576        -4.985530  \n",
       "TCGA-13-0795        -5.834766  \n",
       "TCGA-23-2078        -6.695382  \n",
       "TCGA-09-2056        -4.546488  \n",
       "TCGA-29-1770        -7.564831  \n",
       "TCGA-24-2290        -9.965784  \n",
       "TCGA-13-0726        -7.765299  \n",
       "TCGA-25-1628        -5.854994  \n",
       "TCGA-09-0366        -5.703653  \n",
       "TCGA-24-1924        -6.766490  \n",
       "TCGA-24-1105        -9.965784  \n",
       "TCGA-20-1683        -7.582654  \n",
       "TCGA-61-1733        -6.935538  \n",
       "TCGA-09-1665        -6.581066  \n",
       "TCGA-36-1571        -7.436983  \n",
       "\n",
       "[42 rows x 402 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv(\"val_platin_total_lnc_400_log.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv(\"train_platin_total_lnc_400.csv\")\n",
    "#val = pd.read_csv(\"val_platin_total_lnc_400.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_platin_total_lnc_400_log.csv\")\n",
    "val = pd.read_csv(\"val_platin_total_lnc_400_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label = val['PATIENT_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of Training Data\n",
      "Samples : 168\n",
      "Features : 400\n"
     ]
    }
   ],
   "source": [
    "trn_X_pd = train.drop([\"PATIENT_ID\",\"PLATINUM_STATUS\",\"label\"],axis=1).values\n",
    "trn_y_pd = train.label.values\n",
    "\n",
    "print(\"Information of Training Data\")\n",
    "print(\"Samples : {}\".format(trn_X_pd.shape[0]))\n",
    "print(\"Features : {}\".format(trn_X_pd.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of Training Data\n",
      "Samples : 42\n",
      "Features : 400\n"
     ]
    }
   ],
   "source": [
    "val_X_pd = val.drop([\"PATIENT_ID\",\"PLATINUM_STATUS\",\"label\"],axis=1).values\n",
    "val_y_pd = val.label.values\n",
    "\n",
    "print(\"Information of Training Data\")\n",
    "print(\"Samples : {}\".format(val_X_pd.shape[0]))\n",
    "print(\"Features : {}\".format(val_X_pd.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "29\n",
      "48\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "item = []\n",
    "item_2 = []\n",
    "\n",
    "print( (val_y_pd == 1.0).sum())\n",
    "print( (val_y_pd == 0.0).sum())\n",
    "\n",
    "print( (trn_y_pd == 1.0).sum())\n",
    "print( (trn_y_pd == 0.0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([  1,   4,   6,   7,  10,  11,  12,  13,  14,  15,  16,  17,  18,\n",
       "          19,  20,  22,  23,  27,  28,  29,  30,  31,  33,  34,  36,  37,\n",
       "          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  49,  50,  52,\n",
       "          53,  54,  55,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,\n",
       "          68,  70,  72,  73,  74,  76,  78,  79,  80,  81,  82,  83,  84,\n",
       "          87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  98,  99, 100,\n",
       "         101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114,\n",
       "         115, 116, 117, 118, 119, 120, 122, 124, 126, 127, 128, 129, 130,\n",
       "         131, 132, 134, 135, 137, 138, 139, 141, 142, 143, 144, 145, 146,\n",
       "         147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n",
       "         162, 163, 164, 166]),\n",
       "  array([  0,   2,   3,   5,   8,   9,  21,  24,  25,  26,  32,  35,  48,\n",
       "          51,  56,  57,  69,  71,  75,  77,  85,  86,  97, 109, 121, 123,\n",
       "         125, 133, 136, 140, 160, 161, 165, 167])),\n",
       " (array([  0,   1,   2,   3,   5,   6,   7,   8,   9,  10,  12,  13,  14,\n",
       "          15,  16,  17,  20,  21,  22,  23,  24,  25,  26,  27,  29,  32,\n",
       "          33,  34,  35,  36,  37,  38,  40,  41,  42,  45,  46,  48,  49,\n",
       "          50,  51,  52,  53,  54,  55,  56,  57,  60,  61,  62,  63,  64,\n",
       "          65,  67,  68,  69,  70,  71,  72,  73,  75,  76,  77,  79,  80,\n",
       "          81,  82,  83,  85,  86,  87,  88,  89,  90,  92,  93,  94,  96,\n",
       "          97,  99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 111, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         133, 134, 135, 136, 137, 138, 139, 140, 142, 143, 144, 145, 147,\n",
       "         148, 149, 151, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163,\n",
       "         164, 165, 166, 167]),\n",
       "  array([  4,  11,  18,  19,  28,  30,  31,  39,  43,  44,  47,  58,  59,\n",
       "          66,  74,  78,  84,  91,  95,  98, 108, 110, 112, 113, 114, 115,\n",
       "         130, 131, 132, 141, 146, 150, 154, 155])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   8,   9,  10,  11,  12,  15,  17,\n",
       "          18,  19,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,\n",
       "          32,  33,  34,  35,  36,  37,  39,  40,  41,  42,  43,  44,  45,\n",
       "          46,  47,  48,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,\n",
       "          62,  63,  64,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
       "          77,  78,  80,  81,  82,  84,  85,  86,  87,  88,  91,  92,  94,\n",
       "          95,  97,  98, 101, 102, 103, 107, 108, 109, 110, 111, 112, 113,\n",
       "         114, 115, 116, 117, 118, 120, 121, 123, 124, 125, 128, 129, 130,\n",
       "         131, 132, 133, 134, 136, 137, 140, 141, 142, 143, 145, 146, 147,\n",
       "         148, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162,\n",
       "         164, 165, 166, 167]),\n",
       "  array([  6,   7,  13,  14,  16,  20,  38,  49,  50,  61,  65,  76,  79,\n",
       "          83,  89,  90,  93,  96,  99, 100, 104, 105, 106, 119, 122, 126,\n",
       "         127, 135, 138, 139, 144, 149, 151, 163])),\n",
       " (array([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  16,  17,  18,  19,  20,  21,  23,  24,  25,  26,  27,  28,\n",
       "          29,  30,  31,  32,  35,  37,  38,  39,  40,  41,  42,  43,  44,\n",
       "          45,  46,  47,  48,  49,  50,  51,  52,  54,  55,  56,  57,  58,\n",
       "          59,  61,  64,  65,  66,  68,  69,  71,  73,  74,  75,  76,  77,\n",
       "          78,  79,  81,  82,  83,  84,  85,  86,  87,  89,  90,  91,  93,\n",
       "          95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 108,\n",
       "         109, 110, 111, 112, 113, 114, 115, 119, 120, 121, 122, 123, 125,\n",
       "         126, 127, 130, 131, 132, 133, 135, 136, 137, 138, 139, 140, 141,\n",
       "         144, 145, 146, 147, 149, 150, 151, 152, 154, 155, 157, 160, 161,\n",
       "         162, 163, 165, 166, 167]),\n",
       "  array([  1,  15,  22,  33,  34,  36,  53,  60,  62,  63,  67,  70,  72,\n",
       "          80,  88,  92,  94, 107, 116, 117, 118, 124, 128, 129, 134, 142,\n",
       "         143, 148, 153, 156, 158, 159, 164])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  13,  14,\n",
       "          15,  16,  18,  19,  20,  21,  22,  24,  25,  26,  28,  30,  31,\n",
       "          32,  33,  34,  35,  36,  38,  39,  43,  44,  47,  48,  49,  50,\n",
       "          51,  53,  56,  57,  58,  59,  60,  61,  62,  63,  65,  66,  67,\n",
       "          69,  70,  71,  72,  74,  75,  76,  77,  78,  79,  80,  83,  84,\n",
       "          85,  86,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
       "          99, 100, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115,\n",
       "         116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143,\n",
       "         144, 146, 148, 149, 150, 151, 153, 154, 155, 156, 158, 159, 160,\n",
       "         161, 163, 164, 165, 167]),\n",
       "  array([ 10,  12,  17,  23,  27,  29,  37,  40,  41,  42,  45,  46,  52,\n",
       "          54,  55,  64,  68,  73,  81,  82,  87, 101, 102, 103, 111, 120,\n",
       "         137, 145, 147, 152, 157, 162, 166]))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 5 # Number of K-fold Splits\n",
    "\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True).split(trn_X_pd, trn_y_pd))\n",
    "splits[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "24\n",
      "10\n",
      "24\n",
      "10\n",
      "24\n",
      "9\n",
      "24\n",
      "9\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "\n",
    "    print( (trn_y_pd[valid_idx.astype(int)] == 1.0).sum())\n",
    "    print( (trn_y_pd[valid_idx.astype(int)] == 0.0).sum())\n",
    "    \n",
    "    #print( (trn_y_pd[train_idx.astype(int)] == 1.0).sum())\n",
    "    #print( (trn_y_pd[train_idx.astype(int)] == 0.0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dictionary batch\n",
    "class Dataset(data_utils.Dataset):\n",
    "   \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        return {'X': self.X[idx], 'y': self.y[idx]}\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_seq_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_1, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 200, bias=True),\n",
    "            torch.nn.BatchNorm1d(200),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "        )\n",
    "        self.classifier2 = nn.Sequential(\n",
    "\n",
    "            torch.nn.Linear(200, 200, bias=True),\n",
    "            torch.nn.BatchNorm1d(200),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            \n",
    "\n",
    "            #torch.nn.Dropout(0.3)\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(200,1, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[150,200,100,50]\n",
    "#[150,200,100,50,20]\n",
    "\n",
    "class DNN_seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        \n",
    "        self.classifier2 = nn.Sequential(    \n",
    "            torch.nn.Linear(100, 200, bias=True),\n",
    "            torch.nn.BatchNorm1d(200),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier3 = nn.Sequential(  \n",
    "            torch.nn.Linear(200, 200, bias=True),\n",
    "            torch.nn.BatchNorm1d(200),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            torch.nn.Linear(200, 200, bias=True),\n",
    "            torch.nn.BatchNorm1d(200),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(200, 1, bias=True),\n",
    "            #nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.classifier3(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[150,200,100,50]\n",
    "#[150,200,100,50,20]\n",
    "\n",
    "class DNN_seq_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_2, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        self.classifier2 = nn.Sequential(    \n",
    "            torch.nn.Linear(100, 50, bias=True),\n",
    "            torch.nn.BatchNorm1d(50),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier3 = nn.Sequential(  \n",
    "            torch.nn.Linear(50, 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            torch.nn.Linear(100, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(250, 1, bias=True),\n",
    "            #nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.classifier3(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduler control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(object):\n",
    "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
    "                 step_size=2000, mode='triangular', gamma=1.,\n",
    "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
    "\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(\n",
    "                type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
    "            if len(base_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(base_lr)))\n",
    "            self.base_lrs = list(base_lr)\n",
    "        else:\n",
    "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
    "            if len(max_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(max_lr)))\n",
    "            self.max_lrs = list(max_lr)\n",
    "        else:\n",
    "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.batch_step(last_batch_iteration + 1)\n",
    "        self.last_batch_iteration = last_batch_iteration\n",
    "\n",
    "    def batch_step(self, batch_iteration=None):\n",
    "        if batch_iteration is None:\n",
    "            batch_iteration = self.last_batch_iteration + 1\n",
    "        self.last_batch_iteration = batch_iteration\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma**(x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        step_size = float(self.step_size)\n",
    "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
    "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
    "\n",
    "        lrs = []\n",
    "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
    "        for param_group, base_lr, max_lr in param_lrs:\n",
    "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
    "            lrs.append(lr)\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "import time # ??\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "print(trn_X_pd.shape[0])\n",
    "          \n",
    "train_preds = np.zeros(trn_X_pd.shape[0])\n",
    "## Addiction\n",
    "train_y_sort = np.zeros(trn_X_pd.shape[0])\n",
    "\n",
    "test_preds = np.zeros(val_X_pd.shape[0])\n",
    "\n",
    "\n",
    "train_target = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Fold 1\n",
      "Epoch 1/50 \t loss=0.7050 \t val_loss=0.6449 \t time=0.21s\n",
      "Epoch 2/50 \t loss=0.5987 \t val_loss=0.6233 \t time=0.18s\n",
      "Epoch 3/50 \t loss=0.5652 \t val_loss=0.6145 \t time=0.17s\n",
      "Epoch 4/50 \t loss=0.6352 \t val_loss=0.6055 \t time=0.17s\n",
      "Epoch 5/50 \t loss=0.5130 \t val_loss=0.5887 \t time=0.18s\n",
      "Epoch 6/50 \t loss=0.5710 \t val_loss=0.5964 \t time=0.17s\n",
      "Epoch 7/50 \t loss=0.5605 \t val_loss=0.5501 \t time=0.19s\n",
      "Epoch 8/50 \t loss=0.5191 \t val_loss=0.5774 \t time=0.18s\n",
      "Epoch 9/50 \t loss=0.5207 \t val_loss=0.5819 \t time=0.18s\n",
      "Epoch 10/50 \t loss=0.4991 \t val_loss=0.6172 \t time=0.18s\n",
      "Epoch 11/50 \t loss=0.5348 \t val_loss=0.6020 \t time=0.22s\n",
      "Epoch 12/50 \t loss=0.4355 \t val_loss=0.5398 \t time=0.18s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-468-9d5bf8f0dd95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtrn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mtrn_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_losses_f = []\n",
    "avg_val_losses_f = []\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "    \n",
    "    ## ???\n",
    "    x_train_fold = torch.tensor(trn_X_pd[train_idx.astype(int)], dtype=torch.float)   # use_cuse?\n",
    "    y_train_fold = torch.tensor(trn_y_pd[train_idx.astype(int), np.newaxis], dtype=torch.float)    \n",
    "\n",
    "    x_val_fold = torch.tensor(trn_X_pd[valid_idx.astype(int)], dtype=torch.float)\n",
    "    y_val_fold = torch.tensor(trn_y_pd[valid_idx.astype(int), np.newaxis], dtype=torch.float)  \n",
    "    \n",
    "################################################################################    \n",
    "    trn_X = torch.from_numpy(trn_X_pd[train_idx.astype(int)].astype(float))\n",
    "    trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "    \n",
    "    # Train\n",
    "    trn = Dataset(trn_X, trn_y)\n",
    "    trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True, drop_last = True)  # True or False\n",
    "    trn_test_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=False, drop_last = False)  # True or False\n",
    "    \n",
    "    # Valid\n",
    "    valid_X = torch.from_numpy(trn_X_pd[valid_idx.astype(int)].astype(float))\n",
    "    valid_y = torch.from_numpy(trn_y_pd[valid_idx.astype(int)].astype(float))\n",
    "    \n",
    "    valid = Dataset(valid_X, valid_y)\n",
    "    valid_loader = data_utils.DataLoader(valid, batch_size=batch_size, shuffle=False, drop_last = False) # True or False\n",
    "    \n",
    "    # Test\n",
    "    val_X = torch.from_numpy(val_X_pd.astype(float))\n",
    "    val_y = torch.from_numpy(val_y_pd.astype(float))\n",
    "    val = Dataset(val_X, val_y)\n",
    "    test_loader = data_utils.DataLoader(val, batch_size=batch_size, shuffle=False)\n",
    "   ################################################################################    \n",
    "    print(i)\n",
    "    \n",
    "    ## Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    model = DNN_seq_2()\n",
    "    ## After just second, will modify optimizer(weight_decay,step_size, base_lr, max_lr,scheduler)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "    \n",
    "    model = DNN_seq_2()\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    num_epochs = 50\n",
    "    \n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    ##############################################################################\n",
    "    step_size = 2000\n",
    "    base_lr, max_lr = 0.001, 0.01  \n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                             lr=max_lr)\n",
    "    \n",
    "    scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr, step_size=step_size, mode='exp_range', gamma=0.99994)    \n",
    "    \n",
    "    ##############################################################################\n",
    "    \n",
    "    print(f'Fold {i+1}')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "        #correct = 0.   # Accuracy\n",
    "        \n",
    "        for batch_idx, trn in enumerate(trn_loader):\n",
    "            trn_X, trn_y = trn['X'], trn['y']\n",
    "            if use_cuda:\n",
    "                trn_X, trn_y = trn_X.cuda(), trn_y.cuda()\n",
    "            trn_X, trn_y = Variable(trn_X).float(), Variable(trn_y).float()\n",
    "            #optimizer.zero_grad()\n",
    "            trn_pred = model(trn_X)\n",
    "\n",
    "            \n",
    "            if scheduler:\n",
    "                #print('cycle_LR')\n",
    "                scheduler.batch_step()\n",
    "            #print(trn_pred.squeeze())\n",
    "            #print(trn_y)\n",
    "            trn_loss = criterion(trn_pred.squeeze(), trn_y)\n",
    "            optimizer.zero_grad()\n",
    "            trn_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            avg_loss += trn_loss.item()/len(trn_loader)\n",
    "        \n",
    "            #predicted = torch.max(trn_pred.data, 1)[1] \n",
    "            #correct += (predicted == trn_y).sum()\n",
    "        model.eval()\n",
    "        \n",
    "        valid_preds_fold = np.zeros((valid_X.size(0)))\n",
    "        test_preds_fold = np.zeros(val_X_pd.shape[0])  # Test\n",
    "        \n",
    "        avg_val_loss = 0.\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, val in enumerate(valid_loader):\n",
    "                val_X, val_y = val['X'], val['y']\n",
    "                if use_cuda:\n",
    "                    val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "                val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "                #optimizer.zero_grad()\n",
    "                val_pred = model(val_X).detach()\n",
    "\n",
    "            \n",
    "                val_loss = criterion(val_pred.squeeze(), val_y)\n",
    "        \n",
    "                avg_val_loss += val_loss.item()/len(valid_loader)\n",
    "            \n",
    "            \n",
    "                #val_pred = torch.max(val_pred, 1)[1]\n",
    "                val_pred = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "                #print(val_pred.cpu().numpy())\n",
    "                #print(val_pred.cpu().numpy()[:,0])\n",
    "            \n",
    "                valid_preds_fold[batch_idx * batch_size:(batch_idx+1) * batch_size] = (val_pred.cpu().numpy())    # modified [:,0]\n",
    "            \n",
    "            #valid_preds_fold_2 = \n",
    "                # Loss function chage -> plus Sigmoid\n",
    "            elapsed_time = time.time() - start_time \n",
    "            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(epoch + 1, num_epochs, avg_loss, avg_val_loss, elapsed_time))            \n",
    "\n",
    "# Test        \n",
    "    avg_losses_f.append(avg_loss)\n",
    "    avg_val_losses_f.append(avg_val_loss) \n",
    "    \n",
    "    for batch_idx, test in enumerate(test_loader):\n",
    "        test_X, test_y = test['X'], test['y']\n",
    "        if use_cuda:\n",
    "            test_X, test_y = test_X.cuda(), test_y.cuda()\n",
    "        test_X, test_y = Variable(test_X).float(), Variable(test_y).float()        \n",
    "        test_pred = model(test_X).detach()\n",
    "        \n",
    "        \n",
    "        test_pred = (test_pred > 0.5).flatten().type(torch.ByteTensor)\n",
    "        \n",
    "        #print(test_pred)\n",
    "        #print(test_pred.cpu().numpy())\n",
    "        test_preds_fold[batch_idx * batch_size:(batch_idx+1) * batch_size] = (test_pred.cpu().numpy())   # modified [:,0]\n",
    "        \n",
    "        \n",
    "    train_preds[valid_idx.astype(int)] = valid_preds_fold\n",
    "    print(valid_preds_fold)\n",
    "    print(trn_y_pd[valid_idx.astype(int)])\n",
    "    train_y_sort[valid_idx.astype(int)] = trn_y_pd[valid_idx.astype(int)]\n",
    "    test_preds += test_preds_fold / len(splits)\n",
    "\n",
    "#predict_ = pd.DataFrame(predict)\n",
    "\n",
    "#predict_.iloc[:,0]\n",
    "\n",
    "#label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "#test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)    \n",
    "    \n",
    "print(trn_y_pd)\n",
    "print(train_preds)\n",
    "\n",
    "auc  =  round(roc_auc_score(train_y_sort,train_preds.astype(int)),4)\n",
    "\n",
    "\n",
    "cnf = confusion_matrix(train_y_sort, train_preds, labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "print('AUC: ', auc)\n",
    "\n",
    "\n",
    "#fpr, trp, _  =  roc_auc_score(train_y_sort,train_preds.astype(int))\n",
    "\n",
    "#fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "#print(type(fpr))\n",
    "#print(fpr)\n",
    "\n",
    "#auc = auc(fpr, trp)\n",
    "#print('AUC: ', auc(fpr, trp))\n",
    "print('\\n')\n",
    "print('All \\t loss={:.4f} \\t val_loss={:.4f} \\t auc={:.4f}'.format(np.average(avg_losses_f),np.average(avg_val_losses_f),auc))        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([1, 1, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1., 0., 0., 0., 0.])\n",
      "tensor([0, 1, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0, 1, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 1., 1.])\n",
      "tensor([1, 1, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 1.])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([1, 1, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0.])\n",
      "******************** Train ********************\n",
      "Loss: 0.18184316158294678, Accuracy: 0.7714285850524902 %\n",
      "**********************************************\n",
      "Train accuracy:0.771\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predict = []\n",
    "#y_val = val_y\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.\n",
    "    for j, val in enumerate(valid_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred > 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        print(val_y)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Train', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(valid_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Train accuracy:{:.3f}\".format(float(correct_val) / (len(valid_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.426939</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.268852</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.040547</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.003152</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.358020</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.750645</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.537834</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.376175</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.449809</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.673334</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.241656</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.709759</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.386556</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.497097</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.507144</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.455906</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.601396</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.101933</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.891434</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.623050</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.711889</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.607687</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.425657</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.340504</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.568379</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.079431</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.306398</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.416896</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.390738</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.084908</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.807445</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.842939</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.148527</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0            \n",
       "0.426939  0.0\n",
       "0.268852  0.0\n",
       "0.040547  0.0\n",
       "0.003152  0.0\n",
       "0.358020  0.0\n",
       "0.750645  1.0\n",
       "0.537834  0.0\n",
       "0.376175  0.0\n",
       "0.449809  0.0\n",
       "0.673334  0.0\n",
       "0.241656  0.0\n",
       "0.709759  0.0\n",
       "0.386556  0.0\n",
       "0.497097  0.0\n",
       "0.507144  0.0\n",
       "0.455906  0.0\n",
       "0.601396  0.0\n",
       "0.101933  1.0\n",
       "0.891434  1.0\n",
       "0.623050  1.0\n",
       "0.711889  1.0\n",
       "0.607687  1.0\n",
       "0.425657  0.0\n",
       "0.340504  0.0\n",
       "0.568379  1.0\n",
       "0.079431  0.0\n",
       "0.306398  0.0\n",
       "0.416896  0.0\n",
       "0.390738  0.0\n",
       "0.084908  0.0\n",
       "0.807445  1.0\n",
       "0.842939  1.0\n",
       "0.148527  0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "pd.DataFrame(trn_y_pd[valid_idx.astype(int)], predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  1]\n",
      " [ 5 19]]\n",
      "Accuracy :  0.8181818181818182\n",
      "Sensitivity :  0.8888888888888888\n",
      "Specificity :  0.7916666666666666\n",
      "AUC:  0.7396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(trn_y_pd[valid_idx.astype(int)])\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "#fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "auc  =  round(roc_auc_score(train_y_sort,train_preds.astype(int)),4)\n",
    "#print(type(fpr))\n",
    "#print(fpr)\n",
    "print('AUC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN_seq_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN_seq_2(\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=100, bias=True)\n",
       "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (classifier2): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (classifier3): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=250, bias=True)\n",
       "    (5): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): Linear(in_features=250, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = TheModelClass(*args, **kwargs)                                                                                                     \n",
    "#optimizer = TheOptimizerClass(*args, **kwargs)                                                                                             \n",
    "checkpoint = torch.load(\"./platin_model_save/platin_model_400_model_2_100.pth\")                                                                                  \n",
    "model.load_state_dict(checkpoint['model_state_dict'])                                                                                         \n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])                                                                               \n",
    "#num_epochs = checkpoint['epoch']                                                                                                           \n",
    "loss = checkpoint['loss']                                                                                                                   \n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 0.])\n",
      "tensor([1, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 1.])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 1., 0.])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0, 1, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([1, 1, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 1., 0.])\n",
      "tensor([1, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 1.])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 1.])\n",
      "tensor([0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0.])\n",
      "******************** Test ********************\n",
      "Loss: 0.30355265736579895, Accuracy: 0.6888889074325562 %\n",
      "**********************************************\n",
      "Val accuracy:0.689\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        #print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        print(val_y)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.709781</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.520516</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.406429</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.002304</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.033847</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.510784</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.047692</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.717254</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.366883</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.661646</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.643962</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.471596</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.121474</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.351475</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.322801</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.319806</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.627534</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.489409</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004688</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.047415</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.471125</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.575707</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.035085</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.199436</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.531355</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.587801</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.638052</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.046902</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.816826</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.015502</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.513729</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.361707</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.049204</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.769616</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.372237</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.835525</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.244751</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000844</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.272608</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.810720</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.419190</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.061782</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0            \n",
       "0.709781  1.0\n",
       "0.520516  1.0\n",
       "0.406429  0.0\n",
       "0.002304  0.0\n",
       "0.033847  0.0\n",
       "0.510784  0.0\n",
       "0.047692  0.0\n",
       "0.717254  1.0\n",
       "0.366883  0.0\n",
       "0.661646  1.0\n",
       "0.643962  1.0\n",
       "0.471596  1.0\n",
       "0.121474  0.0\n",
       "0.351475  1.0\n",
       "0.322801  0.0\n",
       "0.319806  0.0\n",
       "0.627534  0.0\n",
       "0.489409  0.0\n",
       "0.004688  0.0\n",
       "0.047415  0.0\n",
       "0.471125  0.0\n",
       "0.575707  1.0\n",
       "0.035085  0.0\n",
       "0.199436  0.0\n",
       "0.531355  0.0\n",
       "0.587801  0.0\n",
       "0.638052  0.0\n",
       "0.046902  0.0\n",
       "0.816826  1.0\n",
       "0.015502  0.0\n",
       "0.513729  0.0\n",
       "0.361707  0.0\n",
       "0.049204  0.0\n",
       "0.769616  0.0\n",
       "0.372237  1.0\n",
       "0.835525  1.0\n",
       "0.244751  1.0\n",
       "0.000844  0.0\n",
       "0.272608  0.0\n",
       "0.810720  1.0\n",
       "0.419190  0.0\n",
       "0.061782  0.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  4]\n",
      " [ 7 22]]\n",
      "Accuracy :  0.7380952380952381\n",
      "Sensitivity :  0.6923076923076923\n",
      "Specificity :  0.7586206896551724\n",
      "<class 'numpy.ndarray'>\n",
      "AUC:  0.7254641909814323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print(type(fpr))\n",
    "#print(fpr)\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "#'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': trn_loss\n",
    "    }, \"./platin_model_save/platin_model_400_model_2_100__1_test.pth\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test (Except Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7690],\n",
      "        [0.0011],\n",
      "        [0.0015],\n",
      "        [0.0312],\n",
      "        [0.0142]])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.1163e-01],\n",
      "        [2.5054e-04],\n",
      "        [6.5338e-02],\n",
      "        [3.7494e-01],\n",
      "        [1.0833e-01]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.4652],\n",
      "        [0.0397],\n",
      "        [0.6512],\n",
      "        [0.1571],\n",
      "        [0.5317]])\n",
      "tensor([0, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([[0.0034],\n",
      "        [0.0203],\n",
      "        [0.0044],\n",
      "        [0.7189],\n",
      "        [0.6362]])\n",
      "tensor([0, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([[2.8724e-04],\n",
      "        [8.3109e-02],\n",
      "        [1.2839e-02],\n",
      "        [6.5839e-01],\n",
      "        [7.0855e-01]])\n",
      "tensor([0, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([[0.1849],\n",
      "        [0.1659],\n",
      "        [0.0229],\n",
      "        [0.0023],\n",
      "        [0.7395]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[0.0014],\n",
      "        [0.0047],\n",
      "        [0.0008],\n",
      "        [0.0753],\n",
      "        [0.7521]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[0.2553],\n",
      "        [0.0036],\n",
      "        [0.0130],\n",
      "        [0.1246],\n",
      "        [0.0003]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.6396],\n",
      "        [0.6114],\n",
      "        [0.0372],\n",
      "        [0.0130],\n",
      "        [0.2907]])\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.1068e-05],\n",
      "        [1.3582e-02],\n",
      "        [1.1188e-02],\n",
      "        [1.3367e-03],\n",
      "        [6.1544e-01]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[0.0593],\n",
      "        [0.0001],\n",
      "        [0.0063],\n",
      "        [0.0180],\n",
      "        [0.0174]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[2.4781e-01],\n",
      "        [8.7479e-06],\n",
      "        [1.7692e-01],\n",
      "        [6.6411e-01],\n",
      "        [3.9623e-04]])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[0.2993],\n",
      "        [0.3640],\n",
      "        [0.1349],\n",
      "        [0.0715],\n",
      "        [0.0309]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.0209],\n",
      "        [0.0252],\n",
      "        [0.6844],\n",
      "        [0.0162],\n",
      "        [0.4719]])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.1418],\n",
      "        [0.1878],\n",
      "        [0.0124],\n",
      "        [0.0207],\n",
      "        [0.0073]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.0152],\n",
      "        [0.6288],\n",
      "        [0.6955],\n",
      "        [0.6425],\n",
      "        [0.6856]])\n",
      "tensor([0, 1, 1, 1, 1], dtype=torch.uint8)\n",
      "tensor([[0.7627],\n",
      "        [0.6799],\n",
      "        [0.0054],\n",
      "        [0.6219],\n",
      "        [0.7339]])\n",
      "tensor([1, 1, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([[0.7702],\n",
      "        [0.3756],\n",
      "        [0.0747],\n",
      "        [0.0112],\n",
      "        [0.6052]])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[0.0378],\n",
      "        [0.0029],\n",
      "        [0.6035],\n",
      "        [0.0519],\n",
      "        [0.7856]])\n",
      "tensor([0, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([[0.0639],\n",
      "        [0.0612],\n",
      "        [0.0244],\n",
      "        [0.7239],\n",
      "        [0.5491]])\n",
      "tensor([0, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([[0.0027],\n",
      "        [0.1309],\n",
      "        [0.0004],\n",
      "        [0.0136],\n",
      "        [0.0752]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.0226],\n",
      "        [0.0212],\n",
      "        [0.0420],\n",
      "        [0.0136],\n",
      "        [0.0257]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.0088],\n",
      "        [0.0042],\n",
      "        [0.1130],\n",
      "        [0.0187],\n",
      "        [0.8867]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[0.3935],\n",
      "        [0.0284],\n",
      "        [0.4404],\n",
      "        [0.0138],\n",
      "        [0.6684]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[0.0021],\n",
      "        [0.0007],\n",
      "        [0.7125],\n",
      "        [0.0100],\n",
      "        [0.0324]])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[6.8318e-01],\n",
      "        [1.3951e-01],\n",
      "        [1.2222e-01],\n",
      "        [2.3204e-04],\n",
      "        [6.9037e-01]])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[0.6633],\n",
      "        [0.8352],\n",
      "        [0.6943],\n",
      "        [0.5683],\n",
      "        [0.8330]])\n",
      "tensor([1, 1, 1, 1, 1], dtype=torch.uint8)\n",
      "******************** Test ********************\n",
      "Loss: 0.3406578600406647, Accuracy: 0.9925925731658936 %\n",
      "**********************************************\n",
      "Val accuracy:0.993\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(trn_test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(trn_test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(trn_test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.769005</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001134</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001475</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.031231</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.014199</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.663252</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.835189</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.694276</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.568349</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.833028</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0            \n",
       "0.769005  1.0\n",
       "0.001134  0.0\n",
       "0.001475  0.0\n",
       "0.031231  0.0\n",
       "0.014199  0.0\n",
       "...       ...\n",
       "0.663252  1.0\n",
       "0.835189  1.0\n",
       "0.694276  1.0\n",
       "0.568349  1.0\n",
       "0.833028  1.0\n",
       "\n",
       "[135 rows x 1 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "#trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "pd.DataFrame(trn_y_pd[train_idx.astype(int)], predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38  1]\n",
      " [ 0 96]]\n",
      "Accuracy :  0.9925925925925926\n",
      "Sensitivity :  0.9743589743589743\n",
      "Specificity :  1.0\n",
      "AUC:  0.9871794871794872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(trn_y_pd[train_idx.astype(int)])\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ........................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Train stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ........................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train (Total Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_seq_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_1, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(0.25),\n",
    "        )\n",
    "        self.classifier2 = nn.Sequential(\n",
    "\n",
    "            torch.nn.Linear(100, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(0.25),\n",
    "            \n",
    "\n",
    "            #torch.nn.Dropout(0.3)\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(250,1, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_X = torch.from_numpy(trn_X_pd.astype(float))\n",
    "trn_y = torch.from_numpy(trn_y_pd.astype(float))\n",
    "\n",
    "val_X = torch.from_numpy(val_X_pd.astype(float))\n",
    "val_y = torch.from_numpy(val_y_pd.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = Dataset(trn_X, trn_y)\n",
    "trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "\n",
    "trn_test_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "val = Dataset(val_X, val_y)\n",
    "test_loader = data_utils.DataLoader(val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = DNN_seq_1()    \n",
    "\n",
    "## After just second, will modify optimizer(weight_decay,step_size, base_lr, max_lr,scheduler)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "    \n",
    "model = DNN_seq_1()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "num_epochs = 70\n",
    "    \n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "##############################################################################\n",
    "step_size = 2000\n",
    "base_lr, max_lr = 0.001, 0.01  \n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                             lr=max_lr)\n",
    "    \n",
    "scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr, step_size=step_size, mode='exp_range', gamma=0.99994)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "model_load = 0\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.40207138657569885, Accuracy: 0.6606060862541199 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.27406561374664307, Accuracy: 0.7939394116401672 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.2302365005016327, Accuracy: 0.8545454740524292 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.1906513273715973, Accuracy: 0.8969696760177612 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.10916025936603546, Accuracy: 0.9090909361839294 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.04991741105914116, Accuracy: 0.939393937587738 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.04607832804322243, Accuracy: 0.9515151381492615 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.02667769230902195, Accuracy: 0.9272727370262146 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.1617596447467804, Accuracy: 0.9575757384300232 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.05430951714515686, Accuracy: 0.9333333373069763 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.10681150108575821, Accuracy: 0.9454545378684998 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.016865098848938942, Accuracy: 0.8969696760177612 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.008540354669094086, Accuracy: 0.9636363387107849 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.15884655714035034, Accuracy: 0.9454545378684998 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.006688643246889114, Accuracy: 0.9515151381492615 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.2927723228931427, Accuracy: 0.939393937587738 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.029838085174560547, Accuracy: 0.9575757384300232 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.5656900405883789, Accuracy: 0.9696969985961914 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.018321925774216652, Accuracy: 0.9515151381492615 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.0028182228561490774, Accuracy: 0.9151515364646912 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.013456040993332863, Accuracy: 0.9333333373069763 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.5837785601615906, Accuracy: 0.9333333373069763 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.160756915807724, Accuracy: 0.9454545378684998 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.03501901775598526, Accuracy: 0.9272727370262146 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.00872822105884552, Accuracy: 0.9696969985961914 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 1.8683140277862549, Accuracy: 0.9636363387107849 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.012460628524422646, Accuracy: 0.9818181991577148 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.010255398228764534, Accuracy: 0.9575757384300232 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.3343938887119293, Accuracy: 0.9515151381492615 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.1202966719865799, Accuracy: 0.9515151381492615 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.14164268970489502, Accuracy: 0.939393937587738 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.027163445949554443, Accuracy: 0.9575757384300232 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.018030766397714615, Accuracy: 0.9757575988769531 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.04781258478760719, Accuracy: 0.9757575988769531 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.002633302705362439, Accuracy: 0.9878787994384766 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.06855861097574234, Accuracy: 0.9818181991577148 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.00251968065276742, Accuracy: 0.9757575988769531 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.007630699779838324, Accuracy: 0.9757575988769531 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.013684439472854137, Accuracy: 0.9757575988769531 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.006444504950195551, Accuracy: 0.9151515364646912 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.21844053268432617, Accuracy: 0.939393937587738 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.0220022089779377, Accuracy: 0.9575757384300232 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.0013832111144438386, Accuracy: 0.9818181991577148 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.001025928882881999, Accuracy: 0.9636363387107849 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.020222753286361694, Accuracy: 0.9696969985961914 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.04148697108030319, Accuracy: 0.9757575988769531 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.2407187521457672, Accuracy: 0.9636363387107849 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.5564928650856018, Accuracy: 0.939393937587738 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.025053609162569046, Accuracy: 0.9696969985961914 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.320683091878891, Accuracy: 0.9636363387107849 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.04638712480664253, Accuracy: 0.9333333373069763 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.8817477226257324, Accuracy: 0.9636363387107849 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.2327510416507721, Accuracy: 0.9090909361839294 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.06864099204540253, Accuracy: 0.9636363387107849 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.01522723026573658, Accuracy: 0.9515151381492615 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.00201004883274436, Accuracy: 0.9636363387107849 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.012729855254292488, Accuracy: 0.9272727370262146 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.0016280697891488671, Accuracy: 0.9939393997192383 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.008615873754024506, Accuracy: 0.9636363387107849 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.630075216293335, Accuracy: 0.9818181991577148 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.3332628905773163, Accuracy: 0.9515151381492615 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.15076573193073273, Accuracy: 0.9757575988769531 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.006341557018458843, Accuracy: 0.9757575988769531 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.004324168898165226, Accuracy: 0.9333333373069763 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.07285147905349731, Accuracy: 0.9818181991577148 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.14785411953926086, Accuracy: 0.9636363387107849 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.23272916674613953, Accuracy: 0.9696969985961914 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 1.1696584224700928, Accuracy: 0.9575757384300232 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.03181454539299011, Accuracy: 0.9818181991577148 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.01477793324738741, Accuracy: 0.9575757384300232 % \t time=0.14s\n",
      "**********************************************\n",
      "Trn accuracy:0.958 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predict = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    #correct = 0.   # Accuracy\n",
    "    correct_val = 0.\n",
    "        \n",
    "    for batch_idx, trn in enumerate(trn_loader):\n",
    "        trn_X, trn_y = trn['X'], trn['y']\n",
    "        if use_cuda:\n",
    "            trn_X, trn_y = trn_X.cuda(), trn_y.cuda()\n",
    "        trn_X, trn_y = Variable(trn_X).float(), Variable(trn_y).float()\n",
    "        optimizer.zero_grad()\n",
    "        trn_pred = model(trn_X)\n",
    "        for i in trn_pred:\n",
    "            predict.append(i.detach().numpy())\n",
    "            \n",
    "        if scheduler:\n",
    "            #print('cycle_LR')\n",
    "            scheduler.batch_step()\n",
    "        #print(trn_pred.squeeze())\n",
    "        #print(trn_y)\n",
    "        trn_loss = criterion(trn_pred.squeeze(), trn_y)\n",
    "        trn_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += trn_loss.item()/len(trn_loader)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        predicted = (trn_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        correct_val += (predicted == trn_y).sum()\n",
    "    print('*'*20, 'Train', '*'*20)\n",
    "    print('Loss: {}, Accuracy: {} % \\t time={:.2f}s'.format(trn_loss.item(), correct_val/(len(trn_loader)*batch_size), elapsed_time))\n",
    "print('*'*46)\n",
    "print(\"Trn accuracy:{:.3f} \".format(float(correct_val) / (len(trn_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.5983e-01],\n",
      "        [2.9158e-05],\n",
      "        [7.6539e-03],\n",
      "        [3.2472e-06],\n",
      "        [9.9180e-01]])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[1.4340e-04],\n",
      "        [1.0315e-05],\n",
      "        [2.7879e-06],\n",
      "        [9.8068e-01],\n",
      "        [3.5452e-04]])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[4.7349e-06],\n",
      "        [8.0224e-03],\n",
      "        [5.9592e-05],\n",
      "        [1.7694e-10],\n",
      "        [9.9776e-04]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[3.3224e-06],\n",
      "        [1.7900e-10],\n",
      "        [7.3089e-07],\n",
      "        [8.9265e-06],\n",
      "        [1.4304e-03]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[4.6982e-09],\n",
      "        [3.3153e-06],\n",
      "        [9.8132e-01],\n",
      "        [3.7413e-02],\n",
      "        [8.2993e-12]])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.9242e-01],\n",
      "        [1.0599e-06],\n",
      "        [1.4360e-05],\n",
      "        [2.2877e-05],\n",
      "        [9.8047e-01]])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[9.8905e-01],\n",
      "        [5.1682e-06],\n",
      "        [3.6797e-04],\n",
      "        [7.1621e-02],\n",
      "        [3.8481e-07]])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.1733e-06],\n",
      "        [7.8580e-02],\n",
      "        [5.6859e-05],\n",
      "        [9.8607e-01],\n",
      "        [1.1640e-05]])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[1.6980e-05],\n",
      "        [1.3019e-02],\n",
      "        [2.7832e-02],\n",
      "        [2.1422e-06],\n",
      "        [9.1486e-08]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.8153e-01],\n",
      "        [1.2298e-02],\n",
      "        [1.2391e-09],\n",
      "        [7.2135e-06],\n",
      "        [9.8319e-01]])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[3.8971e-04],\n",
      "        [8.0166e-06],\n",
      "        [5.4240e-03],\n",
      "        [9.8545e-01],\n",
      "        [5.4269e-05]])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[9.1552e-08],\n",
      "        [9.7443e-01],\n",
      "        [2.5459e-05],\n",
      "        [5.0963e-02],\n",
      "        [9.0609e-05]])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.3391e-04],\n",
      "        [1.5515e-03],\n",
      "        [6.1560e-03],\n",
      "        [2.1507e-02],\n",
      "        [9.4892e-01]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[9.6109e-06],\n",
      "        [5.0049e-07],\n",
      "        [9.7328e-01],\n",
      "        [1.8221e-05],\n",
      "        [2.5208e-07]])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.3980e-04],\n",
      "        [3.0955e-08],\n",
      "        [1.1774e-03],\n",
      "        [1.2330e-04],\n",
      "        [9.8902e-01]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[9.7022e-01],\n",
      "        [9.8032e-01],\n",
      "        [1.8086e-03],\n",
      "        [9.6815e-01],\n",
      "        [1.7823e-04]])\n",
      "tensor([1, 1, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[5.0733e-03],\n",
      "        [9.9189e-01],\n",
      "        [9.4856e-06],\n",
      "        [9.9486e-01],\n",
      "        [9.9091e-02]])\n",
      "tensor([0, 1, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[9.8817e-01],\n",
      "        [1.5910e-01],\n",
      "        [9.8806e-01],\n",
      "        [3.3898e-06],\n",
      "        [9.9183e-01]])\n",
      "tensor([1, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([[3.1138e-05],\n",
      "        [1.3530e-04],\n",
      "        [9.5259e-04],\n",
      "        [9.8720e-01],\n",
      "        [9.6374e-01]])\n",
      "tensor([0, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([[7.4304e-12],\n",
      "        [5.0265e-06],\n",
      "        [9.8453e-01],\n",
      "        [9.8093e-01],\n",
      "        [9.9733e-01]])\n",
      "tensor([0, 0, 1, 1, 1], dtype=torch.uint8)\n",
      "tensor([[3.6668e-06],\n",
      "        [9.7607e-01],\n",
      "        [9.9220e-01],\n",
      "        [9.9149e-01],\n",
      "        [9.8051e-01]])\n",
      "tensor([0, 1, 1, 1, 1], dtype=torch.uint8)\n",
      "tensor([[2.1795e-06],\n",
      "        [9.4834e-05],\n",
      "        [1.4447e-07],\n",
      "        [9.3656e-01],\n",
      "        [9.8873e-05]])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[9.9251e-01],\n",
      "        [9.6407e-01],\n",
      "        [9.8319e-01],\n",
      "        [3.5077e-04],\n",
      "        [2.2969e-06]])\n",
      "tensor([1, 1, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[2.4135e-06],\n",
      "        [1.8538e-03],\n",
      "        [9.8070e-01],\n",
      "        [9.7238e-01],\n",
      "        [1.3585e-02]])\n",
      "tensor([0, 0, 1, 1, 0], dtype=torch.uint8)\n",
      "tensor([[3.4101e-07],\n",
      "        [1.1665e-04],\n",
      "        [2.2607e-03],\n",
      "        [5.4893e-05],\n",
      "        [2.4730e-07]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.4200e-07],\n",
      "        [2.4745e-03],\n",
      "        [9.2458e-03],\n",
      "        [1.1950e-05],\n",
      "        [4.9194e-07]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.4774e-04],\n",
      "        [3.0033e-04],\n",
      "        [1.2223e-07],\n",
      "        [4.1853e-03],\n",
      "        [2.2732e-03]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.8201e-01],\n",
      "        [2.8094e-11],\n",
      "        [1.2705e-09],\n",
      "        [1.2860e-01],\n",
      "        [9.8285e-01]])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[4.2679e-05],\n",
      "        [2.5189e-05],\n",
      "        [9.8044e-01],\n",
      "        [1.4099e-04],\n",
      "        [6.8451e-04]])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.5708e-04],\n",
      "        [9.8984e-01],\n",
      "        [2.2428e-02],\n",
      "        [6.0530e-05],\n",
      "        [7.6319e-03]])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.4294e-06],\n",
      "        [4.0214e-08],\n",
      "        [4.2831e-08],\n",
      "        [9.8084e-01],\n",
      "        [9.5164e-01]])\n",
      "tensor([0, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([[1.8300e-03],\n",
      "        [9.8465e-01],\n",
      "        [1.5823e-06],\n",
      "        [2.2813e-05],\n",
      "        [1.3808e-03]])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.7616e-01],\n",
      "        [1.2572e-02],\n",
      "        [5.7246e-05],\n",
      "        [8.4398e-05],\n",
      "        [6.0153e-10]])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.9840],\n",
      "        [0.0010],\n",
      "        [0.9755]])\n",
      "tensor([1, 0, 1], dtype=torch.uint8)\n",
      "******************** Test ********************\n",
      "Loss: 0.013993213884532452, Accuracy: 0.9882352948188782 %\n",
      "**********************************************\n",
      "Val accuracy:0.988\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(trn_test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(trn_test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(trn_test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9.598317e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.915792e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.653852e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.247193e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.917979e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.439797e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.015256e-10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.839814e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.038756e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.755127e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0                \n",
       "9.598317e-01  1.0\n",
       "2.915792e-05  0.0\n",
       "7.653852e-03  0.0\n",
       "3.247193e-06  0.0\n",
       "9.917979e-01  1.0\n",
       "...           ...\n",
       "8.439797e-05  0.0\n",
       "6.015256e-10  0.0\n",
       "9.839814e-01  1.0\n",
       "1.038756e-03  0.0\n",
       "9.755127e-01  1.0\n",
       "\n",
       "[168 rows x 1 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "#trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "pd.DataFrame(trn_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 48   0]\n",
      " [  0 120]]\n",
      "Accuracy :  1.0\n",
      "Sensitivity :  1.0\n",
      "Specificity :  1.0\n",
      "AUC:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(trn_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_load check\n"
     ]
    }
   ],
   "source": [
    "if (model_load == 1):\n",
    "    model = DNN_seq_1()\n",
    "    #model = TheModelClass(*args, **kwargs)                                                                                                     \n",
    "    #optimizer = TheOptimizerClass(*args, **kwargs)                                                                                             \n",
    "    checkpoint = torch.load(\"./platin_model_save/platin_model_250_50_100_model_1_100_250_Semi_Final_Voting.pth\")                                                                                  \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])                                                                                         \n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])                                                                               \n",
    "    #num_epochs = checkpoint['epoch']                                                                                                           \n",
    "    loss = checkpoint['loss']                                                                                                                   \n",
    "    model.eval() \n",
    "    print('model_load check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 0.])\n",
      "tensor([0, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 1.])\n",
      "tensor([1, 1, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 1., 0.])\n",
      "tensor([0, 1, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([0, 1, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 1., 0.])\n",
      "tensor([1, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 1.])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 1.])\n",
      "tensor([0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0.])\n",
      "******************** Test ********************\n",
      "Loss: 0.0005658600712195039, Accuracy: 0.7777777910232544 %\n",
      "**********************************************\n",
      "Val accuracy:0.778\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        #print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        print(val_y)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9.534943e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.911207e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.269382e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.569815e-09</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.728391e-12</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.387491e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.077649e-13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.466208e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.156189e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.542856e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.174533e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.389222e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.452639e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.486322e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.164496e-13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.107011e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.056695e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.147547e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.461392e-09</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.481692e-11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.278513e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.634816e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.741001e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.664448e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.284923e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.324529e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.027203e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.842052e-11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.955494e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.773930e-13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.412169e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.820220e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.908193e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.883965e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.765153e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.845570e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.748448e-05</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.157890e-14</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.330030e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.637365e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.097103e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.402316e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0                \n",
       "9.534943e-01  1.0\n",
       "6.911207e-01  1.0\n",
       "6.269382e-01  0.0\n",
       "1.569815e-09  0.0\n",
       "3.728391e-12  0.0\n",
       "1.387491e-02  0.0\n",
       "6.077649e-13  0.0\n",
       "9.466208e-01  1.0\n",
       "1.156189e-02  0.0\n",
       "9.542856e-01  1.0\n",
       "8.174533e-01  1.0\n",
       "5.389222e-01  1.0\n",
       "1.452639e-04  0.0\n",
       "5.486322e-01  1.0\n",
       "3.164496e-13  0.0\n",
       "1.107011e-04  0.0\n",
       "8.056695e-01  0.0\n",
       "7.147547e-01  0.0\n",
       "7.461392e-09  0.0\n",
       "7.481692e-11  0.0\n",
       "1.278513e-01  0.0\n",
       "8.634816e-01  1.0\n",
       "3.741001e-05  0.0\n",
       "3.664448e-03  0.0\n",
       "3.284923e-02  0.0\n",
       "1.324529e-01  0.0\n",
       "9.027203e-01  0.0\n",
       "3.842052e-11  0.0\n",
       "9.955494e-01  1.0\n",
       "1.773930e-13  0.0\n",
       "9.412169e-01  0.0\n",
       "3.820220e-06  0.0\n",
       "5.908193e-05  0.0\n",
       "9.883965e-01  0.0\n",
       "6.765153e-01  1.0\n",
       "9.845570e-01  1.0\n",
       "1.748448e-05  1.0\n",
       "1.157890e-14  0.0\n",
       "2.330030e-03  0.0\n",
       "9.637365e-01  1.0\n",
       "1.097103e-03  0.0\n",
       "3.402316e-05  0.0"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  1]\n",
      " [ 6 23]]\n",
      "Accuracy :  0.8333333333333334\n",
      "Sensitivity :  0.9230769230769231\n",
      "Specificity :  0.7931034482758621\n",
      "<class 'numpy.ndarray'>\n",
      "AUC:  0.8580901856763927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p_1 = pd.concat([predict_.iloc[:,0], label, val_label, val_label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p_1.columns = ['predict','label','index_ID', 'ID']\n",
    "test_p_1.loc[test_p_1['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p_1.loc[test_p_1['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print(type(fpr))\n",
    "#print(fpr)\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   predict  label            ID  predicted_prob\n",
      "index_ID                                                       \n",
      "TCGA-23-1027  9.534943e-01    1.0  TCGA-23-1027             1.0\n",
      "TCGA-36-1580  6.911207e-01    1.0  TCGA-36-1580             1.0\n",
      "TCGA-29-1769  6.269382e-01    0.0  TCGA-29-1769             1.0\n",
      "TCGA-23-1122  1.569815e-09    0.0  TCGA-23-1122             0.0\n",
      "TCGA-24-1474  3.728391e-12    0.0  TCGA-24-1474             0.0\n",
      "TCGA-10-0927  1.387491e-02    0.0  TCGA-10-0927             0.0\n",
      "TCGA-61-1914  6.077649e-13    0.0  TCGA-61-1914             0.0\n",
      "TCGA-29-1703  9.466208e-01    1.0  TCGA-29-1703             1.0\n",
      "TCGA-04-1365  1.156189e-02    0.0  TCGA-04-1365             0.0\n",
      "TCGA-29-1696  9.542856e-01    1.0  TCGA-29-1696             1.0\n",
      "TCGA-13-1483  8.174533e-01    1.0  TCGA-13-1483             1.0\n",
      "TCGA-61-1738  5.389222e-01    1.0  TCGA-61-1738             1.0\n",
      "TCGA-61-1911  1.452639e-04    0.0  TCGA-61-1911             0.0\n",
      "TCGA-25-2393  5.486322e-01    1.0  TCGA-25-2393             1.0\n",
      "TCGA-09-1667  3.164496e-13    0.0  TCGA-09-1667             0.0\n",
      "TCGA-61-2097  1.107011e-04    0.0  TCGA-61-2097             0.0\n",
      "TCGA-29-2414  8.056695e-01    0.0  TCGA-29-2414             1.0\n",
      "TCGA-24-1563  7.147547e-01    0.0  TCGA-24-1563             1.0\n",
      "TCGA-09-0364  7.461392e-09    0.0  TCGA-09-0364             0.0\n",
      "TCGA-04-1651  7.481692e-11    0.0  TCGA-04-1651             0.0\n",
      "TCGA-24-1551  1.278513e-01    0.0  TCGA-24-1551             0.0\n",
      "TCGA-13-0893  8.634816e-01    1.0  TCGA-13-0893             1.0\n",
      "TCGA-24-1104  3.741001e-05    0.0  TCGA-24-1104             0.0\n",
      "TCGA-25-1326  3.664448e-03    0.0  TCGA-25-1326             0.0\n",
      "TCGA-13-0916  3.284923e-02    0.0  TCGA-13-0916             0.0\n",
      "TCGA-13-1487  1.324529e-01    0.0  TCGA-13-1487             0.0\n",
      "TCGA-13-1403  9.027203e-01    0.0  TCGA-13-1403             1.0\n",
      "TCGA-36-1576  3.842052e-11    0.0  TCGA-36-1576             0.0\n",
      "TCGA-13-0795  9.955494e-01    1.0  TCGA-13-0795             1.0\n",
      "TCGA-23-2078  1.773930e-13    0.0  TCGA-23-2078             0.0\n",
      "TCGA-09-2056  9.412169e-01    0.0  TCGA-09-2056             1.0\n",
      "TCGA-29-1770  3.820220e-06    0.0  TCGA-29-1770             0.0\n",
      "TCGA-24-2290  5.908193e-05    0.0  TCGA-24-2290             0.0\n",
      "TCGA-13-0726  9.883965e-01    0.0  TCGA-13-0726             1.0\n",
      "TCGA-25-1628  6.765153e-01    1.0  TCGA-25-1628             1.0\n",
      "TCGA-09-0366  9.845570e-01    1.0  TCGA-09-0366             1.0\n",
      "TCGA-24-1924  1.748448e-05    1.0  TCGA-24-1924             0.0\n",
      "TCGA-24-1105  1.157890e-14    0.0  TCGA-24-1105             0.0\n",
      "TCGA-20-1683  2.330030e-03    0.0  TCGA-20-1683             0.0\n",
      "TCGA-61-1733  9.637365e-01    1.0  TCGA-61-1733             1.0\n",
      "TCGA-09-1665  1.097103e-03    0.0  TCGA-09-1665             0.0\n",
      "TCGA-36-1571  3.402316e-05    0.0  TCGA-36-1571             0.0\n",
      "[[12  1]\n",
      " [ 6 23]]\n",
      "18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1027</th>\n",
       "      <td>0.953494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-23-1027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>0.691121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>0.946621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>0.817453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>0.538922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>0.548632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>0.805669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>0.863482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0795</th>\n",
       "      <td>0.995549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0795</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>0.941217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0726</th>\n",
       "      <td>0.988396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-0726</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>0.676515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0366</th>\n",
       "      <td>0.984557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-09-0366</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1733</th>\n",
       "      <td>0.963736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1733</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               predict  label            ID  predicted_prob\n",
       "index_ID                                                   \n",
       "TCGA-23-1027  0.953494    1.0  TCGA-23-1027             1.0\n",
       "TCGA-36-1580  0.691121    1.0  TCGA-36-1580             1.0\n",
       "TCGA-29-1769  0.626938    0.0  TCGA-29-1769             1.0\n",
       "TCGA-29-1703  0.946621    1.0  TCGA-29-1703             1.0\n",
       "TCGA-29-1696  0.954286    1.0  TCGA-29-1696             1.0\n",
       "TCGA-13-1483  0.817453    1.0  TCGA-13-1483             1.0\n",
       "TCGA-61-1738  0.538922    1.0  TCGA-61-1738             1.0\n",
       "TCGA-25-2393  0.548632    1.0  TCGA-25-2393             1.0\n",
       "TCGA-29-2414  0.805669    0.0  TCGA-29-2414             1.0\n",
       "TCGA-24-1563  0.714755    0.0  TCGA-24-1563             1.0\n",
       "TCGA-13-0893  0.863482    1.0  TCGA-13-0893             1.0\n",
       "TCGA-13-1403  0.902720    0.0  TCGA-13-1403             1.0\n",
       "TCGA-13-0795  0.995549    1.0  TCGA-13-0795             1.0\n",
       "TCGA-09-2056  0.941217    0.0  TCGA-09-2056             1.0\n",
       "TCGA-13-0726  0.988396    0.0  TCGA-13-0726             1.0\n",
       "TCGA-25-1628  0.676515    1.0  TCGA-25-1628             1.0\n",
       "TCGA-09-0366  0.984557    1.0  TCGA-09-0366             1.0\n",
       "TCGA-61-1733  0.963736    1.0  TCGA-61-1733             1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf = confusion_matrix(test_p_1['label'], test_p_1['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(test_p_1.set_index('index_ID'))\n",
    "\n",
    "test_p_1temp = test_p_1.set_index('index_ID')\n",
    "\n",
    "\n",
    "print(cnf)\n",
    "###print(pd.DataFrame(test_p_2))\n",
    "is_index = test_p_1temp['predicted_prob'] == 1.0\n",
    "\n",
    "#print(is_index)\n",
    "\n",
    "#print(test_p_2.loc[test_p_2['predict'] < 0.5, 'predicted_prob'])\n",
    "test_1 = test_p_1temp[test_p_1temp['predicted_prob'] == 1.0]\n",
    "#test_p_temp = test_p_2.drop['ID']\n",
    "\n",
    "#print(test_p_2)\n",
    "print(len(test_1))\n",
    "test_1\n",
    "#mask = test_p_2[test_p_2['label'].isin(0)]\n",
    "\n",
    "#test_p_2[~mask.astype(int)].head()\n",
    "\n",
    "#mask = mock_data['country'].isin(['Afghanistan', 'Nigeria']) mock_data[~mask].head()\n",
    "\n",
    "#출처: https://note.espriter.net/1325 [espriter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# require to check~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "#'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': trn_loss\n",
    "    }, \"./platin_model_save/platin_model_250_50_100_model_1_100_250_Semi_Final_Voting___test.pth\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predict_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>predicted_prob_x</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>predicted_prob_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.691121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.946621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.817453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.538922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.548632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.805669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.863482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.941217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.676515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  predict_x  label_x          ID_x  \\\n",
       "index_ID                                                       \n",
       "TCGA-36-1580  TCGA-36-1580   0.691121      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769  TCGA-29-1769   0.626938      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703  TCGA-29-1703   0.946621      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696  TCGA-29-1696   0.954286      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483  TCGA-13-1483   0.817453      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738  TCGA-61-1738   0.538922      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393  TCGA-25-2393   0.548632      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414  TCGA-29-2414   0.805669      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563  TCGA-24-1563   0.714755      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893  TCGA-13-0893   0.863482      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403  TCGA-13-1403   0.902720      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056  TCGA-09-2056   0.941217      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628  TCGA-25-1628   0.676515      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_x  predict_y  label_y          ID_y  \\\n",
       "index_ID                                                           \n",
       "TCGA-36-1580               1.0   0.083512      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769               1.0   0.042268      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703               1.0   0.499927      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696               1.0   0.438316      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483               1.0   0.216467      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738               1.0   0.151342      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393               1.0   0.222550      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414               1.0   0.287566      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563               1.0   0.050670      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893               1.0   0.409376      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403               1.0   0.200409      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056               1.0   0.310341      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628               1.0   0.130608      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_y  \n",
       "index_ID                        \n",
       "TCGA-36-1580               0.0  \n",
       "TCGA-29-1769               0.0  \n",
       "TCGA-29-1703               0.0  \n",
       "TCGA-29-1696               0.0  \n",
       "TCGA-13-1483               0.0  \n",
       "TCGA-61-1738               0.0  \n",
       "TCGA-25-2393               0.0  \n",
       "TCGA-29-2414               0.0  \n",
       "TCGA-24-1563               0.0  \n",
       "TCGA-13-0893               0.0  \n",
       "TCGA-13-1403               0.0  \n",
       "TCGA-09-2056               0.0  \n",
       "TCGA-25-1628               0.0  "
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merge = pd.merge(test_1, test_2, left_on = ['ID'], right_index = True)\n",
    "\n",
    "test_merge\n",
    "\n",
    "#test_merge_2 = pd.merge(test_merge, test_3, left_on = ['ID'], right_index = True)\n",
    "\n",
    "#test_merge_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predict_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>predicted_prob_x</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>predicted_prob_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  predict_x  label_x          ID_x  \\\n",
       "index_ID                                                       \n",
       "TCGA-29-1769  TCGA-29-1769   0.626938      0.0  TCGA-29-1769   \n",
       "TCGA-24-1563  TCGA-24-1563   0.714755      0.0  TCGA-24-1563   \n",
       "\n",
       "              predicted_prob_x  predict_y  label_y          ID_y  \\\n",
       "index_ID                                                           \n",
       "TCGA-29-1769               1.0   0.042268      0.0  TCGA-29-1769   \n",
       "TCGA-24-1563               1.0   0.050670      0.0  TCGA-24-1563   \n",
       "\n",
       "              predicted_prob_y  \n",
       "index_ID                        \n",
       "TCGA-29-1769               0.0  \n",
       "TCGA-24-1563               0.0  "
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merge.loc[(test_merge['predict_y'] < 0.08) & (test_merge['predict_x'] - test_merge['predict_y'] > 0.5) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predict_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>predicted_prob_x</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>predicted_prob_y</th>\n",
       "      <th>mean_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.691121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.946621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.851092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.817453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.538922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.548632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.805669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.863482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.941217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.815042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.676515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  predict_x  label_x          ID_x  \\\n",
       "index_ID                                                       \n",
       "TCGA-36-1580  TCGA-36-1580   0.691121      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769  TCGA-29-1769   0.626938      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703  TCGA-29-1703   0.946621      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696  TCGA-29-1696   0.954286      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483  TCGA-13-1483   0.817453      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738  TCGA-61-1738   0.538922      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393  TCGA-25-2393   0.548632      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414  TCGA-29-2414   0.805669      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563  TCGA-24-1563   0.714755      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893  TCGA-13-0893   0.863482      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403  TCGA-13-1403   0.902720      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056  TCGA-09-2056   0.941217      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628  TCGA-25-1628   0.676515      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_x  predict_y  label_y          ID_y  \\\n",
       "index_ID                                                           \n",
       "TCGA-36-1580               1.0   0.083512      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769               1.0   0.042268      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703               1.0   0.499927      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696               1.0   0.438316      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483               1.0   0.216467      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738               1.0   0.151342      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393               1.0   0.222550      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414               1.0   0.287566      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563               1.0   0.050670      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893               1.0   0.409376      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403               1.0   0.200409      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056               1.0   0.310341      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628               1.0   0.130608      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_y  mean_predict  \n",
       "index_ID                                      \n",
       "TCGA-36-1580               0.0      0.569599  \n",
       "TCGA-29-1769               0.0      0.510004  \n",
       "TCGA-29-1703               0.0      0.857282  \n",
       "TCGA-29-1696               0.0      0.851092  \n",
       "TCGA-13-1483               0.0      0.697256  \n",
       "TCGA-61-1738               0.0      0.461406  \n",
       "TCGA-25-2393               0.0      0.483416  \n",
       "TCGA-29-2414               0.0      0.702049  \n",
       "TCGA-24-1563               0.0      0.581938  \n",
       "TCGA-13-0893               0.0      0.772660  \n",
       "TCGA-13-1403               0.0      0.762258  \n",
       "TCGA-09-2056               0.0      0.815042  \n",
       "TCGA-25-1628               0.0      0.567334  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merge['mean_predict'] = (test_merge['predict_x'] * 0.8 + test_merge['predict_y'] * 0.2)\n",
    "\n",
    "test_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predict_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>predicted_prob_x</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>predicted_prob_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  predict_x  label_x          ID_x  \\\n",
       "index_ID                                                       \n",
       "TCGA-29-1769  TCGA-29-1769   0.626938      0.0  TCGA-29-1769   \n",
       "TCGA-24-1563  TCGA-24-1563   0.714755      0.0  TCGA-24-1563   \n",
       "\n",
       "              predicted_prob_x  predict_y  label_y          ID_y  \\\n",
       "index_ID                                                           \n",
       "TCGA-29-1769               1.0   0.042268      0.0  TCGA-29-1769   \n",
       "TCGA-24-1563               1.0   0.050670      0.0  TCGA-24-1563   \n",
       "\n",
       "              predicted_prob_y  \n",
       "index_ID                        \n",
       "TCGA-29-1769               0.0  \n",
       "TCGA-24-1563               0.0  "
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_index = test_merge.loc[(test_merge['predict_y'] < 0.08) ]\n",
    "\n",
    "mod_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predict_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>predicted_prob_x</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>predicted_prob_y</th>\n",
       "      <th>mean_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.946621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.851092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.817453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.805669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.863482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.941217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.815042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  predict_x  label_x          ID_x  \\\n",
       "index_ID                                                       \n",
       "TCGA-29-1703  TCGA-29-1703   0.946621      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696  TCGA-29-1696   0.954286      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483  TCGA-13-1483   0.817453      1.0  TCGA-13-1483   \n",
       "TCGA-29-2414  TCGA-29-2414   0.805669      0.0  TCGA-29-2414   \n",
       "TCGA-13-0893  TCGA-13-0893   0.863482      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403  TCGA-13-1403   0.902720      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056  TCGA-09-2056   0.941217      0.0  TCGA-09-2056   \n",
       "\n",
       "              predicted_prob_x  predict_y  label_y          ID_y  \\\n",
       "index_ID                                                           \n",
       "TCGA-29-1703               1.0   0.499927      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696               1.0   0.438316      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483               1.0   0.216467      1.0  TCGA-13-1483   \n",
       "TCGA-29-2414               1.0   0.287566      0.0  TCGA-29-2414   \n",
       "TCGA-13-0893               1.0   0.409376      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403               1.0   0.200409      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056               1.0   0.310341      0.0  TCGA-09-2056   \n",
       "\n",
       "              predicted_prob_y  mean_predict  \n",
       "index_ID                                      \n",
       "TCGA-29-1703               0.0      0.857282  \n",
       "TCGA-29-1696               0.0      0.851092  \n",
       "TCGA-13-1483               0.0      0.697256  \n",
       "TCGA-29-2414               0.0      0.702049  \n",
       "TCGA-13-0893               0.0      0.772660  \n",
       "TCGA-13-1403               0.0      0.762258  \n",
       "TCGA-09-2056               0.0      0.815042  "
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merge.loc[(test_merge['predict_x'] > 0.8) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predict_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>predicted_prob_x</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>predicted_prob_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.691121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.946621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.817453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.538922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.548632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.805669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.863482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.941217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.676515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  predict_x  label_x          ID_x  \\\n",
       "index_ID                                                       \n",
       "TCGA-36-1580  TCGA-36-1580   0.691121      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769  TCGA-29-1769   0.626938      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703  TCGA-29-1703   0.946621      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696  TCGA-29-1696   0.954286      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483  TCGA-13-1483   0.817453      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738  TCGA-61-1738   0.538922      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393  TCGA-25-2393   0.548632      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414  TCGA-29-2414   0.805669      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563  TCGA-24-1563   0.714755      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893  TCGA-13-0893   0.863482      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403  TCGA-13-1403   0.902720      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056  TCGA-09-2056   0.941217      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628  TCGA-25-1628   0.676515      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_x  predict_y  label_y          ID_y  \\\n",
       "index_ID                                                           \n",
       "TCGA-36-1580               1.0   0.083512      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769               1.0   0.042268      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703               1.0   0.499927      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696               1.0   0.438316      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483               1.0   0.216467      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738               1.0   0.151342      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393               1.0   0.222550      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414               1.0   0.287566      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563               1.0   0.050670      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893               1.0   0.409376      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403               1.0   0.200409      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056               1.0   0.310341      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628               1.0   0.130608      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_y  \n",
       "index_ID                        \n",
       "TCGA-36-1580               0.0  \n",
       "TCGA-29-1769               0.0  \n",
       "TCGA-29-1703               0.0  \n",
       "TCGA-29-1696               0.0  \n",
       "TCGA-13-1483               0.0  \n",
       "TCGA-61-1738               0.0  \n",
       "TCGA-25-2393               0.0  \n",
       "TCGA-29-2414               0.0  \n",
       "TCGA-24-1563               0.0  \n",
       "TCGA-13-0893               0.0  \n",
       "TCGA-13-1403               0.0  \n",
       "TCGA-09-2056               0.0  \n",
       "TCGA-25-1628               0.0  "
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_temp_df = test_merge.loc[(test_merge['predict_y'] >= 0.2) | (test_merge['predict_x'] <= 0.8) ]\n",
    "test_temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predict_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>predicted_prob_x</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>predicted_prob_y</th>\n",
       "      <th>predict_add</th>\n",
       "      <th>label_add</th>\n",
       "      <th>index_ID</th>\n",
       "      <th>predicted_prob_add</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.691121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377572</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.946621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.817453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.538922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.849077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.548632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.788705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.805669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.863482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.941217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.676515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  predict_x  label_x          ID_x  \\\n",
       "index_ID                                                       \n",
       "TCGA-36-1580  TCGA-36-1580   0.691121      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769  TCGA-29-1769   0.626938      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703  TCGA-29-1703   0.946621      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696  TCGA-29-1696   0.954286      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483  TCGA-13-1483   0.817453      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738  TCGA-61-1738   0.538922      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393  TCGA-25-2393   0.548632      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414  TCGA-29-2414   0.805669      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563  TCGA-24-1563   0.714755      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893  TCGA-13-0893   0.863482      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403  TCGA-13-1403   0.902720      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056  TCGA-09-2056   0.941217      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628  TCGA-25-1628   0.676515      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_x  predict_y  label_y          ID_y  \\\n",
       "index_ID                                                           \n",
       "TCGA-36-1580               1.0   0.083512      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769               1.0   0.042268      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703               1.0   0.499927      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696               1.0   0.438316      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483               1.0   0.216467      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738               1.0   0.151342      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393               1.0   0.222550      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414               1.0   0.287566      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563               1.0   0.050670      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893               1.0   0.409376      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403               1.0   0.200409      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056               1.0   0.310341      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628               1.0   0.130608      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_y  predict_add  label_add      index_ID  \\\n",
       "index_ID                                                               \n",
       "TCGA-36-1580               0.0     0.377572        1.0  TCGA-36-1580   \n",
       "TCGA-29-1769               0.0     0.105563        0.0  TCGA-29-1769   \n",
       "TCGA-29-1703               0.0     0.937590        1.0  TCGA-29-1703   \n",
       "TCGA-29-1696               0.0     0.975946        1.0  TCGA-29-1696   \n",
       "TCGA-13-1483               0.0     0.907308        1.0  TCGA-13-1483   \n",
       "TCGA-61-1738               0.0     0.849077        1.0  TCGA-61-1738   \n",
       "TCGA-25-2393               0.0     0.788705        1.0  TCGA-25-2393   \n",
       "TCGA-29-2414               0.0     0.917132        0.0  TCGA-29-2414   \n",
       "TCGA-24-1563               0.0     0.487189        0.0  TCGA-24-1563   \n",
       "TCGA-13-0893               0.0     0.946662        1.0  TCGA-13-0893   \n",
       "TCGA-13-1403               0.0     0.855336        0.0  TCGA-13-1403   \n",
       "TCGA-09-2056               0.0     0.897042        0.0  TCGA-09-2056   \n",
       "TCGA-25-1628               0.0     0.419460        1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_add  \n",
       "index_ID                          \n",
       "TCGA-36-1580                 0.0  \n",
       "TCGA-29-1769                 0.0  \n",
       "TCGA-29-1703                 1.0  \n",
       "TCGA-29-1696                 1.0  \n",
       "TCGA-13-1483                 1.0  \n",
       "TCGA-61-1738                 1.0  \n",
       "TCGA-25-2393                 1.0  \n",
       "TCGA-29-2414                 1.0  \n",
       "TCGA-24-1563                 0.0  \n",
       "TCGA-13-0893                 1.0  \n",
       "TCGA-13-1403                 1.0  \n",
       "TCGA-09-2056                 1.0  \n",
       "TCGA-25-1628                 0.0  "
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_temp_merge = pd.merge(test_temp_df, test_3, left_on = ['ID'], right_index = True)\n",
    "\n",
    "test_temp_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predict_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>predicted_prob_x</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>predicted_prob_y</th>\n",
       "      <th>predict_add</th>\n",
       "      <th>label_add</th>\n",
       "      <th>index_ID</th>\n",
       "      <th>predicted_prob_add</th>\n",
       "      <th>mean_predict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.691121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377572</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.946621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.832690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.817453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.689670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.538922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.849077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.519566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.548632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.788705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.805669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.917132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.704009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.491842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.863482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.941217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.897042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.772454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.676515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  predict_x  label_x          ID_x  \\\n",
       "index_ID                                                       \n",
       "TCGA-36-1580  TCGA-36-1580   0.691121      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769  TCGA-29-1769   0.626938      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703  TCGA-29-1703   0.946621      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696  TCGA-29-1696   0.954286      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483  TCGA-13-1483   0.817453      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738  TCGA-61-1738   0.538922      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393  TCGA-25-2393   0.548632      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414  TCGA-29-2414   0.805669      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563  TCGA-24-1563   0.714755      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893  TCGA-13-0893   0.863482      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403  TCGA-13-1403   0.902720      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056  TCGA-09-2056   0.941217      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628  TCGA-25-1628   0.676515      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_x  predict_y  label_y          ID_y  \\\n",
       "index_ID                                                           \n",
       "TCGA-36-1580               1.0   0.083512      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769               1.0   0.042268      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703               1.0   0.499927      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696               1.0   0.438316      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483               1.0   0.216467      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738               1.0   0.151342      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393               1.0   0.222550      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414               1.0   0.287566      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563               1.0   0.050670      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893               1.0   0.409376      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403               1.0   0.200409      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056               1.0   0.310341      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628               1.0   0.130608      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_y  predict_add  label_add      index_ID  \\\n",
       "index_ID                                                               \n",
       "TCGA-36-1580               0.0     0.377572        1.0  TCGA-36-1580   \n",
       "TCGA-29-1769               0.0     0.105563        0.0  TCGA-29-1769   \n",
       "TCGA-29-1703               0.0     0.937590        1.0  TCGA-29-1703   \n",
       "TCGA-29-1696               0.0     0.975946        1.0  TCGA-29-1696   \n",
       "TCGA-13-1483               0.0     0.907308        1.0  TCGA-13-1483   \n",
       "TCGA-61-1738               0.0     0.849077        1.0  TCGA-61-1738   \n",
       "TCGA-25-2393               0.0     0.788705        1.0  TCGA-25-2393   \n",
       "TCGA-29-2414               0.0     0.917132        0.0  TCGA-29-2414   \n",
       "TCGA-24-1563               0.0     0.487189        0.0  TCGA-24-1563   \n",
       "TCGA-13-0893               0.0     0.946662        1.0  TCGA-13-0893   \n",
       "TCGA-13-1403               0.0     0.855336        0.0  TCGA-13-1403   \n",
       "TCGA-09-2056               0.0     0.897042        0.0  TCGA-09-2056   \n",
       "TCGA-25-1628               0.0     0.419460        1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_add  mean_predict  \n",
       "index_ID                                        \n",
       "TCGA-36-1580                 0.0      0.460831  \n",
       "TCGA-29-1769                 0.0      0.350427  \n",
       "TCGA-29-1703                 1.0      0.832690  \n",
       "TCGA-29-1696                 1.0      0.830708  \n",
       "TCGA-13-1483                 1.0      0.689670  \n",
       "TCGA-61-1738                 1.0      0.519566  \n",
       "TCGA-25-2393                 1.0      0.527130  \n",
       "TCGA-29-2414                 1.0      0.704009  \n",
       "TCGA-24-1563                 0.0      0.491842  \n",
       "TCGA-13-0893                 1.0      0.770750  \n",
       "TCGA-13-1403                 1.0      0.715296  \n",
       "TCGA-09-2056                 1.0      0.772454  \n",
       "TCGA-25-1628                 0.0      0.475775  "
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_temp_merge['mean_predict'] = (test_temp_merge['predict_x'] + test_temp_merge['predict_y']*0.5 + test_temp_merge['predict_add']*0.5)/2\n",
    "\n",
    "test_temp_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predict_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>predicted_prob_x</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>predicted_prob_y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  predict_x  label_x          ID_x  \\\n",
       "index_ID                                                       \n",
       "TCGA-29-1769  TCGA-29-1769   0.626938      0.0  TCGA-29-1769   \n",
       "TCGA-24-1563  TCGA-24-1563   0.714755      0.0  TCGA-24-1563   \n",
       "\n",
       "              predicted_prob_x  predict_y  label_y          ID_y  \\\n",
       "index_ID                                                           \n",
       "TCGA-29-1769               1.0   0.042268      0.0  TCGA-29-1769   \n",
       "TCGA-24-1563               1.0   0.050670      0.0  TCGA-24-1563   \n",
       "\n",
       "              predicted_prob_y  \n",
       "index_ID                        \n",
       "TCGA-29-1769               0.0  \n",
       "TCGA-24-1563               0.0  "
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_index = test_merge.loc[(test_merge['predict_y'] < 0.08) ]\n",
    "\n",
    "mod_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCGA-24-1563'"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_index.ID[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1027</th>\n",
       "      <td>9.534943e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-23-1027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>6.911207e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>6.269382e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1122</th>\n",
       "      <td>1.569815e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-23-1122</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1474</th>\n",
       "      <td>3.728391e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1474</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-10-0927</th>\n",
       "      <td>1.387491e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-10-0927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1914</th>\n",
       "      <td>6.077649e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-61-1914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>9.466208e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1365</th>\n",
       "      <td>1.156189e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-04-1365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>9.542856e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>8.174533e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>5.389222e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1911</th>\n",
       "      <td>1.452639e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-61-1911</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>5.486322e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-1667</th>\n",
       "      <td>3.164496e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-1667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2097</th>\n",
       "      <td>1.107011e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-61-2097</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>8.056695e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>7.147547e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0364</th>\n",
       "      <td>7.461392e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-0364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1651</th>\n",
       "      <td>7.481692e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-04-1651</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1551</th>\n",
       "      <td>1.278513e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1551</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>8.634816e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1104</th>\n",
       "      <td>3.741001e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1326</th>\n",
       "      <td>3.664448e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-25-1326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0916</th>\n",
       "      <td>3.284923e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-0916</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1487</th>\n",
       "      <td>1.324529e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1487</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>9.027203e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1576</th>\n",
       "      <td>3.842052e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-36-1576</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0795</th>\n",
       "      <td>9.955494e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0795</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-2078</th>\n",
       "      <td>1.773930e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-23-2078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>9.412169e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1770</th>\n",
       "      <td>3.820220e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-2290</th>\n",
       "      <td>5.908193e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-2290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0726</th>\n",
       "      <td>9.883965e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-0726</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>6.765153e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0366</th>\n",
       "      <td>9.845570e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-09-0366</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1924</th>\n",
       "      <td>1.748448e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-24-1924</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1105</th>\n",
       "      <td>1.157890e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-20-1683</th>\n",
       "      <td>2.330030e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-20-1683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1733</th>\n",
       "      <td>9.637365e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1733</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-1665</th>\n",
       "      <td>1.097103e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-1665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1571</th>\n",
       "      <td>3.402316e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-36-1571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   predict  label            ID  predicted_prob\n",
       "index_ID                                                       \n",
       "TCGA-23-1027  9.534943e-01    1.0  TCGA-23-1027             1.0\n",
       "TCGA-36-1580  6.911207e-01    1.0  TCGA-36-1580             1.0\n",
       "TCGA-29-1769  6.269382e-01    0.0  TCGA-29-1769             1.0\n",
       "TCGA-23-1122  1.569815e-09    0.0  TCGA-23-1122             0.0\n",
       "TCGA-24-1474  3.728391e-12    0.0  TCGA-24-1474             0.0\n",
       "TCGA-10-0927  1.387491e-02    0.0  TCGA-10-0927             0.0\n",
       "TCGA-61-1914  6.077649e-13    0.0  TCGA-61-1914             0.0\n",
       "TCGA-29-1703  9.466208e-01    1.0  TCGA-29-1703             1.0\n",
       "TCGA-04-1365  1.156189e-02    0.0  TCGA-04-1365             0.0\n",
       "TCGA-29-1696  9.542856e-01    1.0  TCGA-29-1696             1.0\n",
       "TCGA-13-1483  8.174533e-01    1.0  TCGA-13-1483             1.0\n",
       "TCGA-61-1738  5.389222e-01    1.0  TCGA-61-1738             1.0\n",
       "TCGA-61-1911  1.452639e-04    0.0  TCGA-61-1911             0.0\n",
       "TCGA-25-2393  5.486322e-01    1.0  TCGA-25-2393             1.0\n",
       "TCGA-09-1667  3.164496e-13    0.0  TCGA-09-1667             0.0\n",
       "TCGA-61-2097  1.107011e-04    0.0  TCGA-61-2097             0.0\n",
       "TCGA-29-2414  8.056695e-01    0.0  TCGA-29-2414             1.0\n",
       "TCGA-24-1563  7.147547e-01    0.0  TCGA-24-1563             1.0\n",
       "TCGA-09-0364  7.461392e-09    0.0  TCGA-09-0364             0.0\n",
       "TCGA-04-1651  7.481692e-11    0.0  TCGA-04-1651             0.0\n",
       "TCGA-24-1551  1.278513e-01    0.0  TCGA-24-1551             0.0\n",
       "TCGA-13-0893  8.634816e-01    1.0  TCGA-13-0893             1.0\n",
       "TCGA-24-1104  3.741001e-05    0.0  TCGA-24-1104             0.0\n",
       "TCGA-25-1326  3.664448e-03    0.0  TCGA-25-1326             0.0\n",
       "TCGA-13-0916  3.284923e-02    0.0  TCGA-13-0916             0.0\n",
       "TCGA-13-1487  1.324529e-01    0.0  TCGA-13-1487             0.0\n",
       "TCGA-13-1403  9.027203e-01    0.0  TCGA-13-1403             1.0\n",
       "TCGA-36-1576  3.842052e-11    0.0  TCGA-36-1576             0.0\n",
       "TCGA-13-0795  9.955494e-01    1.0  TCGA-13-0795             1.0\n",
       "TCGA-23-2078  1.773930e-13    0.0  TCGA-23-2078             0.0\n",
       "TCGA-09-2056  9.412169e-01    0.0  TCGA-09-2056             1.0\n",
       "TCGA-29-1770  3.820220e-06    0.0  TCGA-29-1770             0.0\n",
       "TCGA-24-2290  5.908193e-05    0.0  TCGA-24-2290             0.0\n",
       "TCGA-13-0726  9.883965e-01    0.0  TCGA-13-0726             1.0\n",
       "TCGA-25-1628  6.765153e-01    1.0  TCGA-25-1628             1.0\n",
       "TCGA-09-0366  9.845570e-01    1.0  TCGA-09-0366             1.0\n",
       "TCGA-24-1924  1.748448e-05    1.0  TCGA-24-1924             0.0\n",
       "TCGA-24-1105  1.157890e-14    0.0  TCGA-24-1105             0.0\n",
       "TCGA-20-1683  2.330030e-03    0.0  TCGA-20-1683             0.0\n",
       "TCGA-61-1733  9.637365e-01    1.0  TCGA-61-1733             1.0\n",
       "TCGA-09-1665  1.097103e-03    0.0  TCGA-09-1665             0.0\n",
       "TCGA-36-1571  3.402316e-05    0.0  TCGA-36-1571             0.0"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_p_1temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_final = test_p_1temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               predict  label            ID  predicted_prob\n",
       "index_ID                                                   \n",
       "TCGA-29-1769  0.626938    0.0  TCGA-29-1769             1.0"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1_final.loc[test_1_final['ID'] == mod_index.ID[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_final.loc[test_1_final['ID'] == mod_index.ID[0], 'predicted_prob'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               predict  label            ID  predicted_prob\n",
       "index_ID                                                   \n",
       "TCGA-24-1563  0.714755    0.0  TCGA-24-1563             1.0"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1_final.loc[test_1_final['ID'] == mod_index.ID[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1_final.loc[test_1_final['ID'] == mod_index.ID[1], 'predicted_prob'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               predict  label            ID  predicted_prob\n",
       "index_ID                                                   \n",
       "TCGA-29-1769  0.626938    0.0  TCGA-29-1769             0.0"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1_final.loc[test_1_final['ID'] == mod_index.ID[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               predict  label            ID  predicted_prob\n",
       "index_ID                                                   \n",
       "TCGA-24-1563  0.714755    0.0  TCGA-24-1563             0.0"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1_final.loc[test_1_final['ID'] == mod_index.ID[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  1]\n",
      " [ 4 25]]\n",
      "Accuracy :  0.8809523809523809\n",
      "Sensitivity :  0.9230769230769231\n",
      "Specificity :  0.8620689655172413\n",
      "<class 'numpy.ndarray'>\n",
      "AUC:  0.8925729442970822\n"
     ]
    }
   ],
   "source": [
    "cnf = confusion_matrix(test_1_final['label'], test_1_final['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_1_final['label'], test_1_final['predicted_prob'])\n",
    "\n",
    "print(type(fpr))\n",
    "#print(fpr)\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge.loc[test_merge['mean_predict'] >= 0.5, 'mod_predicted_prob'] = 1\n",
    "test_merge.loc[test_merge['mean_predict'] < 0.5, 'mod_predicted_prob'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predict_x</th>\n",
       "      <th>label_x</th>\n",
       "      <th>ID_x</th>\n",
       "      <th>predicted_prob_x</th>\n",
       "      <th>predict_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>ID_y</th>\n",
       "      <th>predicted_prob_y</th>\n",
       "      <th>mean_predict</th>\n",
       "      <th>mod_predicted_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.691121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.083512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448077</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.626938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.042268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.946621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767943</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.954286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.438316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.747898</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.817453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577059</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.538922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151342</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.548632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.805669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598428</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.714755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449121</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.863482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681839</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.621796</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.941217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.688867</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.676515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130608</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458152</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  predict_x  label_x          ID_x  \\\n",
       "index_ID                                                       \n",
       "TCGA-36-1580  TCGA-36-1580   0.691121      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769  TCGA-29-1769   0.626938      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703  TCGA-29-1703   0.946621      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696  TCGA-29-1696   0.954286      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483  TCGA-13-1483   0.817453      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738  TCGA-61-1738   0.538922      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393  TCGA-25-2393   0.548632      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414  TCGA-29-2414   0.805669      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563  TCGA-24-1563   0.714755      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893  TCGA-13-0893   0.863482      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403  TCGA-13-1403   0.902720      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056  TCGA-09-2056   0.941217      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628  TCGA-25-1628   0.676515      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_x  predict_y  label_y          ID_y  \\\n",
       "index_ID                                                           \n",
       "TCGA-36-1580               1.0   0.083512      1.0  TCGA-36-1580   \n",
       "TCGA-29-1769               1.0   0.042268      0.0  TCGA-29-1769   \n",
       "TCGA-29-1703               1.0   0.499927      1.0  TCGA-29-1703   \n",
       "TCGA-29-1696               1.0   0.438316      1.0  TCGA-29-1696   \n",
       "TCGA-13-1483               1.0   0.216467      1.0  TCGA-13-1483   \n",
       "TCGA-61-1738               1.0   0.151342      1.0  TCGA-61-1738   \n",
       "TCGA-25-2393               1.0   0.222550      1.0  TCGA-25-2393   \n",
       "TCGA-29-2414               1.0   0.287566      0.0  TCGA-29-2414   \n",
       "TCGA-24-1563               1.0   0.050670      0.0  TCGA-24-1563   \n",
       "TCGA-13-0893               1.0   0.409376      1.0  TCGA-13-0893   \n",
       "TCGA-13-1403               1.0   0.200409      0.0  TCGA-13-1403   \n",
       "TCGA-09-2056               1.0   0.310341      0.0  TCGA-09-2056   \n",
       "TCGA-25-1628               1.0   0.130608      1.0  TCGA-25-1628   \n",
       "\n",
       "              predicted_prob_y  mean_predict  mod_predicted_prob  \n",
       "index_ID                                                          \n",
       "TCGA-36-1580               0.0      0.448077                 0.0  \n",
       "TCGA-29-1769               0.0      0.393070                 0.0  \n",
       "TCGA-29-1703               0.0      0.767943                 1.0  \n",
       "TCGA-29-1696               0.0      0.747898                 1.0  \n",
       "TCGA-13-1483               0.0      0.577059                 1.0  \n",
       "TCGA-61-1738               0.0      0.383890                 0.0  \n",
       "TCGA-25-2393               0.0      0.418199                 0.0  \n",
       "TCGA-29-2414               0.0      0.598428                 1.0  \n",
       "TCGA-24-1563               0.0      0.449121                 0.0  \n",
       "TCGA-13-0893               0.0      0.681839                 1.0  \n",
       "TCGA-13-1403               0.0      0.621796                 1.0  \n",
       "TCGA-09-2056               0.0      0.688867                 1.0  \n",
       "TCGA-25-1628               0.0      0.458152                 0.0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결론적으로 이미 잘 훈련된 모델이 있고, 특히 해당 모델과 유사한 문제를 해결시 transfer learining을 사용합니다.\n",
    "실질적 조언\n",
    "새로 훈련할 데이터가 적지만 original 데이터와 유사할 경우\n",
    "\n",
    "데이터의 양이 적어 fine-tune (전체 모델에 대해서 backpropagation을 진행하는 것) 은 over-fitting의 위험이 있기에 하지 않습니다.\n",
    "새로 학습할 데이터는 original 데이터와 유사하기 때문에 이 경우 최종 linear classfier 레이어만 학습을 합니다.\n",
    "새로 훈련할 데이터가 매우 많으며 original 데이터와 유사할 경우\n",
    "\n",
    "새로 학습할 데이터의 양이 많다는 것은 over-fitting의 위험이 낮다는 뜻이므로, 전체 레이어에 대해서 fine-tune을 합니다.\n",
    "새로 훈련할 데이터가 적으며 original 데이터와 다른 경우\n",
    "\n",
    "데이터의 양이 적기 때문에 최종 단계의 linear classifier 레이어를 학습하는 것이 좋을 것입니다. 반면서 데이터가 서로 다르기 때문에 거의 마지막부분 (the top of the network)만 학습하는 것은 좋지 않습니다. 서로 상충이 되는데.. 이 경우에는 네트워크 초기 부분 어딘가 activation 이후에 특정 레이어를 학습시키는게 좋습니다.\n",
    "새로 훈련할 데이터가 많지만 original 데이터와와 다른 경우\n",
    "\n",
    "데이터가 많기 때문에 아예 새로운 ConvNet을 만들수도 있지만, 실적적으로 transfer learning이 더 효율이 좋습니다. 전체 네트워크에 대해서 fine-tune을 해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=250, bias=True)\n",
       "  (1): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): LeakyReLU(negative_slope=0.01)\n",
       "  (3): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pre_temp = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_temp = DNN_seq_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_pre_temp.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_temp.classifier4 = model_pre_temp.classifier2    \n",
    "#model_temp.classifier2 = model_pre_temp.classifier2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 1e-3\n",
    "#model_2 = DNN_seq_2()   \n",
    "## After just second, will modify optimizer(weight_decay,step_size, base_lr, max_lr,scheduler)\n",
    "optimizer = optim.Adam(model_temp.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "    \n",
    "#model_2 = DNN_seq_2()\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "num_epochs = 90\n",
    "    \n",
    "if use_cuda:\n",
    "    model_temp = model_temp.cuda()\n",
    "    \n",
    "##############################################################################\n",
    "step_size = 2000\n",
    "base_lr, max_lr = 0.001, 0.01  \n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model_temp.parameters()), \n",
    "                             lr=max_lr)\n",
    "    \n",
    "scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr, step_size=step_size, mode='exp_range', gamma=0.99994)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.5815005898475647, Accuracy: 0.699999988079071 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.6397777795791626, Accuracy: 0.7230769395828247 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.7110729217529297, Accuracy: 0.7230769395828247 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.4122587740421295, Accuracy: 0.7230769395828247 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.6807829141616821, Accuracy: 0.7076923251152039 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.4648997187614441, Accuracy: 0.7153846025466919 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.5600745677947998, Accuracy: 0.7153846025466919 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.34087198972702026, Accuracy: 0.7461538314819336 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.5421463251113892, Accuracy: 0.7923076748847961 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 1.0851771831512451, Accuracy: 0.7230769395828247 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.3242802619934082, Accuracy: 0.7461538314819336 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.3788490891456604, Accuracy: 0.7923076748847961 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.4290893077850342, Accuracy: 0.7538461685180664 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.3531005382537842, Accuracy: 0.8461538553237915 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.31874188780784607, Accuracy: 0.7923076748847961 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.41610488295555115, Accuracy: 0.7769230604171753 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.43529319763183594, Accuracy: 0.8769230842590332 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.1511932909488678, Accuracy: 0.8769230842590332 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.1455099880695343, Accuracy: 0.8307692408561707 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.6103969812393188, Accuracy: 0.8615384697914124 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.171977236866951, Accuracy: 0.8461538553237915 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.34328389167785645, Accuracy: 0.8846153616905212 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.7295297384262085, Accuracy: 0.8692307472229004 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.544813334941864, Accuracy: 0.8461538553237915 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.7026508450508118, Accuracy: 0.8769230842590332 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.2644449472427368, Accuracy: 0.8846153616905212 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.395773708820343, Accuracy: 0.8999999761581421 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.15198424458503723, Accuracy: 0.8769230842590332 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.16849173605442047, Accuracy: 0.8999999761581421 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.4817970395088196, Accuracy: 0.8538461327552795 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.10324428975582123, Accuracy: 0.8692307472229004 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.2057790756225586, Accuracy: 0.9153845906257629 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.39064717292785645, Accuracy: 0.800000011920929 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.1448356658220291, Accuracy: 0.8769230842590332 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.5534846186637878, Accuracy: 0.8538461327552795 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.19763343036174774, Accuracy: 0.8846153616905212 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.09078625589609146, Accuracy: 0.8461538553237915 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 1.0402019023895264, Accuracy: 0.8230769038200378 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.15045443177223206, Accuracy: 0.9538461565971375 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.12107105553150177, Accuracy: 0.8769230842590332 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.4659556448459625, Accuracy: 0.8769230842590332 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.9506187438964844, Accuracy: 0.9230769276618958 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.055705200880765915, Accuracy: 0.9384615421295166 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.08778417110443115, Accuracy: 0.8846153616905212 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.14204296469688416, Accuracy: 0.9153845906257629 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.14438697695732117, Accuracy: 0.8307692408561707 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.1818152666091919, Accuracy: 0.8461538553237915 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.13205699622631073, Accuracy: 0.8615384697914124 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.9262957572937012, Accuracy: 0.8538461327552795 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.21969854831695557, Accuracy: 0.892307698726654 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.09270716458559036, Accuracy: 0.892307698726654 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.23240509629249573, Accuracy: 0.8692307472229004 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.03780160844326019, Accuracy: 0.8230769038200378 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.3306201100349426, Accuracy: 0.8692307472229004 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.49889880418777466, Accuracy: 0.8692307472229004 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.03912515193223953, Accuracy: 0.892307698726654 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.1847234070301056, Accuracy: 0.8615384697914124 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.07736773788928986, Accuracy: 0.9230769276618958 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.20936603844165802, Accuracy: 0.8384615182876587 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.1206030622124672, Accuracy: 0.8692307472229004 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.2002379149198532, Accuracy: 0.8538461327552795 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.2939077913761139, Accuracy: 0.8769230842590332 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.08383138477802277, Accuracy: 0.8692307472229004 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.12912042438983917, Accuracy: 0.9230769276618958 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.055493008345365524, Accuracy: 0.9461538195610046 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.31937652826309204, Accuracy: 0.8230769038200378 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.2779207229614258, Accuracy: 0.8692307472229004 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.11314336955547333, Accuracy: 0.8999999761581421 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.1435958445072174, Accuracy: 0.892307698726654 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.45214542746543884, Accuracy: 0.8692307472229004 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.11884133517742157, Accuracy: 0.8846153616905212 % \t time=0.15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.11002825200557709, Accuracy: 0.8692307472229004 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.5053497552871704, Accuracy: 0.8999999761581421 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.09194616973400116, Accuracy: 0.9384615421295166 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.1149885281920433, Accuracy: 0.8999999761581421 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.016813818365335464, Accuracy: 0.9307692050933838 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 1.238769292831421, Accuracy: 0.8153846263885498 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.6086644530296326, Accuracy: 0.9076923131942749 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.20249898731708527, Accuracy: 0.8692307472229004 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.18814440071582794, Accuracy: 0.8384615182876587 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.10586847364902496, Accuracy: 0.9076923131942749 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.18094798922538757, Accuracy: 0.9384615421295166 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.05806288868188858, Accuracy: 0.9307692050933838 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.2862967550754547, Accuracy: 0.9307692050933838 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.16622033715248108, Accuracy: 0.9615384340286255 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.0822882130742073, Accuracy: 0.8846153616905212 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.005984945222735405, Accuracy: 0.9538461565971375 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.10299460589885712, Accuracy: 0.8538461327552795 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.42681044340133667, Accuracy: 0.9153845906257629 % \t time=0.15s\n",
      "******************** Train ********************\n",
      "Loss: 0.16909240186214447, Accuracy: 0.9153845906257629 % \t time=0.15s\n",
      "**********************************************\n",
      "Trn accuracy:0.915 \n"
     ]
    }
   ],
   "source": [
    "predict_pre_1 = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model_temp.train()\n",
    "    avg_loss = 0.\n",
    "    #correct = 0.   # Accuracy\n",
    "    correct_val = 0.\n",
    "        \n",
    "    for batch_idx, trn in enumerate(trn_loader):\n",
    "        trn_X, trn_y = trn['X'], trn['y']\n",
    "        if use_cuda:\n",
    "            trn_X, trn_y = trn_X.cuda(), trn_y.cuda()\n",
    "        trn_X, trn_y = Variable(trn_X).float(), Variable(trn_y).float()\n",
    "        optimizer.zero_grad()\n",
    "        trn_pred = model_temp(trn_X)\n",
    "        for i in trn_pred:\n",
    "            predict_pre_1.append(i.detach().numpy())\n",
    "            \n",
    "        if scheduler:\n",
    "            #print('cycle_LR')\n",
    "            scheduler.batch_step()\n",
    "        #print(trn_pred.squeeze())\n",
    "        #print(trn_y)\n",
    "        trn_loss = criterion(trn_pred.squeeze(), trn_y)\n",
    "        trn_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += trn_loss.item()/len(trn_loader)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        predicted = (trn_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        correct_val += (predicted == trn_y).sum()\n",
    "    print('*'*20, 'Train', '*'*20)\n",
    "    print('Loss: {}, Accuracy: {} % \\t time={:.2f}s'.format(trn_loss.item(), correct_val/(len(trn_loader)*batch_size), elapsed_time))\n",
    "print('*'*46)\n",
    "print(\"Trn accuracy:{:.3f} \".format(float(correct_val) / (len(trn_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 0.])\n",
      "tensor([1, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 1.])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 1., 0.])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([1, 1, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 1., 0.])\n",
      "tensor([1, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 1.])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 1.])\n",
      "tensor([0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0.])\n",
      "******************** Test ********************\n",
      "Loss: 0.16241788864135742, Accuracy: 0.7111111283302307 %\n",
      "**********************************************\n",
      "Val accuracy:0.711\n"
     ]
    }
   ],
   "source": [
    "model_temp.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict_2_temp = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model_temp(val_X)\n",
    "        for i in val_pred:\n",
    "            predict_2_temp.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        #print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        print(val_y)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.805975</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.454256</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.169648</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010601</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.039155</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.543723</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000800</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.697436</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.259694</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.783476</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.590912</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.398407</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.061806</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.385780</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000299</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.253182</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.699488</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.474830</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000003</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000158</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.345787</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.764106</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.027714</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.122558</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.288897</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.673376</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.728359</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.015176</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.872487</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001331</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.735132</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.359677</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.060079</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.886411</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.644131</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.941831</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.101609</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000223</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010635</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.876936</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.273325</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005545</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0            \n",
       "0.805975  1.0\n",
       "0.454256  1.0\n",
       "0.169648  0.0\n",
       "0.010601  0.0\n",
       "0.039155  0.0\n",
       "0.543723  0.0\n",
       "0.000800  0.0\n",
       "0.697436  1.0\n",
       "0.259694  0.0\n",
       "0.783476  1.0\n",
       "0.590912  1.0\n",
       "0.398407  1.0\n",
       "0.061806  0.0\n",
       "0.385780  1.0\n",
       "0.000299  0.0\n",
       "0.253182  0.0\n",
       "0.699488  0.0\n",
       "0.474830  0.0\n",
       "0.000003  0.0\n",
       "0.000158  0.0\n",
       "0.345787  0.0\n",
       "0.764106  1.0\n",
       "0.027714  0.0\n",
       "0.122558  0.0\n",
       "0.288897  0.0\n",
       "0.673376  0.0\n",
       "0.728359  0.0\n",
       "0.015176  0.0\n",
       "0.872487  1.0\n",
       "0.001331  0.0\n",
       "0.735132  0.0\n",
       "0.359677  0.0\n",
       "0.060079  0.0\n",
       "0.886411  0.0\n",
       "0.644131  1.0\n",
       "0.941831  1.0\n",
       "0.101609  1.0\n",
       "0.000223  0.0\n",
       "0.010635  0.0\n",
       "0.876936  1.0\n",
       "0.273325  0.0\n",
       "0.005545  0.0"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict_2_temp)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "#trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  4]\n",
      " [ 6 23]]\n",
      "Accuracy :  0.7619047619047619\n",
      "Sensitivity :  0.6923076923076923\n",
      "Specificity :  0.7931034482758621\n",
      "AUC:  0.7427055702917772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict_2_temp)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "\n",
    "test_p_2 = pd.concat([predict_.iloc[:,0], label, val_label, val_label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p_2.columns = ['predict','label','index_ID', 'ID']\n",
    "test_p_2.loc[test_p_2['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p_2.loc[test_p_2['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/171 (0%)]\tLoss: 0.746858\t Accuracy:50.000%\n",
      "Epoch : 0 [32/171 (18%)]\tLoss: 0.662493\t Accuracy:60.417%\n",
      "Epoch : 0 [64/171 (36%)]\tLoss: 0.704260\t Accuracy:60.000%\n",
      "Epoch : 0 [96/171 (55%)]\tLoss: 0.674394\t Accuracy:66.071%\n",
      "Epoch : 0 [128/171 (73%)]\tLoss: 0.722818\t Accuracy:67.361%\n",
      "Epoch : 0 [110/171 (91%)]\tLoss: 0.599336\t Accuracy:65.909%\n",
      "Epoch : 1 [0/171 (0%)]\tLoss: 0.575366\t Accuracy:87.500%\n",
      "Epoch : 1 [32/171 (18%)]\tLoss: 0.667310\t Accuracy:70.833%\n",
      "Epoch : 1 [64/171 (36%)]\tLoss: 0.673750\t Accuracy:68.750%\n",
      "Epoch : 1 [96/171 (55%)]\tLoss: 0.751240\t Accuracy:67.857%\n",
      "Epoch : 1 [128/171 (73%)]\tLoss: 0.740712\t Accuracy:67.361%\n",
      "Epoch : 1 [110/171 (91%)]\tLoss: 0.710288\t Accuracy:65.909%\n",
      "Epoch : 2 [0/171 (0%)]\tLoss: 0.641428\t Accuracy:62.500%\n",
      "Epoch : 2 [32/171 (18%)]\tLoss: 0.618767\t Accuracy:68.750%\n",
      "Epoch : 2 [64/171 (36%)]\tLoss: 0.619703\t Accuracy:65.000%\n",
      "Epoch : 2 [96/171 (55%)]\tLoss: 0.579154\t Accuracy:65.179%\n",
      "Epoch : 2 [128/171 (73%)]\tLoss: 0.667362\t Accuracy:66.667%\n",
      "Epoch : 2 [110/171 (91%)]\tLoss: 0.572492\t Accuracy:65.909%\n",
      "Epoch : 3 [0/171 (0%)]\tLoss: 0.709065\t Accuracy:75.000%\n",
      "Epoch : 3 [32/171 (18%)]\tLoss: 0.596966\t Accuracy:70.833%\n",
      "Epoch : 3 [64/171 (36%)]\tLoss: 0.615786\t Accuracy:72.500%\n",
      "Epoch : 3 [96/171 (55%)]\tLoss: 0.585047\t Accuracy:68.750%\n",
      "Epoch : 3 [128/171 (73%)]\tLoss: 0.710601\t Accuracy:70.139%\n",
      "Epoch : 3 [110/171 (91%)]\tLoss: 0.893020\t Accuracy:65.909%\n",
      "Epoch : 4 [0/171 (0%)]\tLoss: 0.663931\t Accuracy:68.750%\n",
      "Epoch : 4 [32/171 (18%)]\tLoss: 0.728086\t Accuracy:60.417%\n",
      "Epoch : 4 [64/171 (36%)]\tLoss: 0.655770\t Accuracy:62.500%\n",
      "Epoch : 4 [96/171 (55%)]\tLoss: 0.606156\t Accuracy:65.179%\n",
      "Epoch : 4 [128/171 (73%)]\tLoss: 0.622089\t Accuracy:66.667%\n",
      "Epoch : 4 [110/171 (91%)]\tLoss: 0.579138\t Accuracy:65.909%\n",
      "Epoch : 5 [0/171 (0%)]\tLoss: 0.675125\t Accuracy:68.750%\n",
      "Epoch : 5 [32/171 (18%)]\tLoss: 0.662640\t Accuracy:64.583%\n",
      "Epoch : 5 [64/171 (36%)]\tLoss: 0.550371\t Accuracy:71.250%\n",
      "Epoch : 5 [96/171 (55%)]\tLoss: 0.596231\t Accuracy:69.643%\n",
      "Epoch : 5 [128/171 (73%)]\tLoss: 0.657763\t Accuracy:69.444%\n",
      "Epoch : 5 [110/171 (91%)]\tLoss: 0.628837\t Accuracy:65.909%\n",
      "Epoch : 6 [0/171 (0%)]\tLoss: 0.709476\t Accuracy:62.500%\n",
      "Epoch : 6 [32/171 (18%)]\tLoss: 0.679773\t Accuracy:72.917%\n",
      "Epoch : 6 [64/171 (36%)]\tLoss: 0.579446\t Accuracy:67.500%\n",
      "Epoch : 6 [96/171 (55%)]\tLoss: 0.582037\t Accuracy:68.750%\n",
      "Epoch : 6 [128/171 (73%)]\tLoss: 0.705310\t Accuracy:67.361%\n",
      "Epoch : 6 [110/171 (91%)]\tLoss: 0.729313\t Accuracy:65.909%\n",
      "Epoch : 7 [0/171 (0%)]\tLoss: 0.688270\t Accuracy:62.500%\n",
      "Epoch : 7 [32/171 (18%)]\tLoss: 0.753611\t Accuracy:68.750%\n",
      "Epoch : 7 [64/171 (36%)]\tLoss: 0.588925\t Accuracy:62.500%\n",
      "Epoch : 7 [96/171 (55%)]\tLoss: 0.562787\t Accuracy:65.179%\n",
      "Epoch : 7 [128/171 (73%)]\tLoss: 0.592404\t Accuracy:66.667%\n",
      "Epoch : 7 [110/171 (91%)]\tLoss: 0.673879\t Accuracy:65.909%\n",
      "Epoch : 8 [0/171 (0%)]\tLoss: 0.641790\t Accuracy:81.250%\n",
      "Epoch : 8 [32/171 (18%)]\tLoss: 0.659684\t Accuracy:68.750%\n",
      "Epoch : 8 [64/171 (36%)]\tLoss: 0.469823\t Accuracy:75.000%\n",
      "Epoch : 8 [96/171 (55%)]\tLoss: 0.649886\t Accuracy:68.750%\n",
      "Epoch : 8 [128/171 (73%)]\tLoss: 0.584355\t Accuracy:68.750%\n",
      "Epoch : 8 [110/171 (91%)]\tLoss: 0.712025\t Accuracy:65.909%\n",
      "Epoch : 9 [0/171 (0%)]\tLoss: 0.726692\t Accuracy:56.250%\n",
      "Epoch : 9 [32/171 (18%)]\tLoss: 0.564370\t Accuracy:62.500%\n",
      "Epoch : 9 [64/171 (36%)]\tLoss: 0.594889\t Accuracy:58.750%\n",
      "Epoch : 9 [96/171 (55%)]\tLoss: 0.599691\t Accuracy:63.393%\n",
      "Epoch : 9 [128/171 (73%)]\tLoss: 0.662696\t Accuracy:65.972%\n",
      "Epoch : 9 [110/171 (91%)]\tLoss: 0.608411\t Accuracy:65.909%\n"
     ]
    }
   ],
   "source": [
    "#model = DNN_seq()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "fit(model, trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Test ********************\n",
      "Loss: 0.5934396982192993, Accuracy: 0.7291666865348816 %\n",
      "**********************************************\n",
      "Val accuracy:0.729\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(val_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        val_loss = criterion(val_pred, val_y)\n",
    "        val_loss_summary += val_loss\n",
    "        predicted = torch.max(val_pred.data, 1)[1] \n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(val_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(val_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeClassifier\n",
    "# VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# ensemble 할 model 정의\n",
    "models = [\n",
    "    ('ada', AdaBoostClassifier()),\n",
    "    ('bc', BaggingClassifier()),\n",
    "    ('etc',ExtraTreesClassifier()),\n",
    "    ('gbc', GradientBoostingClassifier()),\n",
    "    ('rfc', RandomForestClassifier()),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('xgb', XGBClassifier()),\n",
    "    ('lgbm', LGBMClassifier()),\n",
    "    ('dtc', DecisionTreeClassifier()),\n",
    "    ('lr', LogisticRegressionCV()),\n",
    "    ('ridge', RidgeClassifier()),\n",
    "]\n",
    "\n",
    "# hard vote\n",
    "hard_vote  = VotingClassifier(models, voting='hard')\n",
    "hard_vote_cv = cross_validate(hard_vote, x_train, y_train, cv=k_fold)\n",
    "hard_vote.fit(x_train, y_train)\n",
    "\n",
    "# soft vote\n",
    "soft_vote  = VotingClassifier(models, voting='soft')\n",
    "soft_vote_cv = cross_validate(soft_vote, x_train, y_train, cv=k_fold)\n",
    "soft_vote.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_seq_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_1, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(0.25),\n",
    "        )\n",
    "        self.classifier2 = nn.Sequential(\n",
    "\n",
    "            torch.nn.Linear(100, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(0.25),\n",
    "            \n",
    "\n",
    "            #torch.nn.Dropout(0.3)\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(250,1, bias=True),\n",
    "            torch.nn.BatchNorm1d(1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[150,200,100,50]\n",
    "#[150,200,100,50,20]\n",
    "\n",
    "class DNN_seq_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_2, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        self.classifier2 = nn.Sequential(    \n",
    "            torch.nn.Linear(100, 50, bias=True),\n",
    "            torch.nn.BatchNorm1d(50),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier3 = nn.Sequential(  \n",
    "            torch.nn.Linear(50, 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            torch.nn.Linear(100, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(250, 1, bias=True),\n",
    "            #nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.classifier3(x_out)\n",
    "        #x_out = self.classifier4(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[150,200,100,50]\n",
    "#[150,200,100,50,20]\n",
    "\n",
    "class DNN_seq_2mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_2mod, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        self.classifier2 = nn.Sequential(    \n",
    "            torch.nn.Linear(100, 50, bias=True),\n",
    "            torch.nn.BatchNorm1d(50),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier3 = nn.Sequential(  \n",
    "            torch.nn.Linear(50, 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        self.classifier4 = nn.Sequential(\n",
    "            torch.nn.Linear(100, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(250, 1, bias=True),\n",
    "            #nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.classifier3(x_out)\n",
    "        x_out = self.classifier4(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[150,200,100,50]\n",
    "#[150,200,100,50,20]\n",
    "\n",
    "class DNN_seq_3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_3, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 150, bias=True),\n",
    "            torch.nn.BatchNorm1d(150),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        self.classifier2 = nn.Sequential(    \n",
    "            torch.nn.Linear(150, 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier3 = nn.Sequential(  \n",
    "            torch.nn.Linear(100, 150, bias=True),\n",
    "            torch.nn.BatchNorm1d(150),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            torch.nn.Linear(150, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(250, 1, bias=True),\n",
    "            #nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.classifier3(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[150,200,100,50]\n",
    "#[150,200,100,50,20]\n",
    "\n",
    "class DNN_seq_new(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_new, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]),200, bias=True),\n",
    "            torch.nn.BatchNorm1d(200),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.30),\n",
    "        )\n",
    "        \n",
    "        self.classifier2 = nn.Sequential(    \n",
    "            torch.nn.Linear(200, 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.30),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier3 = nn.Sequential(  \n",
    "            torch.nn.Linear(100, 50, bias=True),\n",
    "            torch.nn.BatchNorm1d(50),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(0.30),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(50, 1, bias=True),\n",
    "            #nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.classifier3(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_X = torch.from_numpy(trn_X_pd.astype(float))\n",
    "trn_y = torch.from_numpy(trn_y_pd.astype(float))\n",
    "\n",
    "val_X = torch.from_numpy(val_X_pd.astype(float))\n",
    "val_y = torch.from_numpy(val_y_pd.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = Dataset(trn_X, trn_y)\n",
    "trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "\n",
    "trn_test_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "val = Dataset(val_X, val_y)\n",
    "test_loader = data_utils.DataLoader(val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model_1 = DNN_seq_1()    \n",
    "\n",
    "## After just second, will modify optimizer(weight_decay,step_size, base_lr, max_lr,scheduler)\n",
    "optimizer = optim.Adam(model_1.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "    \n",
    "model_1 = DNN_seq_1()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "num_epochs = 70\n",
    "    \n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "##############################################################################\n",
    "step_size = 2000\n",
    "base_lr, max_lr = 0.001, 0.01  \n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model_1.parameters()), \n",
    "                             lr=max_lr)\n",
    "    \n",
    "scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr, step_size=step_size, mode='exp_range', gamma=0.99994)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.584441065788269, Accuracy: 0.6846153736114502 % \t time=0.14s\n",
      "******************** Train ********************\n",
      "Loss: 0.37215694785118103, Accuracy: 0.7769230604171753 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.2013917863368988, Accuracy: 0.8307692408561707 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.1639670431613922, Accuracy: 0.892307698726654 % \t time=0.13s\n",
      "******************** Train ********************\n",
      "Loss: 0.31819847226142883, Accuracy: 0.9076923131942749 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.07631389796733856, Accuracy: 0.8999999761581421 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.11699125915765762, Accuracy: 0.9538461565971375 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.05854858085513115, Accuracy: 0.9538461565971375 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.01869424805045128, Accuracy: 0.9769230484962463 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.01622634381055832, Accuracy: 0.9769230484962463 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.3643389642238617, Accuracy: 0.9461538195610046 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.03957225754857063, Accuracy: 0.9538461565971375 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.023539502173662186, Accuracy: 0.9076923131942749 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.08338656276464462, Accuracy: 0.892307698726654 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.03230597451329231, Accuracy: 0.9538461565971375 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.05964071676135063, Accuracy: 0.9538461565971375 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.5054712891578674, Accuracy: 0.9461538195610046 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.27766385674476624, Accuracy: 0.9461538195610046 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.2669956088066101, Accuracy: 0.9615384340286255 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.032076843082904816, Accuracy: 0.9846153855323792 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.001896990230306983, Accuracy: 0.9384615421295166 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.008772404864430428, Accuracy: 0.9307692050933838 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.07394637912511826, Accuracy: 0.9615384340286255 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.09064079821109772, Accuracy: 0.9846153855323792 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.04985080286860466, Accuracy: 0.9538461565971375 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.003176232101395726, Accuracy: 0.9461538195610046 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.07562938332557678, Accuracy: 0.9692307710647583 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.05728551745414734, Accuracy: 0.9461538195610046 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.02919972501695156, Accuracy: 0.9538461565971375 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.02650790475308895, Accuracy: 0.9153845906257629 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 1.3754534721374512, Accuracy: 0.9384615421295166 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.43378114700317383, Accuracy: 0.9153845906257629 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.05278131365776062, Accuracy: 0.9538461565971375 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.04737482964992523, Accuracy: 0.9692307710647583 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.32454678416252136, Accuracy: 0.9769230484962463 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.004082932136952877, Accuracy: 0.9461538195610046 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.0034921958576887846, Accuracy: 0.9692307710647583 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.023378314450383186, Accuracy: 0.9692307710647583 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.0032935861963778734, Accuracy: 0.9615384340286255 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.001613215310499072, Accuracy: 0.9692307710647583 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.125937357544899, Accuracy: 0.9769230484962463 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.020585274323821068, Accuracy: 0.9538461565971375 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.9471765756607056, Accuracy: 0.9230769276618958 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.042304106056690216, Accuracy: 0.9461538195610046 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.03266642615199089, Accuracy: 0.9538461565971375 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.259342759847641, Accuracy: 0.9461538195610046 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.028841953724622726, Accuracy: 0.9769230484962463 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.0074128657579422, Accuracy: 0.9923076629638672 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.003948704339563847, Accuracy: 1.0 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.24159368872642517, Accuracy: 0.9846153855323792 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.002032170770689845, Accuracy: 0.9615384340286255 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.04339831322431564, Accuracy: 0.9769230484962463 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.005807847715914249, Accuracy: 0.9384615421295166 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.020764803513884544, Accuracy: 0.9692307710647583 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.4161107540130615, Accuracy: 0.9615384340286255 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.1705012023448944, Accuracy: 0.9461538195610046 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.8501667976379395, Accuracy: 0.9461538195610046 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.0065132565796375275, Accuracy: 0.9461538195610046 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.045334309339523315, Accuracy: 0.9692307710647583 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.0373476967215538, Accuracy: 0.892307698726654 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.031001150608062744, Accuracy: 0.9076923131942749 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.030285846441984177, Accuracy: 0.9461538195610046 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.05019809678196907, Accuracy: 0.9769230484962463 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.3837043046951294, Accuracy: 0.9923076629638672 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.005784239619970322, Accuracy: 0.9615384340286255 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.07769088447093964, Accuracy: 0.9384615421295166 % \t time=0.12s\n",
      "******************** Train ********************\n",
      "Loss: 0.0027836784720420837, Accuracy: 0.9384615421295166 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.09740423411130905, Accuracy: 0.9692307710647583 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.011354624293744564, Accuracy: 0.9461538195610046 % \t time=0.11s\n",
      "******************** Train ********************\n",
      "Loss: 0.05472130328416824, Accuracy: 0.9692307710647583 % \t time=0.11s\n",
      "**********************************************\n",
      "Trn accuracy:0.969 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predict = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model_1.train()\n",
    "    avg_loss = 0.\n",
    "    #correct = 0.   # Accuracy\n",
    "    correct_val = 0.\n",
    "        \n",
    "    for batch_idx, trn in enumerate(trn_loader):\n",
    "        trn_X, trn_y = trn['X'], trn['y']\n",
    "        if use_cuda:\n",
    "            trn_X, trn_y = trn_X.cuda(), trn_y.cuda()\n",
    "        trn_X, trn_y = Variable(trn_X).float(), Variable(trn_y).float()\n",
    "        optimizer.zero_grad()\n",
    "        trn_pred = model_1(trn_X)\n",
    "        for i in trn_pred:\n",
    "            predict.append(i.detach().numpy())\n",
    "            \n",
    "        if scheduler:\n",
    "            #print('cycle_LR')\n",
    "            scheduler.batch_step()\n",
    "        #print(trn_pred.squeeze())\n",
    "        #print(trn_y)\n",
    "        trn_loss = criterion(trn_pred.squeeze(), trn_y)\n",
    "        trn_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += trn_loss.item()/len(trn_loader)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        predicted = (trn_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        correct_val += (predicted == trn_y).sum()\n",
    "    print('*'*20, 'Train', '*'*20)\n",
    "    print('Loss: {}, Accuracy: {} % \\t time={:.2f}s'.format(trn_loss.item(), correct_val/(len(trn_loader)*batch_size), elapsed_time))\n",
    "print('*'*46)\n",
    "print(\"Trn accuracy:{:.3f} \".format(float(correct_val) / (len(trn_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 1e-3\n",
    "model_2 = DNN_seq_2()   \n",
    "## After just second, will modify optimizer(weight_decay,step_size, base_lr, max_lr,scheduler)\n",
    "optimizer = optim.Adam(model_2.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "    \n",
    "model_2 = DNN_seq_2()\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "num_epochs = 90\n",
    "    \n",
    "if use_cuda:\n",
    "    model_2 = model_2.cuda()\n",
    "    \n",
    "##############################################################################\n",
    "step_size = 2000\n",
    "base_lr, max_lr = 0.001, 0.01  \n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model_2.parameters()), \n",
    "                             lr=max_lr)\n",
    "    \n",
    "scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr, step_size=step_size, mode='exp_range', gamma=0.99994)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.8320714831352234, Accuracy: 0.6666666865348816 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.5061639547348022, Accuracy: 0.6909090876579285 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.5217592120170593, Accuracy: 0.6909090876579285 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.688666582107544, Accuracy: 0.7151514887809753 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.30240315198898315, Accuracy: 0.7030302882194519 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.4755634665489197, Accuracy: 0.7272727489471436 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.3247077167034149, Accuracy: 0.7151514887809753 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.5992145538330078, Accuracy: 0.7030302882194519 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 1.1018040180206299, Accuracy: 0.7333333492279053 % \t time=0.30s\n",
      "******************** Train ********************\n",
      "Loss: 0.2680153250694275, Accuracy: 0.7757575511932373 % \t time=0.26s\n",
      "******************** Train ********************\n",
      "Loss: 0.38285356760025024, Accuracy: 0.739393949508667 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.34921783208847046, Accuracy: 0.7878788113594055 % \t time=0.25s\n",
      "******************** Train ********************\n",
      "Loss: 0.41115617752075195, Accuracy: 0.8060606122016907 % \t time=0.29s\n",
      "******************** Train ********************\n",
      "Loss: 0.39183324575424194, Accuracy: 0.8121212124824524 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.18562355637550354, Accuracy: 0.7757575511932373 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.15294837951660156, Accuracy: 0.7757575511932373 % \t time=0.26s\n",
      "******************** Train ********************\n",
      "Loss: 0.4483680725097656, Accuracy: 0.7818182110786438 % \t time=0.32s\n",
      "******************** Train ********************\n",
      "Loss: 0.11987479776144028, Accuracy: 0.8303030133247375 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.2937152683734894, Accuracy: 0.800000011920929 % \t time=0.27s\n",
      "******************** Train ********************\n",
      "Loss: 0.16365878283977509, Accuracy: 0.8363636136054993 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 1.0398935079574585, Accuracy: 0.800000011920929 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.13279631733894348, Accuracy: 0.8545454740524292 % \t time=0.27s\n",
      "******************** Train ********************\n",
      "Loss: 0.29421302676200867, Accuracy: 0.8848484754562378 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.2959425449371338, Accuracy: 0.8727272748947144 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.35249435901641846, Accuracy: 0.8787878751754761 % \t time=0.27s\n",
      "******************** Train ********************\n",
      "Loss: 0.1557164490222931, Accuracy: 0.8606060743331909 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.1376965045928955, Accuracy: 0.8545454740524292 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.12174931913614273, Accuracy: 0.8727272748947144 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.09971518814563751, Accuracy: 0.8363636136054993 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.11906150728464127, Accuracy: 0.8787878751754761 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.11038491874933243, Accuracy: 0.8787878751754761 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.6947794556617737, Accuracy: 0.8727272748947144 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.22412142157554626, Accuracy: 0.8969696760177612 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.04936625808477402, Accuracy: 0.8727272748947144 % \t time=0.26s\n",
      "******************** Train ********************\n",
      "Loss: 0.6925634145736694, Accuracy: 0.842424213886261 % \t time=0.27s\n",
      "******************** Train ********************\n",
      "Loss: 0.36896175146102905, Accuracy: 0.8606060743331909 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.548803448677063, Accuracy: 0.8787878751754761 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.5642233490943909, Accuracy: 0.8363636136054993 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.08016965538263321, Accuracy: 0.8727272748947144 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.4447055757045746, Accuracy: 0.903030276298523 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.09040019661188126, Accuracy: 0.9212121367454529 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.48516377806663513, Accuracy: 0.8787878751754761 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.21674148738384247, Accuracy: 0.8363636136054993 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.17401538789272308, Accuracy: 0.8181818127632141 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.14254969358444214, Accuracy: 0.903030276298523 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.07312439382076263, Accuracy: 0.8909090757369995 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.22940976917743683, Accuracy: 0.8303030133247375 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 1.1201388835906982, Accuracy: 0.8848484754562378 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.0605199858546257, Accuracy: 0.8545454740524292 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.5268864035606384, Accuracy: 0.8787878751754761 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.21853189170360565, Accuracy: 0.8121212124824524 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.2276483029127121, Accuracy: 0.8727272748947144 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.06436832249164581, Accuracy: 0.8909090757369995 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.10297219455242157, Accuracy: 0.8787878751754761 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.08048044145107269, Accuracy: 0.8606060743331909 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.06816823780536652, Accuracy: 0.8606060743331909 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.08528260886669159, Accuracy: 0.9090909361839294 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.890093982219696, Accuracy: 0.8909090757369995 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.43632015585899353, Accuracy: 0.8606060743331909 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.060241829603910446, Accuracy: 0.8666666746139526 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.08587463200092316, Accuracy: 0.8969696760177612 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.025284763425588608, Accuracy: 0.8909090757369995 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.27333909273147583, Accuracy: 0.8909090757369995 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.03455236554145813, Accuracy: 0.8909090757369995 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.2952330708503723, Accuracy: 0.9090909361839294 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.41700226068496704, Accuracy: 0.9090909361839294 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.19306352734565735, Accuracy: 0.8727272748947144 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.15439298748970032, Accuracy: 0.8969696760177612 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.15874776244163513, Accuracy: 0.9212121367454529 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.408721387386322, Accuracy: 0.9272727370262146 % \t time=0.21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.5444689393043518, Accuracy: 0.8909090757369995 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.86505526304245, Accuracy: 0.903030276298523 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.2206982672214508, Accuracy: 0.8969696760177612 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 1.9621505737304688, Accuracy: 0.903030276298523 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.19641944766044617, Accuracy: 0.8909090757369995 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.06559957563877106, Accuracy: 0.9090909361839294 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.02798665501177311, Accuracy: 0.903030276298523 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.08178630471229553, Accuracy: 0.9212121367454529 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.02175176329910755, Accuracy: 0.903030276298523 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.5981972813606262, Accuracy: 0.8848484754562378 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 4.251283645629883, Accuracy: 0.8787878751754761 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.4898458421230316, Accuracy: 0.8606060743331909 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.06279140710830688, Accuracy: 0.939393937587738 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.011052018962800503, Accuracy: 0.9272727370262146 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.15461228787899017, Accuracy: 0.9151515364646912 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.5666688680648804, Accuracy: 0.8969696760177612 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.4562687277793884, Accuracy: 0.8909090757369995 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.12959355115890503, Accuracy: 0.903030276298523 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 1.5278098583221436, Accuracy: 0.8666666746139526 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.5325064659118652, Accuracy: 0.939393937587738 % \t time=0.22s\n",
      "**********************************************\n",
      "Trn accuracy:0.939 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predict = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    #correct = 0.   # Accuracy\n",
    "    correct_val = 0.\n",
    "        \n",
    "    for batch_idx, trn in enumerate(trn_loader):\n",
    "        trn_X, trn_y = trn['X'], trn['y']\n",
    "        if use_cuda:\n",
    "            trn_X, trn_y = trn_X.cuda(), trn_y.cuda()\n",
    "        trn_X, trn_y = Variable(trn_X).float(), Variable(trn_y).float()\n",
    "        optimizer.zero_grad()\n",
    "        trn_pred = model_2(trn_X)\n",
    "        for i in trn_pred:\n",
    "            predict.append(i.detach().numpy())\n",
    "            \n",
    "        if scheduler:\n",
    "            #print('cycle_LR')\n",
    "            scheduler.batch_step()\n",
    "        #print(trn_pred.squeeze())\n",
    "        #print(trn_y)\n",
    "        trn_loss = criterion(trn_pred.squeeze(), trn_y)\n",
    "        trn_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += trn_loss.item()/len(trn_loader)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        predicted = (trn_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        correct_val += (predicted == trn_y).sum()\n",
    "    print('*'*20, 'Train', '*'*20)\n",
    "    print('Loss: {}, Accuracy: {} % \\t time={:.2f}s'.format(trn_loss.item(), correct_val/(len(trn_loader)*batch_size), elapsed_time))\n",
    "print('*'*46)\n",
    "print(\"Trn accuracy:{:.3f} \".format(float(correct_val) / (len(trn_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 1e-3\n",
    "model_3 = DNN_seq_new()   \n",
    "## After just second, will modify optimizer(weight_decay,step_size, base_lr, max_lr,scheduler)\n",
    "optimizer = optim.Adam(model_3.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "    \n",
    "model_3 = DNN_seq_new()\n",
    "\n",
    "\n",
    "##\n",
    "use_cuda = torch.cuda.is_available()\n",
    "num_epochs = 90\n",
    "    \n",
    "if use_cuda:\n",
    "    model_3 = model_3.cuda()\n",
    "    \n",
    "##############################################################################\n",
    "step_size = 2000\n",
    "base_lr, max_lr = 0.001, 0.01  \n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model_3.parameters()), \n",
    "                             lr=max_lr)\n",
    "    \n",
    "scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr, step_size=step_size, mode='exp_range', gamma=0.99994)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.6863959431648254, Accuracy: 0.6181818246841431 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.3292355537414551, Accuracy: 0.7272727489471436 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.562929093837738, Accuracy: 0.7696969509124756 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.4331723153591156, Accuracy: 0.800000011920929 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.30614250898361206, Accuracy: 0.8666666746139526 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.4113381505012512, Accuracy: 0.8909090757369995 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.15512089431285858, Accuracy: 0.9151515364646912 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.3054869771003723, Accuracy: 0.9090909361839294 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.7388367652893066, Accuracy: 0.8848484754562378 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.45716747641563416, Accuracy: 0.8787878751754761 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.2990034818649292, Accuracy: 0.8606060743331909 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.08711602538824081, Accuracy: 0.939393937587738 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.05155285447835922, Accuracy: 0.8969696760177612 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.6205047369003296, Accuracy: 0.9272727370262146 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 1.3045388460159302, Accuracy: 0.9272727370262146 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.06299000978469849, Accuracy: 0.8606060743331909 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.22034578025341034, Accuracy: 0.9636363387107849 % \t time=0.29s\n",
      "******************** Train ********************\n",
      "Loss: 0.08460579812526703, Accuracy: 0.8969696760177612 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.021170565858483315, Accuracy: 0.9636363387107849 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.01695220172405243, Accuracy: 0.8969696760177612 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.12365090847015381, Accuracy: 0.9272727370262146 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.24765388667583466, Accuracy: 0.9272727370262146 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.1879972517490387, Accuracy: 0.9575757384300232 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.06825612485408783, Accuracy: 0.8909090757369995 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.036385003477334976, Accuracy: 0.8909090757369995 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.10776140540838242, Accuracy: 0.9212121367454529 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.04284865781664848, Accuracy: 0.9272727370262146 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 1.259967565536499, Accuracy: 0.9151515364646912 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.035845886915922165, Accuracy: 0.9454545378684998 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.04077686369419098, Accuracy: 0.9757575988769531 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.07024114578962326, Accuracy: 0.9333333373069763 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.4035201668739319, Accuracy: 0.9333333373069763 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.5144262313842773, Accuracy: 0.9454545378684998 % \t time=0.25s\n",
      "******************** Train ********************\n",
      "Loss: 0.26344338059425354, Accuracy: 0.9515151381492615 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.19296038150787354, Accuracy: 0.9272727370262146 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.155012845993042, Accuracy: 0.9333333373069763 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.04916659742593765, Accuracy: 0.9333333373069763 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.2742224335670471, Accuracy: 0.8969696760177612 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 1.149343490600586, Accuracy: 0.9151515364646912 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.10916280746459961, Accuracy: 0.9212121367454529 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.032469745725393295, Accuracy: 0.9575757384300232 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.011871912516653538, Accuracy: 0.9151515364646912 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.12561361491680145, Accuracy: 0.9272727370262146 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.38434889912605286, Accuracy: 0.9151515364646912 % \t time=0.29s\n",
      "******************** Train ********************\n",
      "Loss: 0.023413050919771194, Accuracy: 0.9333333373069763 % \t time=0.32s\n",
      "******************** Train ********************\n",
      "Loss: 0.8264741897583008, Accuracy: 0.9212121367454529 % \t time=0.33s\n",
      "******************** Train ********************\n",
      "Loss: 0.11561979353427887, Accuracy: 0.9636363387107849 % \t time=0.31s\n",
      "******************** Train ********************\n",
      "Loss: 0.01152101345360279, Accuracy: 0.9636363387107849 % \t time=0.28s\n",
      "******************** Train ********************\n",
      "Loss: 0.07262877374887466, Accuracy: 0.9515151381492615 % \t time=0.29s\n",
      "******************** Train ********************\n",
      "Loss: 0.016942119225859642, Accuracy: 0.9757575988769531 % \t time=0.30s\n",
      "******************** Train ********************\n",
      "Loss: 0.041822195053100586, Accuracy: 0.9515151381492615 % \t time=0.29s\n",
      "******************** Train ********************\n",
      "Loss: 0.25315061211586, Accuracy: 0.9454545378684998 % \t time=0.29s\n",
      "******************** Train ********************\n",
      "Loss: 0.19006451964378357, Accuracy: 0.9333333373069763 % \t time=0.30s\n",
      "******************** Train ********************\n",
      "Loss: 0.270860880613327, Accuracy: 0.9696969985961914 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.03298868238925934, Accuracy: 0.9696969985961914 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.002679008524864912, Accuracy: 0.9454545378684998 % \t time=0.29s\n",
      "******************** Train ********************\n",
      "Loss: 0.0019090936984866858, Accuracy: 0.9696969985961914 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.03475744649767876, Accuracy: 0.9878787994384766 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 1.5551602840423584, Accuracy: 0.9090909361839294 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.24963566660881042, Accuracy: 0.939393937587738 % \t time=0.32s\n",
      "******************** Train ********************\n",
      "Loss: 0.03477690741419792, Accuracy: 0.9272727370262146 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.03614295646548271, Accuracy: 0.9454545378684998 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.014212151058018208, Accuracy: 0.9454545378684998 % \t time=0.25s\n",
      "******************** Train ********************\n",
      "Loss: 0.1163865178823471, Accuracy: 0.9212121367454529 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.026377374306321144, Accuracy: 0.9636363387107849 % \t time=0.26s\n",
      "******************** Train ********************\n",
      "Loss: 0.011383039876818657, Accuracy: 0.9636363387107849 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.004159665200859308, Accuracy: 0.9696969985961914 % \t time=0.32s\n",
      "******************** Train ********************\n",
      "Loss: 0.006525888107717037, Accuracy: 0.9454545378684998 % \t time=0.25s\n",
      "******************** Train ********************\n",
      "Loss: 0.011287414468824863, Accuracy: 0.9333333373069763 % \t time=0.28s\n",
      "******************** Train ********************\n",
      "Loss: 0.08309925347566605, Accuracy: 0.9515151381492615 % \t time=0.19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.09617182612419128, Accuracy: 0.9454545378684998 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.02341035008430481, Accuracy: 0.9333333373069763 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.0630071833729744, Accuracy: 0.9575757384300232 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.9255126714706421, Accuracy: 0.9454545378684998 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.01234782487154007, Accuracy: 0.9212121367454529 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.002612736541777849, Accuracy: 0.9696969985961914 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.03966129943728447, Accuracy: 0.9818181991577148 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.07900598645210266, Accuracy: 0.9515151381492615 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.010768515057861805, Accuracy: 0.9272727370262146 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.04678342863917351, Accuracy: 0.9696969985961914 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.01828468218445778, Accuracy: 0.9575757384300232 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.2029179036617279, Accuracy: 0.9878787994384766 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.046877168118953705, Accuracy: 0.9818181991577148 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.02203470841050148, Accuracy: 0.9696969985961914 % \t time=0.16s\n",
      "******************** Train ********************\n",
      "Loss: 0.041298605501651764, Accuracy: 0.9878787994384766 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.007639135234057903, Accuracy: 0.9757575988769531 % \t time=0.17s\n",
      "******************** Train ********************\n",
      "Loss: 0.014037017710506916, Accuracy: 0.9575757384300232 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.005132630001753569, Accuracy: 0.9757575988769531 % \t time=0.19s\n",
      "******************** Train ********************\n",
      "Loss: 0.005940111353993416, Accuracy: 0.9757575988769531 % \t time=0.28s\n",
      "******************** Train ********************\n",
      "Loss: 0.0036199986934661865, Accuracy: 0.9757575988769531 % \t time=0.18s\n",
      "**********************************************\n",
      "Trn accuracy:0.976 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#predict = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    #correct = 0.   # Accuracy\n",
    "    correct_val = 0.\n",
    "        \n",
    "    for batch_idx, trn in enumerate(trn_loader):\n",
    "        trn_X, trn_y = trn['X'], trn['y']\n",
    "        if use_cuda:\n",
    "            trn_X, trn_y = trn_X.cuda(), trn_y.cuda()\n",
    "        trn_X, trn_y = Variable(trn_X).float(), Variable(trn_y).float()\n",
    "        optimizer.zero_grad()\n",
    "        trn_pred = model_3(trn_X)\n",
    "        #for i in trn_pred:\n",
    "        #    predict.append(i.detach().numpy())\n",
    "            \n",
    "        if scheduler:\n",
    "            #print('cycle_LR')\n",
    "            scheduler.batch_step()\n",
    "        #print(trn_pred.squeeze())\n",
    "        #print(trn_y)\n",
    "        trn_loss = criterion(trn_pred.squeeze(), trn_y)\n",
    "        trn_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += trn_loss.item()/len(trn_loader)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        predicted = (trn_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        correct_val += (predicted == trn_y).sum()\n",
    "    print('*'*20, 'Train', '*'*20)\n",
    "    print('Loss: {}, Accuracy: {} % \\t time={:.2f}s'.format(trn_loss.item(), correct_val/(len(trn_loader)*batch_size), elapsed_time))\n",
    "print('*'*46)\n",
    "print(\"Trn accuracy:{:.3f} \".format(float(correct_val) / (len(trn_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 0.])\n",
      "tensor([1, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 1.])\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 1., 0.])\n",
      "tensor([0, 1, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([1, 1, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 1., 0.])\n",
      "tensor([1, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 1.])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 1.])\n",
      "tensor([0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0.])\n",
      "******************** Test ********************\n",
      "Loss: 0.1342855840921402, Accuracy: 0.6888889074325562 %\n",
      "**********************************************\n",
      "Val accuracy:0.689\n"
     ]
    }
   ],
   "source": [
    "model_1.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict_1 = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model_1(val_X)\n",
    "        for i in val_pred:\n",
    "            predict_1.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        #print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        print(val_y)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9.762787e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.681830e-02</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.301538e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.546975e-07</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.442643e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.398000e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.629387e-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.875772e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.526865e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.548151e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.480246e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.086496e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.743067e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.413304e-02</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.636050e-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.450371e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.395835e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.912666e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.476366e-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.216386e-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.192121e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.708781e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.196090e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.033346e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.223607e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.680074e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.306922e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.067044e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.752141e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.162556e-13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.118645e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.000411e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.483174e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.862286e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.126378e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.913958e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.872928e-06</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.287785e-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.190172e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.832146e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.355235e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.132759e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0                \n",
       "9.762787e-01  1.0\n",
       "7.681830e-02  1.0\n",
       "3.301538e-01  0.0\n",
       "1.546975e-07  0.0\n",
       "6.442643e-06  0.0\n",
       "7.398000e-01  0.0\n",
       "2.629387e-08  0.0\n",
       "8.875772e-01  1.0\n",
       "1.526865e-01  0.0\n",
       "9.548151e-01  1.0\n",
       "7.480246e-01  1.0\n",
       "5.086496e-01  1.0\n",
       "9.743067e-03  0.0\n",
       "7.413304e-02  1.0\n",
       "4.636050e-08  0.0\n",
       "4.450371e-03  0.0\n",
       "8.395835e-01  0.0\n",
       "6.912666e-01  0.0\n",
       "4.476366e-08  0.0\n",
       "1.216386e-08  0.0\n",
       "7.192121e-01  0.0\n",
       "8.708781e-01  1.0\n",
       "5.196090e-02  0.0\n",
       "1.033346e-03  0.0\n",
       "4.223607e-01  0.0\n",
       "5.680074e-01  0.0\n",
       "6.306922e-01  0.0\n",
       "1.067044e-06  0.0\n",
       "9.752141e-01  1.0\n",
       "2.162556e-13  0.0\n",
       "9.118645e-01  0.0\n",
       "4.000411e-01  0.0\n",
       "1.483174e-04  0.0\n",
       "9.862286e-01  0.0\n",
       "7.126378e-01  1.0\n",
       "9.913958e-01  1.0\n",
       "8.872928e-06  1.0\n",
       "1.287785e-08  0.0\n",
       "2.190172e-03  0.0\n",
       "9.832146e-01  1.0\n",
       "2.355235e-01  0.0\n",
       "7.132759e-06  0.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict_1)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "#trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  3]\n",
      " [ 8 21]]\n",
      "Accuracy :  0.7380952380952381\n",
      "Sensitivity :  0.7692307692307693\n",
      "Specificity :  0.7241379310344828\n",
      "AUC:  0.746684350132626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict_1)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_load check\n"
     ]
    }
   ],
   "source": [
    "if (model_load == 1):\n",
    "    model_2 = DNN_seq_2()\n",
    "    #model = TheModelClass(*args, **kwargs)                                                                                                     \n",
    "    #optimizer = TheOptimizerClass(*args, **kwargs)                                                                                             \n",
    "    checkpoint = torch.load(\"./platin_model_save/platin_model_250_50_100_model_1_100_250_Semi_Final_Voting_test_2.pth\")                                                                                  \n",
    "    model_2.load_state_dict(checkpoint['model_state_dict'])                                                                                         \n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])                                                                               \n",
    "    #num_epochs = checkpoint['epoch']                                                                                                           \n",
    "    loss = checkpoint['loss']                                                                                                                   \n",
    "    #model.eval() \n",
    "    print('model_load check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 0.])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 1.])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 1., 0.])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 1., 0.])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 1.])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 1.])\n",
      "tensor([0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0.])\n",
      "******************** Test ********************\n",
      "Loss: 0.021410737186670303, Accuracy: 0.7333333492279053 %\n",
      "**********************************************\n",
      "Val accuracy:0.733\n"
     ]
    }
   ],
   "source": [
    "model_2.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict_2 = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model_2(val_X)\n",
    "        for i in val_pred:\n",
    "            predict_2.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        #print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        print(val_y)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5.568392e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.307219e-02</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.053841e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.673898e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.432269e-07</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.467769e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.366220e-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.193180e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.399535e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.591291e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.208362e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.555768e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.517349e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.272412e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.194334e-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.102896e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.967533e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.953551e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.937189e-09</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.482032e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.465105e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.239356e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.135628e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.767242e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.921774e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.303619e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.062773e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.083706e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.538557e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.263378e-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.214971e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.454651e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.617995e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.496148e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.334413e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.414215e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.287787e-03</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.743025e-11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.369618e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.816279e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.191536e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.304033e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0                \n",
       "5.568392e-01  1.0\n",
       "8.307219e-02  1.0\n",
       "4.053841e-02  0.0\n",
       "4.673898e-04  0.0\n",
       "7.432269e-07  0.0\n",
       "1.467769e-01  0.0\n",
       "4.366220e-08  0.0\n",
       "5.193180e-01  1.0\n",
       "6.399535e-02  0.0\n",
       "4.591291e-01  1.0\n",
       "2.208362e-01  1.0\n",
       "1.555768e-01  1.0\n",
       "7.517349e-04  0.0\n",
       "2.272412e-01  1.0\n",
       "4.194334e-08  0.0\n",
       "1.102896e-02  0.0\n",
       "2.967533e-01  0.0\n",
       "4.953551e-02  0.0\n",
       "7.937189e-09  0.0\n",
       "1.482032e-06  0.0\n",
       "2.465105e-01  0.0\n",
       "4.239356e-01  1.0\n",
       "1.135628e-04  0.0\n",
       "3.767242e-02  0.0\n",
       "1.921774e-01  0.0\n",
       "7.303619e-02  0.0\n",
       "2.062773e-01  0.0\n",
       "9.083706e-06  0.0\n",
       "7.538557e-01  1.0\n",
       "7.263378e-08  0.0\n",
       "3.214971e-01  0.0\n",
       "1.454651e-02  0.0\n",
       "8.617995e-05  0.0\n",
       "6.496148e-01  0.0\n",
       "1.334413e-01  1.0\n",
       "7.414215e-01  1.0\n",
       "7.287787e-03  1.0\n",
       "1.743025e-11  0.0\n",
       "4.369618e-02  0.0\n",
       "6.816279e-01  1.0\n",
       "4.191536e-02  0.0\n",
       "2.304033e-06  0.0"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict_2)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "#trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  8]\n",
      " [ 1 28]]\n",
      "Accuracy :  0.7857142857142857\n",
      "Sensitivity :  0.38461538461538464\n",
      "Specificity :  0.9655172413793104\n",
      "AUC:  0.6750663129973474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict_2)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "\n",
    "test_p_2 = pd.concat([predict_.iloc[:,0], label, val_label, val_label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p_2.columns = ['predict','label','index_ID', 'ID']\n",
    "test_p_2.loc[test_p_2['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p_2.loc[test_p_2['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   predict  label            ID  predicted_prob\n",
      "index_ID                                                       \n",
      "TCGA-23-1027  5.351465e-01    1.0  TCGA-23-1027             1.0\n",
      "TCGA-36-1580  8.351165e-02    1.0  TCGA-36-1580             0.0\n",
      "TCGA-29-1769  4.226791e-02    0.0  TCGA-29-1769             0.0\n",
      "TCGA-23-1122  5.597841e-04    0.0  TCGA-23-1122             0.0\n",
      "TCGA-24-1474  9.908041e-07    0.0  TCGA-24-1474             0.0\n",
      "TCGA-10-0927  1.434996e-01    0.0  TCGA-10-0927             0.0\n",
      "TCGA-61-1914  5.851045e-08    0.0  TCGA-61-1914             0.0\n",
      "TCGA-29-1703  4.999270e-01    1.0  TCGA-29-1703             0.0\n",
      "TCGA-04-1365  6.453138e-02    0.0  TCGA-04-1365             0.0\n",
      "TCGA-29-1696  4.383163e-01    1.0  TCGA-29-1696             0.0\n",
      "TCGA-13-1483  2.164667e-01    1.0  TCGA-13-1483             0.0\n",
      "TCGA-61-1738  1.513424e-01    1.0  TCGA-61-1738             0.0\n",
      "TCGA-61-1911  8.708345e-04    0.0  TCGA-61-1911             0.0\n",
      "TCGA-25-2393  2.225501e-01    1.0  TCGA-25-2393             0.0\n",
      "TCGA-09-1667  5.703374e-08    0.0  TCGA-09-1667             0.0\n",
      "TCGA-61-2097  1.178192e-02    0.0  TCGA-61-2097             0.0\n",
      "TCGA-29-2414  2.875663e-01    0.0  TCGA-29-2414             0.0\n",
      "TCGA-24-1563  5.067045e-02    0.0  TCGA-24-1563             0.0\n",
      "TCGA-09-0364  1.027376e-08    0.0  TCGA-09-0364             0.0\n",
      "TCGA-04-1651  1.884282e-06    0.0  TCGA-04-1651             0.0\n",
      "TCGA-24-1551  2.391759e-01    0.0  TCGA-24-1551             0.0\n",
      "TCGA-13-0893  4.093755e-01    1.0  TCGA-13-0893             0.0\n",
      "TCGA-24-1104  1.375017e-04    0.0  TCGA-24-1104             0.0\n",
      "TCGA-25-1326  3.882391e-02    0.0  TCGA-25-1326             0.0\n",
      "TCGA-13-0916  1.858136e-01    0.0  TCGA-13-0916             0.0\n",
      "TCGA-13-1487  7.326313e-02    0.0  TCGA-13-1487             0.0\n",
      "TCGA-13-1403  2.004087e-01    0.0  TCGA-13-1403             0.0\n",
      "TCGA-36-1576  1.180532e-05    0.0  TCGA-36-1576             0.0\n",
      "TCGA-13-0795  7.302767e-01    1.0  TCGA-13-0795             1.0\n",
      "TCGA-23-2078  1.016826e-07    0.0  TCGA-23-2078             0.0\n",
      "TCGA-09-2056  3.103412e-01    0.0  TCGA-09-2056             0.0\n",
      "TCGA-29-1770  1.592839e-02    0.0  TCGA-29-1770             0.0\n",
      "TCGA-24-2290  1.021478e-04    0.0  TCGA-24-2290             0.0\n",
      "TCGA-13-0726  6.236615e-01    0.0  TCGA-13-0726             1.0\n",
      "TCGA-25-1628  1.306076e-01    1.0  TCGA-25-1628             0.0\n",
      "TCGA-09-0366  7.184532e-01    1.0  TCGA-09-0366             1.0\n",
      "TCGA-24-1924  8.283701e-03    1.0  TCGA-24-1924             0.0\n",
      "TCGA-24-1105  2.515213e-11    0.0  TCGA-24-1105             0.0\n",
      "TCGA-20-1683  4.433103e-02    0.0  TCGA-20-1683             0.0\n",
      "TCGA-61-1733  6.568779e-01    1.0  TCGA-61-1733             1.0\n",
      "TCGA-09-1665  4.211840e-02    0.0  TCGA-09-1665             0.0\n",
      "TCGA-36-1571  2.970283e-06    0.0  TCGA-36-1571             0.0\n",
      "[[ 4  9]\n",
      " [ 1 28]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict</th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>8.351165e-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>4.226791e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1122</th>\n",
       "      <td>5.597841e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-23-1122</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1474</th>\n",
       "      <td>9.908041e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1474</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-10-0927</th>\n",
       "      <td>1.434996e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-10-0927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1914</th>\n",
       "      <td>5.851045e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-61-1914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>4.999270e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1365</th>\n",
       "      <td>6.453138e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-04-1365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>4.383163e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>2.164667e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>1.513424e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1911</th>\n",
       "      <td>8.708345e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-61-1911</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>2.225501e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-1667</th>\n",
       "      <td>5.703374e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-1667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2097</th>\n",
       "      <td>1.178192e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-61-2097</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>2.875663e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>5.067045e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0364</th>\n",
       "      <td>1.027376e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-0364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1651</th>\n",
       "      <td>1.884282e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-04-1651</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1551</th>\n",
       "      <td>2.391759e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1551</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>4.093755e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1104</th>\n",
       "      <td>1.375017e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1326</th>\n",
       "      <td>3.882391e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-25-1326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0916</th>\n",
       "      <td>1.858136e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-0916</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1487</th>\n",
       "      <td>7.326313e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1487</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>2.004087e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1576</th>\n",
       "      <td>1.180532e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-36-1576</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-2078</th>\n",
       "      <td>1.016826e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-23-2078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>3.103412e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1770</th>\n",
       "      <td>1.592839e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-2290</th>\n",
       "      <td>1.021478e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-2290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>1.306076e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1924</th>\n",
       "      <td>8.283701e-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-24-1924</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1105</th>\n",
       "      <td>2.515213e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-20-1683</th>\n",
       "      <td>4.433103e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-20-1683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-1665</th>\n",
       "      <td>4.211840e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-1665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1571</th>\n",
       "      <td>2.970283e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-36-1571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   predict  label            ID  predicted_prob\n",
       "index_ID                                                       \n",
       "TCGA-36-1580  8.351165e-02    1.0  TCGA-36-1580             0.0\n",
       "TCGA-29-1769  4.226791e-02    0.0  TCGA-29-1769             0.0\n",
       "TCGA-23-1122  5.597841e-04    0.0  TCGA-23-1122             0.0\n",
       "TCGA-24-1474  9.908041e-07    0.0  TCGA-24-1474             0.0\n",
       "TCGA-10-0927  1.434996e-01    0.0  TCGA-10-0927             0.0\n",
       "TCGA-61-1914  5.851045e-08    0.0  TCGA-61-1914             0.0\n",
       "TCGA-29-1703  4.999270e-01    1.0  TCGA-29-1703             0.0\n",
       "TCGA-04-1365  6.453138e-02    0.0  TCGA-04-1365             0.0\n",
       "TCGA-29-1696  4.383163e-01    1.0  TCGA-29-1696             0.0\n",
       "TCGA-13-1483  2.164667e-01    1.0  TCGA-13-1483             0.0\n",
       "TCGA-61-1738  1.513424e-01    1.0  TCGA-61-1738             0.0\n",
       "TCGA-61-1911  8.708345e-04    0.0  TCGA-61-1911             0.0\n",
       "TCGA-25-2393  2.225501e-01    1.0  TCGA-25-2393             0.0\n",
       "TCGA-09-1667  5.703374e-08    0.0  TCGA-09-1667             0.0\n",
       "TCGA-61-2097  1.178192e-02    0.0  TCGA-61-2097             0.0\n",
       "TCGA-29-2414  2.875663e-01    0.0  TCGA-29-2414             0.0\n",
       "TCGA-24-1563  5.067045e-02    0.0  TCGA-24-1563             0.0\n",
       "TCGA-09-0364  1.027376e-08    0.0  TCGA-09-0364             0.0\n",
       "TCGA-04-1651  1.884282e-06    0.0  TCGA-04-1651             0.0\n",
       "TCGA-24-1551  2.391759e-01    0.0  TCGA-24-1551             0.0\n",
       "TCGA-13-0893  4.093755e-01    1.0  TCGA-13-0893             0.0\n",
       "TCGA-24-1104  1.375017e-04    0.0  TCGA-24-1104             0.0\n",
       "TCGA-25-1326  3.882391e-02    0.0  TCGA-25-1326             0.0\n",
       "TCGA-13-0916  1.858136e-01    0.0  TCGA-13-0916             0.0\n",
       "TCGA-13-1487  7.326313e-02    0.0  TCGA-13-1487             0.0\n",
       "TCGA-13-1403  2.004087e-01    0.0  TCGA-13-1403             0.0\n",
       "TCGA-36-1576  1.180532e-05    0.0  TCGA-36-1576             0.0\n",
       "TCGA-23-2078  1.016826e-07    0.0  TCGA-23-2078             0.0\n",
       "TCGA-09-2056  3.103412e-01    0.0  TCGA-09-2056             0.0\n",
       "TCGA-29-1770  1.592839e-02    0.0  TCGA-29-1770             0.0\n",
       "TCGA-24-2290  1.021478e-04    0.0  TCGA-24-2290             0.0\n",
       "TCGA-25-1628  1.306076e-01    1.0  TCGA-25-1628             0.0\n",
       "TCGA-24-1924  8.283701e-03    1.0  TCGA-24-1924             0.0\n",
       "TCGA-24-1105  2.515213e-11    0.0  TCGA-24-1105             0.0\n",
       "TCGA-20-1683  4.433103e-02    0.0  TCGA-20-1683             0.0\n",
       "TCGA-09-1665  4.211840e-02    0.0  TCGA-09-1665             0.0\n",
       "TCGA-36-1571  2.970283e-06    0.0  TCGA-36-1571             0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf = confusion_matrix(test_p_2['label'], test_p_2['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(test_p_2.set_index('index_ID'))\n",
    "\n",
    "test_p_2temp = test_p_2.set_index('index_ID')\n",
    "\n",
    "\n",
    "print(cnf)\n",
    "###print(pd.DataFrame(test_p_2))\n",
    "is_index = test_p_2temp['predicted_prob'] == 0.0\n",
    "\n",
    "#print(is_index)\n",
    "\n",
    "#print(test_p_2.loc[test_p_2['predict'] < 0.5, 'predicted_prob'])\n",
    "test_2 = test_p_2temp[test_p_2temp['predicted_prob'] == 0.0]\n",
    "#test_p_temp = test_p_2.drop['ID']\n",
    "\n",
    "#print(test_p_2)\n",
    "test_2\n",
    "#mask = test_p_2[test_p_2['label'].isin(0)]\n",
    "\n",
    "#test_p_2[~mask.astype(int)].head()\n",
    "\n",
    "#mask = mock_data['country'].isin(['Afghanistan', 'Nigeria']) mock_data[~mask].head()\n",
    "\n",
    "#출처: https://note.espriter.net/1325 [espriter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "#'epoch': EPOCHS,\n",
    "    'model_state_dict': model_2.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': trn_loss\n",
    "    }, \"./platin_model_save/platin_model_250_50_100_model_1_100_250_Semi_Final_Voting_test_2__.pth\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 0.])\n",
      "tensor([0, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 1.])\n",
      "tensor([1, 1, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 1., 0.])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([1, 1, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 1., 0.])\n",
      "tensor([1, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 1.])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 0., 1.])\n",
      "tensor([0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0.])\n",
      "******************** Test ********************\n",
      "Loss: 0.10455100238323212, Accuracy: 0.7555555701255798 %\n",
      "**********************************************\n",
      "Val accuracy:0.756\n"
     ]
    }
   ],
   "source": [
    "model_3.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict_3 = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model_3(val_X)\n",
    "        for i in val_pred:\n",
    "            predict_3.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        #print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        print(val_y)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9.615111e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.775721e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.055634e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.133583e-07</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.891717e-09</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.357328e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.614696e-09</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.375903e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.562330e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.759462e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.073076e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.490772e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.676609e-07</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.887046e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.369313e-12</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.825172e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.171318e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.871888e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.685589e-11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.558872e-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.872296e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.466625e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.640998e-07</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.620433e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.735436e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.392757e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.553365e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539662e-10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.963024e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.442792e-10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.970422e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.415026e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.364197e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.819081e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.194603e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.925121e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.733681e-03</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.036988e-14</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.007920e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.873109e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.886853e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.747257e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0                \n",
       "9.615111e-01  1.0\n",
       "3.775721e-01  1.0\n",
       "1.055634e-01  0.0\n",
       "5.133583e-07  0.0\n",
       "1.891717e-09  0.0\n",
       "4.357328e-01  0.0\n",
       "7.614696e-09  0.0\n",
       "9.375903e-01  1.0\n",
       "8.562330e-02  0.0\n",
       "9.759462e-01  1.0\n",
       "9.073076e-01  1.0\n",
       "8.490772e-01  1.0\n",
       "7.676609e-07  0.0\n",
       "7.887046e-01  1.0\n",
       "9.369313e-12  0.0\n",
       "1.825172e-02  0.0\n",
       "9.171318e-01  0.0\n",
       "4.871888e-01  0.0\n",
       "2.685589e-11  0.0\n",
       "8.558872e-08  0.0\n",
       "3.872296e-01  0.0\n",
       "9.466625e-01  1.0\n",
       "2.640998e-07  0.0\n",
       "3.620433e-03  0.0\n",
       "6.735436e-02  0.0\n",
       "7.392757e-01  0.0\n",
       "8.553365e-01  0.0\n",
       "1.539662e-10  0.0\n",
       "9.963024e-01  1.0\n",
       "2.442792e-10  0.0\n",
       "8.970422e-01  0.0\n",
       "2.415026e-05  0.0\n",
       "5.364197e-05  0.0\n",
       "9.819081e-01  0.0\n",
       "4.194603e-01  1.0\n",
       "9.925121e-01  1.0\n",
       "6.733681e-03  1.0\n",
       "2.036988e-14  0.0\n",
       "2.007920e-01  0.0\n",
       "9.873109e-01  1.0\n",
       "1.886853e-01  0.0\n",
       "2.747257e-06  0.0"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict_3)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "#trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  3]\n",
      " [ 5 24]]\n",
      "Accuracy :  0.8095238095238095\n",
      "Sensitivity :  0.7692307692307693\n",
      "Specificity :  0.8275862068965517\n",
      "AUC:  0.7984084880636604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict_3)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p_3 = pd.concat([predict_.iloc[:,0], label, val_label, val_label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p_3.columns = ['predict_add','label_add','index_ID','ID']\n",
    "test_p_3.loc[test_p_3['predict_add'] >= 0.5, 'predicted_prob_add'] = 1\n",
    "test_p_3.loc[test_p_3['predict_add'] < 0.5, 'predicted_prob_add'] = 0\n",
    "\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               predict_add  label_add      index_ID  predicted_prob_add\n",
      "ID                                                                     \n",
      "TCGA-23-1027  9.615111e-01        1.0  TCGA-23-1027                 1.0\n",
      "TCGA-36-1580  3.775721e-01        1.0  TCGA-36-1580                 0.0\n",
      "TCGA-29-1769  1.055634e-01        0.0  TCGA-29-1769                 0.0\n",
      "TCGA-23-1122  5.133583e-07        0.0  TCGA-23-1122                 0.0\n",
      "TCGA-24-1474  1.891717e-09        0.0  TCGA-24-1474                 0.0\n",
      "TCGA-10-0927  4.357328e-01        0.0  TCGA-10-0927                 0.0\n",
      "TCGA-61-1914  7.614696e-09        0.0  TCGA-61-1914                 0.0\n",
      "TCGA-29-1703  9.375903e-01        1.0  TCGA-29-1703                 1.0\n",
      "TCGA-04-1365  8.562330e-02        0.0  TCGA-04-1365                 0.0\n",
      "TCGA-29-1696  9.759462e-01        1.0  TCGA-29-1696                 1.0\n",
      "TCGA-13-1483  9.073076e-01        1.0  TCGA-13-1483                 1.0\n",
      "TCGA-61-1738  8.490772e-01        1.0  TCGA-61-1738                 1.0\n",
      "TCGA-61-1911  7.676609e-07        0.0  TCGA-61-1911                 0.0\n",
      "TCGA-25-2393  7.887046e-01        1.0  TCGA-25-2393                 1.0\n",
      "TCGA-09-1667  9.369313e-12        0.0  TCGA-09-1667                 0.0\n",
      "TCGA-61-2097  1.825172e-02        0.0  TCGA-61-2097                 0.0\n",
      "TCGA-29-2414  9.171318e-01        0.0  TCGA-29-2414                 1.0\n",
      "TCGA-24-1563  4.871888e-01        0.0  TCGA-24-1563                 0.0\n",
      "TCGA-09-0364  2.685589e-11        0.0  TCGA-09-0364                 0.0\n",
      "TCGA-04-1651  8.558872e-08        0.0  TCGA-04-1651                 0.0\n",
      "TCGA-24-1551  3.872296e-01        0.0  TCGA-24-1551                 0.0\n",
      "TCGA-13-0893  9.466625e-01        1.0  TCGA-13-0893                 1.0\n",
      "TCGA-24-1104  2.640998e-07        0.0  TCGA-24-1104                 0.0\n",
      "TCGA-25-1326  3.620433e-03        0.0  TCGA-25-1326                 0.0\n",
      "TCGA-13-0916  6.735436e-02        0.0  TCGA-13-0916                 0.0\n",
      "TCGA-13-1487  7.392757e-01        0.0  TCGA-13-1487                 1.0\n",
      "TCGA-13-1403  8.553365e-01        0.0  TCGA-13-1403                 1.0\n",
      "TCGA-36-1576  1.539662e-10        0.0  TCGA-36-1576                 0.0\n",
      "TCGA-13-0795  9.963024e-01        1.0  TCGA-13-0795                 1.0\n",
      "TCGA-23-2078  2.442792e-10        0.0  TCGA-23-2078                 0.0\n",
      "TCGA-09-2056  8.970422e-01        0.0  TCGA-09-2056                 1.0\n",
      "TCGA-29-1770  2.415026e-05        0.0  TCGA-29-1770                 0.0\n",
      "TCGA-24-2290  5.364197e-05        0.0  TCGA-24-2290                 0.0\n",
      "TCGA-13-0726  9.819081e-01        0.0  TCGA-13-0726                 1.0\n",
      "TCGA-25-1628  4.194603e-01        1.0  TCGA-25-1628                 0.0\n",
      "TCGA-09-0366  9.925121e-01        1.0  TCGA-09-0366                 1.0\n",
      "TCGA-24-1924  6.733681e-03        1.0  TCGA-24-1924                 0.0\n",
      "TCGA-24-1105  2.036988e-14        0.0  TCGA-24-1105                 0.0\n",
      "TCGA-20-1683  2.007920e-01        0.0  TCGA-20-1683                 0.0\n",
      "TCGA-61-1733  9.873109e-01        1.0  TCGA-61-1733                 1.0\n",
      "TCGA-09-1665  1.886853e-01        0.0  TCGA-09-1665                 0.0\n",
      "TCGA-36-1571  2.747257e-06        0.0  TCGA-36-1571                 0.0\n",
      "[[10  3]\n",
      " [ 5 24]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_add</th>\n",
       "      <th>label_add</th>\n",
       "      <th>index_ID</th>\n",
       "      <th>predicted_prob_add</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1027</th>\n",
       "      <td>9.615111e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-23-1027</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>3.775721e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-36-1580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1769</th>\n",
       "      <td>1.055634e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1769</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1122</th>\n",
       "      <td>5.133583e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-23-1122</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1474</th>\n",
       "      <td>1.891717e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1474</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-10-0927</th>\n",
       "      <td>4.357328e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-10-0927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1914</th>\n",
       "      <td>7.614696e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-61-1914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1703</th>\n",
       "      <td>9.375903e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1703</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1365</th>\n",
       "      <td>8.562330e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-04-1365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1696</th>\n",
       "      <td>9.759462e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-29-1696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1483</th>\n",
       "      <td>9.073076e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-1483</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1738</th>\n",
       "      <td>8.490772e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1738</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1911</th>\n",
       "      <td>7.676609e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-61-1911</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>7.887046e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-2393</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-1667</th>\n",
       "      <td>9.369313e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-1667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2097</th>\n",
       "      <td>1.825172e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-61-2097</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>9.171318e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-2414</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>4.871888e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1563</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0364</th>\n",
       "      <td>2.685589e-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-0364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1651</th>\n",
       "      <td>8.558872e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-04-1651</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1551</th>\n",
       "      <td>3.872296e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1551</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0893</th>\n",
       "      <td>9.466625e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0893</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1104</th>\n",
       "      <td>2.640998e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1326</th>\n",
       "      <td>3.620433e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-25-1326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0916</th>\n",
       "      <td>6.735436e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-0916</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1487</th>\n",
       "      <td>7.392757e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1487</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1403</th>\n",
       "      <td>8.553365e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-1403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1576</th>\n",
       "      <td>1.539662e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-36-1576</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0795</th>\n",
       "      <td>9.963024e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-13-0795</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-2078</th>\n",
       "      <td>2.442792e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-23-2078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>8.970422e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-2056</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1770</th>\n",
       "      <td>2.415026e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-29-1770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-2290</th>\n",
       "      <td>5.364197e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-2290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0726</th>\n",
       "      <td>9.819081e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-13-0726</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1628</th>\n",
       "      <td>4.194603e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-25-1628</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0366</th>\n",
       "      <td>9.925121e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-09-0366</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1924</th>\n",
       "      <td>6.733681e-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-24-1924</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1105</th>\n",
       "      <td>2.036988e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-24-1105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-20-1683</th>\n",
       "      <td>2.007920e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-20-1683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1733</th>\n",
       "      <td>9.873109e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TCGA-61-1733</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-1665</th>\n",
       "      <td>1.886853e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-09-1665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1571</th>\n",
       "      <td>2.747257e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TCGA-36-1571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               predict_add  label_add      index_ID  predicted_prob_add\n",
       "ID                                                                     \n",
       "TCGA-23-1027  9.615111e-01        1.0  TCGA-23-1027                 1.0\n",
       "TCGA-36-1580  3.775721e-01        1.0  TCGA-36-1580                 0.0\n",
       "TCGA-29-1769  1.055634e-01        0.0  TCGA-29-1769                 0.0\n",
       "TCGA-23-1122  5.133583e-07        0.0  TCGA-23-1122                 0.0\n",
       "TCGA-24-1474  1.891717e-09        0.0  TCGA-24-1474                 0.0\n",
       "TCGA-10-0927  4.357328e-01        0.0  TCGA-10-0927                 0.0\n",
       "TCGA-61-1914  7.614696e-09        0.0  TCGA-61-1914                 0.0\n",
       "TCGA-29-1703  9.375903e-01        1.0  TCGA-29-1703                 1.0\n",
       "TCGA-04-1365  8.562330e-02        0.0  TCGA-04-1365                 0.0\n",
       "TCGA-29-1696  9.759462e-01        1.0  TCGA-29-1696                 1.0\n",
       "TCGA-13-1483  9.073076e-01        1.0  TCGA-13-1483                 1.0\n",
       "TCGA-61-1738  8.490772e-01        1.0  TCGA-61-1738                 1.0\n",
       "TCGA-61-1911  7.676609e-07        0.0  TCGA-61-1911                 0.0\n",
       "TCGA-25-2393  7.887046e-01        1.0  TCGA-25-2393                 1.0\n",
       "TCGA-09-1667  9.369313e-12        0.0  TCGA-09-1667                 0.0\n",
       "TCGA-61-2097  1.825172e-02        0.0  TCGA-61-2097                 0.0\n",
       "TCGA-29-2414  9.171318e-01        0.0  TCGA-29-2414                 1.0\n",
       "TCGA-24-1563  4.871888e-01        0.0  TCGA-24-1563                 0.0\n",
       "TCGA-09-0364  2.685589e-11        0.0  TCGA-09-0364                 0.0\n",
       "TCGA-04-1651  8.558872e-08        0.0  TCGA-04-1651                 0.0\n",
       "TCGA-24-1551  3.872296e-01        0.0  TCGA-24-1551                 0.0\n",
       "TCGA-13-0893  9.466625e-01        1.0  TCGA-13-0893                 1.0\n",
       "TCGA-24-1104  2.640998e-07        0.0  TCGA-24-1104                 0.0\n",
       "TCGA-25-1326  3.620433e-03        0.0  TCGA-25-1326                 0.0\n",
       "TCGA-13-0916  6.735436e-02        0.0  TCGA-13-0916                 0.0\n",
       "TCGA-13-1487  7.392757e-01        0.0  TCGA-13-1487                 1.0\n",
       "TCGA-13-1403  8.553365e-01        0.0  TCGA-13-1403                 1.0\n",
       "TCGA-36-1576  1.539662e-10        0.0  TCGA-36-1576                 0.0\n",
       "TCGA-13-0795  9.963024e-01        1.0  TCGA-13-0795                 1.0\n",
       "TCGA-23-2078  2.442792e-10        0.0  TCGA-23-2078                 0.0\n",
       "TCGA-09-2056  8.970422e-01        0.0  TCGA-09-2056                 1.0\n",
       "TCGA-29-1770  2.415026e-05        0.0  TCGA-29-1770                 0.0\n",
       "TCGA-24-2290  5.364197e-05        0.0  TCGA-24-2290                 0.0\n",
       "TCGA-13-0726  9.819081e-01        0.0  TCGA-13-0726                 1.0\n",
       "TCGA-25-1628  4.194603e-01        1.0  TCGA-25-1628                 0.0\n",
       "TCGA-09-0366  9.925121e-01        1.0  TCGA-09-0366                 1.0\n",
       "TCGA-24-1924  6.733681e-03        1.0  TCGA-24-1924                 0.0\n",
       "TCGA-24-1105  2.036988e-14        0.0  TCGA-24-1105                 0.0\n",
       "TCGA-20-1683  2.007920e-01        0.0  TCGA-20-1683                 0.0\n",
       "TCGA-61-1733  9.873109e-01        1.0  TCGA-61-1733                 1.0\n",
       "TCGA-09-1665  1.886853e-01        0.0  TCGA-09-1665                 0.0\n",
       "TCGA-36-1571  2.747257e-06        0.0  TCGA-36-1571                 0.0"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf = confusion_matrix(test_p_3['label_add'], test_p_3['predicted_prob_add'], labels = [1,0])\n",
    "\n",
    "print(test_p_3.set_index('ID'))\n",
    "\n",
    "test_p_3temp = test_p_3.set_index('ID')\n",
    "\n",
    "\n",
    "print(cnf)\n",
    "###print(pd.DataFrame(test_p_2))\n",
    "###is_index = test_p_3temp['predicted_prob'] == 1.0\n",
    "\n",
    "#print(is_index)\n",
    "\n",
    "#print(test_p_2.loc[test_p_2['predict'] < 0.5, 'predicted_prob'])\n",
    "test_3 = test_p_3temp\n",
    "#test_p_temp = test_p_2.drop['ID']\n",
    "\n",
    "#print(test_p_2)\n",
    "test_3\n",
    "#mask = test_p_2[test_p_2['label'].isin(0)]\n",
    "\n",
    "#test_p_2[~mask.astype(int)].head()\n",
    "\n",
    "#mask = mock_data['country'].isin(['Afghanistan', 'Nigeria']) mock_data[~mask].head()\n",
    "\n",
    "#출처: https://note.espriter.net/1325 [espriter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_test = pd.concat([test_1, test_2], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "                   predict  label  predicted_prob\n",
      "ID                                               \n",
      "TCGA-23-1027  9.534943e-01    1.0             1.0\n",
      "TCGA-36-1580  6.911207e-01    1.0             1.0\n",
      "TCGA-29-1703  9.466208e-01    1.0             1.0\n",
      "TCGA-29-1696  9.542856e-01    1.0             1.0\n",
      "TCGA-13-1483  8.174533e-01    1.0             1.0\n",
      "TCGA-61-1738  5.389222e-01    1.0             1.0\n",
      "TCGA-25-2393  5.486322e-01    1.0             1.0\n",
      "TCGA-13-0893  8.634816e-01    1.0             1.0\n",
      "TCGA-13-0795  9.955494e-01    1.0             1.0\n",
      "TCGA-25-1628  6.765153e-01    1.0             1.0\n",
      "TCGA-09-0366  9.845570e-01    1.0             1.0\n",
      "TCGA-24-1924  1.748448e-05    1.0             0.0\n",
      "TCGA-61-1733  9.637365e-01    1.0             1.0\n",
      "TCGA-29-1769  4.053841e-02    0.0             0.0\n",
      "TCGA-23-1122  4.673898e-04    0.0             0.0\n",
      "TCGA-24-1474  7.432269e-07    0.0             0.0\n",
      "TCGA-10-0927  1.467769e-01    0.0             0.0\n",
      "TCGA-61-1914  4.366220e-08    0.0             0.0\n",
      "TCGA-04-1365  6.399535e-02    0.0             0.0\n",
      "TCGA-61-1911  7.517349e-04    0.0             0.0\n",
      "TCGA-09-1667  4.194334e-08    0.0             0.0\n",
      "TCGA-61-2097  1.102896e-02    0.0             0.0\n",
      "TCGA-29-2414  2.967533e-01    0.0             0.0\n",
      "TCGA-24-1563  4.953551e-02    0.0             0.0\n",
      "TCGA-09-0364  7.937189e-09    0.0             0.0\n",
      "TCGA-04-1651  1.482032e-06    0.0             0.0\n",
      "TCGA-24-1551  2.465105e-01    0.0             0.0\n",
      "TCGA-24-1104  1.135628e-04    0.0             0.0\n",
      "TCGA-25-1326  3.767242e-02    0.0             0.0\n",
      "TCGA-13-0916  1.921774e-01    0.0             0.0\n",
      "TCGA-13-1487  7.303619e-02    0.0             0.0\n",
      "TCGA-13-1403  2.062773e-01    0.0             0.0\n",
      "TCGA-36-1576  9.083706e-06    0.0             0.0\n",
      "TCGA-23-2078  7.263378e-08    0.0             0.0\n",
      "TCGA-09-2056  3.214971e-01    0.0             0.0\n",
      "TCGA-29-1770  1.454651e-02    0.0             0.0\n",
      "TCGA-24-2290  8.617995e-05    0.0             0.0\n",
      "TCGA-13-0726  6.496148e-01    0.0             1.0\n",
      "TCGA-24-1105  1.743025e-11    0.0             0.0\n",
      "TCGA-20-1683  4.369618e-02    0.0             0.0\n",
      "TCGA-09-1665  4.191536e-02    0.0             0.0\n",
      "TCGA-36-1571  2.304033e-06    0.0             0.0\n",
      "[[12  1]\n",
      " [ 1 28]]\n",
      "Accuracy :  0.9523809523809523\n",
      "Sensitivity :  0.9230769230769231\n",
      "Specificity :  0.9655172413793104\n",
      "AUC:  0.8581\n"
     ]
    }
   ],
   "source": [
    "print(Final_test.shape[0])\n",
    "\n",
    "print(Final_test)\n",
    "\n",
    "cnf = confusion_matrix(Final_test['label'], Final_test['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "\n",
    "auc  =  round(roc_auc_score(test_p['label'],test_p['predicted_prob']),4)\n",
    "\n",
    "#fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "#print('AUC: ', auc(fpr, trp))\n",
    "print('AUC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.96523094], dtype=float32),\n",
       " array([0.40869933], dtype=float32),\n",
       " array([0.18736918], dtype=float32),\n",
       " array([6.5656457e-07], dtype=float32),\n",
       " array([2.3786907e-08], dtype=float32),\n",
       " array([0.05763014], dtype=float32),\n",
       " array([1.9820663e-10], dtype=float32),\n",
       " array([0.9488913], dtype=float32),\n",
       " array([0.41917148], dtype=float32),\n",
       " array([0.9683527], dtype=float32),\n",
       " array([0.75444454], dtype=float32),\n",
       " array([0.69513965], dtype=float32),\n",
       " array([0.00034798], dtype=float32),\n",
       " array([0.70198876], dtype=float32),\n",
       " array([2.795339e-09], dtype=float32),\n",
       " array([6.0754446e-05], dtype=float32),\n",
       " array([0.91316634], dtype=float32),\n",
       " array([0.6346924], dtype=float32),\n",
       " array([5.5596742e-12], dtype=float32),\n",
       " array([1.352942e-13], dtype=float32),\n",
       " array([0.5749145], dtype=float32),\n",
       " array([0.8809959], dtype=float32),\n",
       " array([2.519986e-05], dtype=float32),\n",
       " array([0.00343669], dtype=float32),\n",
       " array([0.49783298], dtype=float32),\n",
       " array([0.71625566], dtype=float32),\n",
       " array([0.78362393], dtype=float32),\n",
       " array([1.2181736e-09], dtype=float32),\n",
       " array([0.98857796], dtype=float32),\n",
       " array([2.2718281e-12], dtype=float32),\n",
       " array([0.8310575], dtype=float32),\n",
       " array([0.00596385], dtype=float32),\n",
       " array([1.1859802e-07], dtype=float32),\n",
       " array([0.9726179], dtype=float32),\n",
       " array([0.5310959], dtype=float32),\n",
       " array([0.9829896], dtype=float32),\n",
       " array([0.00059432], dtype=float32),\n",
       " array([1.350266e-13], dtype=float32),\n",
       " array([0.01798952], dtype=float32),\n",
       " array([0.9774236], dtype=float32),\n",
       " array([0.21573254], dtype=float32),\n",
       " array([1.5710613e-08], dtype=float32)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.55683917], dtype=float32),\n",
       " array([0.08307219], dtype=float32),\n",
       " array([0.04053841], dtype=float32),\n",
       " array([0.00046739], dtype=float32),\n",
       " array([7.432269e-07], dtype=float32),\n",
       " array([0.14677685], dtype=float32),\n",
       " array([4.3662197e-08], dtype=float32),\n",
       " array([0.51931804], dtype=float32),\n",
       " array([0.06399535], dtype=float32),\n",
       " array([0.45912912], dtype=float32),\n",
       " array([0.2208362], dtype=float32),\n",
       " array([0.15557681], dtype=float32),\n",
       " array([0.00075173], dtype=float32),\n",
       " array([0.22724117], dtype=float32),\n",
       " array([4.1943338e-08], dtype=float32),\n",
       " array([0.01102896], dtype=float32),\n",
       " array([0.2967533], dtype=float32),\n",
       " array([0.04953551], dtype=float32),\n",
       " array([7.937189e-09], dtype=float32),\n",
       " array([1.4820315e-06], dtype=float32),\n",
       " array([0.24651052], dtype=float32),\n",
       " array([0.4239356], dtype=float32),\n",
       " array([0.00011356], dtype=float32),\n",
       " array([0.03767242], dtype=float32),\n",
       " array([0.19217741], dtype=float32),\n",
       " array([0.07303619], dtype=float32),\n",
       " array([0.20627727], dtype=float32),\n",
       " array([9.083706e-06], dtype=float32),\n",
       " array([0.7538557], dtype=float32),\n",
       " array([7.263378e-08], dtype=float32),\n",
       " array([0.32149705], dtype=float32),\n",
       " array([0.01454651], dtype=float32),\n",
       " array([8.617995e-05], dtype=float32),\n",
       " array([0.6496148], dtype=float32),\n",
       " array([0.13344125], dtype=float32),\n",
       " array([0.74142146], dtype=float32),\n",
       " array([0.00728779], dtype=float32),\n",
       " array([1.7430252e-11], dtype=float32),\n",
       " array([0.04369618], dtype=float32),\n",
       " array([0.6816279], dtype=float32),\n",
       " array([0.04191536], dtype=float32),\n",
       " array([2.3040327e-06], dtype=float32)]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.8607451], dtype=float32),\n",
       " array([0.4790696], dtype=float32),\n",
       " array([0.3565798], dtype=float32),\n",
       " array([7.1915606e-06], dtype=float32),\n",
       " array([0.0014108], dtype=float32),\n",
       " array([0.16123456], dtype=float32),\n",
       " array([1.3273825e-07], dtype=float32),\n",
       " array([0.7402205], dtype=float32),\n",
       " array([0.3974231], dtype=float32),\n",
       " array([0.8689314], dtype=float32),\n",
       " array([0.6825226], dtype=float32),\n",
       " array([0.5898785], dtype=float32),\n",
       " array([0.00829941], dtype=float32),\n",
       " array([0.51559234], dtype=float32),\n",
       " array([0.00072743], dtype=float32),\n",
       " array([0.02738246], dtype=float32),\n",
       " array([0.69638824], dtype=float32),\n",
       " array([0.3023329], dtype=float32),\n",
       " array([3.455946e-05], dtype=float32),\n",
       " array([7.268803e-07], dtype=float32),\n",
       " array([0.5242045], dtype=float32),\n",
       " array([0.7060348], dtype=float32),\n",
       " array([0.08810126], dtype=float32),\n",
       " array([0.10685713], dtype=float32),\n",
       " array([0.4980478], dtype=float32),\n",
       " array([0.42031947], dtype=float32),\n",
       " array([0.642132], dtype=float32),\n",
       " array([6.2494615e-07], dtype=float32),\n",
       " array([0.9697491], dtype=float32),\n",
       " array([2.7625786e-08], dtype=float32),\n",
       " array([0.62372434], dtype=float32),\n",
       " array([0.05262083], dtype=float32),\n",
       " array([0.02307679], dtype=float32),\n",
       " array([0.86410004], dtype=float32),\n",
       " array([0.42016312], dtype=float32),\n",
       " array([0.9370525], dtype=float32),\n",
       " array([0.03397452], dtype=float32),\n",
       " array([2.6617318e-08], dtype=float32),\n",
       " array([0.37829864], dtype=float32),\n",
       " array([0.92217773], dtype=float32),\n",
       " array([0.21684174], dtype=float32),\n",
       " array([0.01006378], dtype=float32)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x7f289456c320>\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "predict_ = []\n",
    "\n",
    "for i in predict:\n",
    "    #print (i) # 3\n",
    "    predict_.append(i) # 3\n",
    "    #print (predict_)\n",
    "\n",
    "predict_1_2 = []\n",
    "\n",
    "for i in predict:\n",
    "    #print (i) # 3\n",
    "    predict_1_2.append(i) # 3\n",
    "    #print (predict_2_)\n",
    "\n",
    "predict_3_ = []\n",
    "\n",
    "for i in predict_3:\n",
    "    #print (i) # 3\n",
    "    predict_3_.append(i) # 3\n",
    "    #print (predict_2_)\n",
    "\n",
    "#predict_ = map(operator.mul, predict, 0.7)\n",
    "#predict_2_ = map(operator.mul, predict_2, 0.3)\n",
    "#predict_total = map(operator.add, predict_3, predict)\n",
    "predict_total = map(operator.add, predict_, predict_3_)\n",
    "#predict_total = map(operator.add, predict_total, predict_1_2)\n",
    "print(predict_total)\n",
    "\n",
    "##for i in predict_total:\n",
    "##    print (i) # 3\n",
    "    #predict_final.append(i) # 3\n",
    "    #print (predict_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8450831]\n",
      "[array([0.6150277], dtype=float32)]\n",
      "[1.1708615]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32)]\n",
      "[0.64521825]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32)]\n",
      "[0.6269195]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32)]\n",
      "[0.68808395]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32)]\n",
      "[0.7017898]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32)]\n",
      "[0.6526075]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32)]\n",
      "[1.579553]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32)]\n",
      "[0.61710364]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32)]\n",
      "[1.7378885]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32)]\n",
      "[1.3298857]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32)]\n",
      "[1.4743105]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32)]\n",
      "[0.6283997]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32)]\n",
      "[0.8977568]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32)]\n",
      "[0.7787465]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32)]\n",
      "[0.3944703]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32)]\n",
      "[1.2915779]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32)]\n",
      "[0.81079674]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32)]\n",
      "[0.8092163]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32)]\n",
      "[0.76935786]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32)]\n",
      "[0.96179056]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32)]\n",
      "[1.3822813]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32)]\n",
      "[0.67052376]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32)]\n",
      "[0.5690135]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32)]\n",
      "[0.9602722]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32)]\n",
      "[0.9652314]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32)]\n",
      "[1.2940578]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32)]\n",
      "[0.6487013]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32)]\n",
      "[1.7762345]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32)]\n",
      "[0.6443446]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32)]\n",
      "[1.3489572]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32)]\n",
      "[0.67222905]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32)]\n",
      "[0.7307981]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32)]\n",
      "[1.778948]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32), array([0.59298265], dtype=float32)]\n",
      "[1.0470698]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32), array([0.59298265], dtype=float32), array([0.34902325], dtype=float32)]\n",
      "[1.6257691]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32), array([0.59298265], dtype=float32), array([0.34902325], dtype=float32), array([0.54192305], dtype=float32)]\n",
      "[0.7757879]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32), array([0.59298265], dtype=float32), array([0.34902325], dtype=float32), array([0.54192305], dtype=float32), array([0.25859597], dtype=float32)]\n",
      "[0.37314677]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32), array([0.59298265], dtype=float32), array([0.34902325], dtype=float32), array([0.54192305], dtype=float32), array([0.25859597], dtype=float32), array([0.12438226], dtype=float32)]\n",
      "[0.8534595]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32), array([0.59298265], dtype=float32), array([0.34902325], dtype=float32), array([0.54192305], dtype=float32), array([0.25859597], dtype=float32), array([0.12438226], dtype=float32), array([0.2844865], dtype=float32)]\n",
      "[1.6170764]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32), array([0.59298265], dtype=float32), array([0.34902325], dtype=float32), array([0.54192305], dtype=float32), array([0.25859597], dtype=float32), array([0.12438226], dtype=float32), array([0.2844865], dtype=float32), array([0.5390255], dtype=float32)]\n",
      "[0.9193163]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32), array([0.59298265], dtype=float32), array([0.34902325], dtype=float32), array([0.54192305], dtype=float32), array([0.25859597], dtype=float32), array([0.12438226], dtype=float32), array([0.2844865], dtype=float32), array([0.5390255], dtype=float32), array([0.30643877], dtype=float32)]\n",
      "[0.32391727]\n",
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32), array([0.59298265], dtype=float32), array([0.34902325], dtype=float32), array([0.54192305], dtype=float32), array([0.25859597], dtype=float32), array([0.12438226], dtype=float32), array([0.2844865], dtype=float32), array([0.5390255], dtype=float32), array([0.30643877], dtype=float32), array([0.10797242], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "predict_final = []\n",
    "\n",
    "for i in predict_total:\n",
    "    print (i) # 3\n",
    "    predict_final.append(i/3) # 3\n",
    "    print (predict_final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.6150277], dtype=float32), array([0.39028716], dtype=float32), array([0.21507275], dtype=float32), array([0.20897317], dtype=float32), array([0.22936131], dtype=float32), array([0.23392993], dtype=float32), array([0.21753584], dtype=float32), array([0.5265177], dtype=float32), array([0.20570122], dtype=float32), array([0.5792962], dtype=float32), array([0.44329524], dtype=float32), array([0.49143684], dtype=float32), array([0.20946658], dtype=float32), array([0.29925227], dtype=float32), array([0.25958216], dtype=float32), array([0.1314901], dtype=float32), array([0.430526], dtype=float32), array([0.27026558], dtype=float32), array([0.26973876], dtype=float32), array([0.25645262], dtype=float32), array([0.32059684], dtype=float32), array([0.46076044], dtype=float32), array([0.22350793], dtype=float32), array([0.18967116], dtype=float32), array([0.32009074], dtype=float32), array([0.32174382], dtype=float32), array([0.43135262], dtype=float32), array([0.21623378], dtype=float32), array([0.59207815], dtype=float32), array([0.21478154], dtype=float32), array([0.4496524], dtype=float32), array([0.22407635], dtype=float32), array([0.24359937], dtype=float32), array([0.59298265], dtype=float32), array([0.34902325], dtype=float32), array([0.54192305], dtype=float32), array([0.25859597], dtype=float32), array([0.12438226], dtype=float32), array([0.2844865], dtype=float32), array([0.5390255], dtype=float32), array([0.30643877], dtype=float32), array([0.10797242], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predict_final)\n",
    "type(predict_final)\n",
    "len(predict_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.615028</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.390287</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.215073</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.208973</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.229361</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.233930</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.217536</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.526518</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.205701</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.579296</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.443295</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.491437</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.209467</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.299252</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.259582</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.131490</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.430526</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.270266</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.269739</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.256453</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.320597</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.460760</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.223508</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.189671</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.320091</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.321744</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.431353</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.216234</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.592078</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.214782</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.449652</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.224076</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.243599</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.592983</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.349023</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.541923</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.258596</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.124382</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.284487</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.539025</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.306439</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.107972</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0            \n",
       "0.615028  1.0\n",
       "0.390287  1.0\n",
       "0.215073  0.0\n",
       "0.208973  0.0\n",
       "0.229361  0.0\n",
       "0.233930  0.0\n",
       "0.217536  0.0\n",
       "0.526518  1.0\n",
       "0.205701  0.0\n",
       "0.579296  1.0\n",
       "0.443295  1.0\n",
       "0.491437  1.0\n",
       "0.209467  0.0\n",
       "0.299252  1.0\n",
       "0.259582  0.0\n",
       "0.131490  0.0\n",
       "0.430526  0.0\n",
       "0.270266  0.0\n",
       "0.269739  0.0\n",
       "0.256453  0.0\n",
       "0.320597  0.0\n",
       "0.460760  1.0\n",
       "0.223508  0.0\n",
       "0.189671  0.0\n",
       "0.320091  0.0\n",
       "0.321744  0.0\n",
       "0.431353  0.0\n",
       "0.216234  0.0\n",
       "0.592078  1.0\n",
       "0.214782  0.0\n",
       "0.449652  0.0\n",
       "0.224076  0.0\n",
       "0.243599  0.0\n",
       "0.592983  0.0\n",
       "0.349023  1.0\n",
       "0.541923  1.0\n",
       "0.258596  1.0\n",
       "0.124382  0.0\n",
       "0.284487  0.0\n",
       "0.539025  1.0\n",
       "0.306439  0.0\n",
       "0.107972  0.0"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict_final)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "#trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7]\n",
      " [ 1 28]]\n",
      "Accuracy :  0.8095238095238095\n",
      "Sensitivity :  0.46153846153846156\n",
      "Specificity :  0.9655172413793104\n",
      "AUC:  0.7135278514588861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict_final)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/171 (0%)]\tLoss: 0.935273\t Accuracy:68.750%\n",
      "Epoch : 0 [32/171 (18%)]\tLoss: 0.791408\t Accuracy:70.833%\n",
      "Epoch : 0 [64/171 (36%)]\tLoss: 0.752347\t Accuracy:68.750%\n",
      "Epoch : 0 [96/171 (55%)]\tLoss: 0.723812\t Accuracy:63.393%\n",
      "Epoch : 0 [128/171 (73%)]\tLoss: 0.811310\t Accuracy:65.972%\n",
      "Epoch : 0 [110/171 (91%)]\tLoss: 0.819974\t Accuracy:65.909%\n",
      "Epoch : 1 [0/171 (0%)]\tLoss: 0.823073\t Accuracy:62.500%\n",
      "Epoch : 1 [32/171 (18%)]\tLoss: 0.663486\t Accuracy:64.583%\n",
      "Epoch : 1 [64/171 (36%)]\tLoss: 0.554099\t Accuracy:66.250%\n",
      "Epoch : 1 [96/171 (55%)]\tLoss: 0.667068\t Accuracy:66.071%\n",
      "Epoch : 1 [128/171 (73%)]\tLoss: 0.624170\t Accuracy:65.278%\n",
      "Epoch : 1 [110/171 (91%)]\tLoss: 0.637554\t Accuracy:65.909%\n",
      "Epoch : 2 [0/171 (0%)]\tLoss: 0.651228\t Accuracy:75.000%\n",
      "Epoch : 2 [32/171 (18%)]\tLoss: 0.534523\t Accuracy:81.250%\n",
      "Epoch : 2 [64/171 (36%)]\tLoss: 0.607727\t Accuracy:71.250%\n",
      "Epoch : 2 [96/171 (55%)]\tLoss: 0.625725\t Accuracy:69.643%\n",
      "Epoch : 2 [128/171 (73%)]\tLoss: 0.518599\t Accuracy:68.750%\n",
      "Epoch : 2 [110/171 (91%)]\tLoss: 0.623615\t Accuracy:65.909%\n",
      "Epoch : 3 [0/171 (0%)]\tLoss: 0.721605\t Accuracy:62.500%\n",
      "Epoch : 3 [32/171 (18%)]\tLoss: 0.700559\t Accuracy:62.500%\n",
      "Epoch : 3 [64/171 (36%)]\tLoss: 0.640351\t Accuracy:62.500%\n",
      "Epoch : 3 [96/171 (55%)]\tLoss: 0.522688\t Accuracy:65.179%\n",
      "Epoch : 3 [128/171 (73%)]\tLoss: 0.591321\t Accuracy:67.361%\n",
      "Epoch : 3 [110/171 (91%)]\tLoss: 0.585958\t Accuracy:65.909%\n",
      "Epoch : 4 [0/171 (0%)]\tLoss: 0.535764\t Accuracy:68.750%\n",
      "Epoch : 4 [32/171 (18%)]\tLoss: 0.641071\t Accuracy:66.667%\n",
      "Epoch : 4 [64/171 (36%)]\tLoss: 0.745152\t Accuracy:63.750%\n",
      "Epoch : 4 [96/171 (55%)]\tLoss: 0.596616\t Accuracy:66.071%\n",
      "Epoch : 4 [128/171 (73%)]\tLoss: 0.489455\t Accuracy:68.750%\n",
      "Epoch : 4 [110/171 (91%)]\tLoss: 1.087884\t Accuracy:65.909%\n",
      "Epoch : 5 [0/171 (0%)]\tLoss: 0.492926\t Accuracy:81.250%\n",
      "Epoch : 5 [32/171 (18%)]\tLoss: 0.597117\t Accuracy:66.667%\n",
      "Epoch : 5 [64/171 (36%)]\tLoss: 0.585361\t Accuracy:70.000%\n",
      "Epoch : 5 [96/171 (55%)]\tLoss: 0.607225\t Accuracy:68.750%\n",
      "Epoch : 5 [128/171 (73%)]\tLoss: 0.816338\t Accuracy:66.667%\n",
      "Epoch : 5 [110/171 (91%)]\tLoss: 0.549977\t Accuracy:65.909%\n",
      "Epoch : 6 [0/171 (0%)]\tLoss: 0.777337\t Accuracy:50.000%\n",
      "Epoch : 6 [32/171 (18%)]\tLoss: 0.587489\t Accuracy:62.500%\n",
      "Epoch : 6 [64/171 (36%)]\tLoss: 0.539594\t Accuracy:66.250%\n",
      "Epoch : 6 [96/171 (55%)]\tLoss: 0.654489\t Accuracy:65.179%\n",
      "Epoch : 6 [128/171 (73%)]\tLoss: 0.592911\t Accuracy:65.972%\n",
      "Epoch : 6 [110/171 (91%)]\tLoss: 0.484829\t Accuracy:65.909%\n",
      "Epoch : 7 [0/171 (0%)]\tLoss: 0.581097\t Accuracy:62.500%\n",
      "Epoch : 7 [32/171 (18%)]\tLoss: 0.598890\t Accuracy:66.667%\n",
      "Epoch : 7 [64/171 (36%)]\tLoss: 0.490318\t Accuracy:72.500%\n",
      "Epoch : 7 [96/171 (55%)]\tLoss: 0.669338\t Accuracy:71.429%\n",
      "Epoch : 7 [128/171 (73%)]\tLoss: 0.590307\t Accuracy:69.444%\n",
      "Epoch : 7 [110/171 (91%)]\tLoss: 0.956334\t Accuracy:65.909%\n",
      "Epoch : 8 [0/171 (0%)]\tLoss: 0.554228\t Accuracy:68.750%\n",
      "Epoch : 8 [32/171 (18%)]\tLoss: 0.985561\t Accuracy:64.583%\n",
      "Epoch : 8 [64/171 (36%)]\tLoss: 0.583143\t Accuracy:65.000%\n",
      "Epoch : 8 [96/171 (55%)]\tLoss: 0.484694\t Accuracy:70.536%\n",
      "Epoch : 8 [128/171 (73%)]\tLoss: 0.619994\t Accuracy:68.750%\n",
      "Epoch : 8 [110/171 (91%)]\tLoss: 0.591878\t Accuracy:65.909%\n",
      "Epoch : 9 [0/171 (0%)]\tLoss: 0.595703\t Accuracy:62.500%\n",
      "Epoch : 9 [32/171 (18%)]\tLoss: 0.504482\t Accuracy:68.750%\n",
      "Epoch : 9 [64/171 (36%)]\tLoss: 0.598189\t Accuracy:67.500%\n",
      "Epoch : 9 [96/171 (55%)]\tLoss: 0.609455\t Accuracy:67.857%\n",
      "Epoch : 9 [128/171 (73%)]\tLoss: 0.594306\t Accuracy:67.361%\n",
      "Epoch : 9 [110/171 (91%)]\tLoss: 0.475993\t Accuracy:65.909%\n"
     ]
    }
   ],
   "source": [
    "model_1 = DNN_seq_()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    model_1 = model_1.cuda()\n",
    "    \n",
    "fit(model_1, trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/171 (0%)]\tLoss: 0.745150\t Accuracy:56.250%\n",
      "Epoch : 0 [32/171 (18%)]\tLoss: 0.593750\t Accuracy:70.833%\n",
      "Epoch : 0 [64/171 (36%)]\tLoss: 0.609681\t Accuracy:72.500%\n",
      "Epoch : 0 [96/171 (55%)]\tLoss: 0.811276\t Accuracy:70.536%\n",
      "Epoch : 0 [128/171 (73%)]\tLoss: 0.909858\t Accuracy:68.750%\n",
      "Epoch : 0 [110/171 (91%)]\tLoss: 0.555978\t Accuracy:65.909%\n",
      "Epoch : 1 [0/171 (0%)]\tLoss: 0.671668\t Accuracy:62.500%\n",
      "Epoch : 1 [32/171 (18%)]\tLoss: 0.751559\t Accuracy:60.417%\n",
      "Epoch : 1 [64/171 (36%)]\tLoss: 0.629498\t Accuracy:66.250%\n",
      "Epoch : 1 [96/171 (55%)]\tLoss: 0.660346\t Accuracy:67.857%\n",
      "Epoch : 1 [128/171 (73%)]\tLoss: 0.670158\t Accuracy:68.056%\n",
      "Epoch : 1 [110/171 (91%)]\tLoss: 0.560989\t Accuracy:65.909%\n",
      "Epoch : 2 [0/171 (0%)]\tLoss: 0.624824\t Accuracy:68.750%\n",
      "Epoch : 2 [32/171 (18%)]\tLoss: 0.593675\t Accuracy:70.833%\n",
      "Epoch : 2 [64/171 (36%)]\tLoss: 0.510769\t Accuracy:67.500%\n",
      "Epoch : 2 [96/171 (55%)]\tLoss: 0.542457\t Accuracy:65.179%\n",
      "Epoch : 2 [128/171 (73%)]\tLoss: 0.449139\t Accuracy:68.056%\n",
      "Epoch : 2 [110/171 (91%)]\tLoss: 0.709045\t Accuracy:65.909%\n",
      "Epoch : 3 [0/171 (0%)]\tLoss: 0.510405\t Accuracy:81.250%\n",
      "Epoch : 3 [32/171 (18%)]\tLoss: 0.566522\t Accuracy:75.000%\n",
      "Epoch : 3 [64/171 (36%)]\tLoss: 0.568372\t Accuracy:73.750%\n",
      "Epoch : 3 [96/171 (55%)]\tLoss: 0.822826\t Accuracy:68.750%\n",
      "Epoch : 3 [128/171 (73%)]\tLoss: 0.632761\t Accuracy:68.056%\n",
      "Epoch : 3 [110/171 (91%)]\tLoss: 0.728441\t Accuracy:65.909%\n",
      "Epoch : 4 [0/171 (0%)]\tLoss: 0.511926\t Accuracy:81.250%\n",
      "Epoch : 4 [32/171 (18%)]\tLoss: 0.588146\t Accuracy:72.917%\n",
      "Epoch : 4 [64/171 (36%)]\tLoss: 0.601966\t Accuracy:68.750%\n",
      "Epoch : 4 [96/171 (55%)]\tLoss: 0.555080\t Accuracy:71.429%\n",
      "Epoch : 4 [128/171 (73%)]\tLoss: 0.604517\t Accuracy:69.444%\n",
      "Epoch : 4 [110/171 (91%)]\tLoss: 0.809859\t Accuracy:65.909%\n",
      "Epoch : 5 [0/171 (0%)]\tLoss: 0.629632\t Accuracy:62.500%\n",
      "Epoch : 5 [32/171 (18%)]\tLoss: 0.562846\t Accuracy:77.083%\n",
      "Epoch : 5 [64/171 (36%)]\tLoss: 0.527351\t Accuracy:70.000%\n",
      "Epoch : 5 [96/171 (55%)]\tLoss: 0.754989\t Accuracy:68.750%\n",
      "Epoch : 5 [128/171 (73%)]\tLoss: 0.674207\t Accuracy:68.056%\n",
      "Epoch : 5 [110/171 (91%)]\tLoss: 0.581754\t Accuracy:65.909%\n",
      "Epoch : 6 [0/171 (0%)]\tLoss: 0.519321\t Accuracy:75.000%\n",
      "Epoch : 6 [32/171 (18%)]\tLoss: 0.661274\t Accuracy:68.750%\n",
      "Epoch : 6 [64/171 (36%)]\tLoss: 0.487016\t Accuracy:70.000%\n",
      "Epoch : 6 [96/171 (55%)]\tLoss: 0.697098\t Accuracy:66.071%\n",
      "Epoch : 6 [128/171 (73%)]\tLoss: 0.612715\t Accuracy:65.972%\n",
      "Epoch : 6 [110/171 (91%)]\tLoss: 0.501077\t Accuracy:65.909%\n",
      "Epoch : 7 [0/171 (0%)]\tLoss: 0.706766\t Accuracy:62.500%\n",
      "Epoch : 7 [32/171 (18%)]\tLoss: 0.713934\t Accuracy:64.583%\n",
      "Epoch : 7 [64/171 (36%)]\tLoss: 0.643361\t Accuracy:63.750%\n",
      "Epoch : 7 [96/171 (55%)]\tLoss: 0.527158\t Accuracy:67.857%\n",
      "Epoch : 7 [128/171 (73%)]\tLoss: 0.764433\t Accuracy:65.972%\n",
      "Epoch : 7 [110/171 (91%)]\tLoss: 0.495314\t Accuracy:65.909%\n",
      "Epoch : 8 [0/171 (0%)]\tLoss: 0.657935\t Accuracy:75.000%\n",
      "Epoch : 8 [32/171 (18%)]\tLoss: 0.593164\t Accuracy:70.833%\n",
      "Epoch : 8 [64/171 (36%)]\tLoss: 0.572450\t Accuracy:67.500%\n",
      "Epoch : 8 [96/171 (55%)]\tLoss: 0.509525\t Accuracy:71.429%\n",
      "Epoch : 8 [128/171 (73%)]\tLoss: 0.577141\t Accuracy:70.139%\n",
      "Epoch : 8 [110/171 (91%)]\tLoss: 0.661615\t Accuracy:65.909%\n",
      "Epoch : 9 [0/171 (0%)]\tLoss: 0.616295\t Accuracy:62.500%\n",
      "Epoch : 9 [32/171 (18%)]\tLoss: 0.658520\t Accuracy:66.667%\n",
      "Epoch : 9 [64/171 (36%)]\tLoss: 0.734764\t Accuracy:71.250%\n",
      "Epoch : 9 [96/171 (55%)]\tLoss: 0.587277\t Accuracy:66.964%\n",
      "Epoch : 9 [128/171 (73%)]\tLoss: 0.617130\t Accuracy:67.361%\n",
      "Epoch : 9 [110/171 (91%)]\tLoss: 0.577146\t Accuracy:65.909%\n"
     ]
    }
   ],
   "source": [
    "model_2 = DNN_seq_()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    model_2 = model_2.cuda()\n",
    "    \n",
    "fit(model_2, trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Test ********************\n",
      "Loss: 0.5453603863716125, Accuracy: 0.7291666865348816 %\n",
      "**********************************************\n",
      "Val accuracy:0.729\n"
     ]
    }
   ],
   "source": [
    "model_1.eval()\n",
    "predict_1 = []\n",
    "#y_val = val_y\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(val_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model_1(val_X)\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        for i in val_pred:\n",
    "            predict_1.append(i.numpy())\n",
    "        val_loss = criterion(val_pred, val_y)\n",
    "        val_loss_summary += val_loss\n",
    "        predicted = torch.max(val_pred.data, 1)[1] \n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(val_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(val_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Test ********************\n",
      "Loss: 0.586574375629425, Accuracy: 0.7291666865348816 %\n",
      "**********************************************\n",
      "Val accuracy:0.729\n"
     ]
    }
   ],
   "source": [
    "model_2.eval()\n",
    "predict_2 = []\n",
    "#y_val = val_y\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(val_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model_2(val_X)\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        for i in val_pred:\n",
    "            predict_2.append(i.numpy())\n",
    "        val_loss = criterion(val_pred, val_y)\n",
    "        val_loss_summary += val_loss\n",
    "        predicted = torch.max(val_pred.data, 1)[1] \n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(val_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(val_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.39712372], dtype=float32),\n",
       " array([0.20998392], dtype=float32),\n",
       " array([0.32124352], dtype=float32),\n",
       " array([0.34580824], dtype=float32),\n",
       " array([0.43426463], dtype=float32),\n",
       " array([0.43412134], dtype=float32),\n",
       " array([0.39131775], dtype=float32),\n",
       " array([0.38226905], dtype=float32),\n",
       " array([0.42771617], dtype=float32),\n",
       " array([0.2733672], dtype=float32),\n",
       " array([0.42271107], dtype=float32),\n",
       " array([0.4628345], dtype=float32),\n",
       " array([0.4519838], dtype=float32),\n",
       " array([0.3947924], dtype=float32),\n",
       " array([0.39574006], dtype=float32),\n",
       " array([0.4404809], dtype=float32),\n",
       " array([0.3974393], dtype=float32),\n",
       " array([0.48102662], dtype=float32),\n",
       " array([0.42520103], dtype=float32),\n",
       " array([0.43733662], dtype=float32),\n",
       " array([0.3043311], dtype=float32),\n",
       " array([0.4567577], dtype=float32),\n",
       " array([0.36690694], dtype=float32),\n",
       " array([0.38817948], dtype=float32),\n",
       " array([0.5215086], dtype=float32),\n",
       " array([0.4337628], dtype=float32),\n",
       " array([0.40996504], dtype=float32),\n",
       " array([0.6179651], dtype=float32),\n",
       " array([0.06799946], dtype=float32),\n",
       " array([0.35044378], dtype=float32),\n",
       " array([0.4207713], dtype=float32),\n",
       " array([0.24543233], dtype=float32),\n",
       " array([0.31436154], dtype=float32),\n",
       " array([0.32930988], dtype=float32),\n",
       " array([0.24549559], dtype=float32),\n",
       " array([0.42242727], dtype=float32),\n",
       " array([0.08231714], dtype=float32),\n",
       " array([0.4540262], dtype=float32),\n",
       " array([0.18898232], dtype=float32),\n",
       " array([0.4693117], dtype=float32),\n",
       " array([0.3819803], dtype=float32),\n",
       " array([0.41919783], dtype=float32),\n",
       " array([0.35521805], dtype=float32)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.40936574], dtype=float32),\n",
       " array([0.30449998], dtype=float32),\n",
       " array([0.37039232], dtype=float32),\n",
       " array([0.37293124], dtype=float32),\n",
       " array([0.45267642], dtype=float32),\n",
       " array([0.44899222], dtype=float32),\n",
       " array([0.41215253], dtype=float32),\n",
       " array([0.40887272], dtype=float32),\n",
       " array([0.4442977], dtype=float32),\n",
       " array([0.39285985], dtype=float32),\n",
       " array([0.4360027], dtype=float32),\n",
       " array([0.48552424], dtype=float32),\n",
       " array([0.46931365], dtype=float32),\n",
       " array([0.40514487], dtype=float32),\n",
       " array([0.41182923], dtype=float32),\n",
       " array([0.42791894], dtype=float32),\n",
       " array([0.405836], dtype=float32),\n",
       " array([0.4981986], dtype=float32),\n",
       " array([0.43440622], dtype=float32),\n",
       " array([0.44471112], dtype=float32),\n",
       " array([0.37168515], dtype=float32),\n",
       " array([0.47441038], dtype=float32),\n",
       " array([0.3651678], dtype=float32),\n",
       " array([0.40067512], dtype=float32),\n",
       " array([0.5199345], dtype=float32),\n",
       " array([0.4233134], dtype=float32),\n",
       " array([0.4351335], dtype=float32),\n",
       " array([0.4555768], dtype=float32),\n",
       " array([0.03253645], dtype=float32),\n",
       " array([0.38686517], dtype=float32),\n",
       " array([0.43364474], dtype=float32),\n",
       " array([0.35556954], dtype=float32),\n",
       " array([0.3455017], dtype=float32),\n",
       " array([0.36210445], dtype=float32),\n",
       " array([0.3429039], dtype=float32),\n",
       " array([0.4352731], dtype=float32),\n",
       " array([0.17092553], dtype=float32),\n",
       " array([0.47549853], dtype=float32),\n",
       " array([0.34219885], dtype=float32),\n",
       " array([0.48880357], dtype=float32),\n",
       " array([0.38187575], dtype=float32),\n",
       " array([0.42263123], dtype=float32),\n",
       " array([0.31459165], dtype=float32)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_3 = predict_1 + predict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-072387173aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_3' is not defined"
     ]
    }
   ],
   "source": [
    "len(predict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "predict_3 = map(operator.add, predict_1, predict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x7fc040081c50>\n"
     ]
    }
   ],
   "source": [
    "print(predict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43645966]\n",
      "[array([0.43645966], dtype=float32)]\n",
      "[0.34106642]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32)]\n",
      "[0.4075713]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32)]\n",
      "[0.40122908]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32)]\n",
      "[0.44226646]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32)]\n",
      "[0.44394046]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32)]\n",
      "[0.41578606]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32)]\n",
      "[0.41548812]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32)]\n",
      "[0.4436235]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32)]\n",
      "[0.357646]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32)]\n",
      "[0.43614274]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32)]\n",
      "[0.4559007]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32)]\n",
      "[0.44684273]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32)]\n",
      "[0.42056525]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32)]\n",
      "[0.42621326]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32)]\n",
      "[0.42557824]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32)]\n",
      "[0.4176554]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32)]\n",
      "[0.45774207]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32)]\n",
      "[0.43780085]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32)]\n",
      "[0.4308337]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32)]\n",
      "[0.4050982]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32)]\n",
      "[0.4504068]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32)]\n",
      "[0.39789623]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32)]\n",
      "[0.41764146]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32)]\n",
      "[0.4750628]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32)]\n",
      "[0.4315881]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32)]\n",
      "[0.4379266]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32)]\n",
      "[0.4739846]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32)]\n",
      "[0.14909385]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32)]\n",
      "[0.38376015]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32)]\n",
      "[0.43800506]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32)]\n",
      "[0.35712954]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32)]\n",
      "[0.37910074]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32)]\n",
      "[0.35794306]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32)]\n",
      "[0.3569919]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32)]\n",
      "[0.4402965]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32)]\n",
      "[0.23215562]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32)]\n",
      "[0.45525098]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32)]\n",
      "[0.32845485]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32)]\n",
      "[0.45887935]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32), array([0.45887935], dtype=float32)]\n",
      "[0.41872162]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32), array([0.45887935], dtype=float32), array([0.41872162], dtype=float32)]\n",
      "[0.42732608]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32), array([0.45887935], dtype=float32), array([0.41872162], dtype=float32), array([0.42732608], dtype=float32)]\n",
      "[0.41365343]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32), array([0.45887935], dtype=float32), array([0.41872162], dtype=float32), array([0.42732608], dtype=float32), array([0.41365343], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "predict = []\n",
    "\n",
    "for i in predict_3:\n",
    "    print (i/2)\n",
    "    predict.append(i/2)\n",
    "    print (predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32), array([0.45887935], dtype=float32), array([0.41872162], dtype=float32), array([0.42732608], dtype=float32), array([0.41365343], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predict)\n",
    "type(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y_pd_ = val_y_pd.to_numpy()\n",
    "val_y_pd_ = torch.from_numpy(val_y_pd_)\n",
    "val_y_pd_ = val_y_pd_.type_as(torch.FloatTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = criterion(predict, val_y)\n",
    "val_loss_summary += val_loss\n",
    "predicted = torch.max(val_pred.data, 1)[1] \n",
    "correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(val_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(val_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     1.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     1.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    0.0\n",
       "13    1.0\n",
       "14    0.0\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    1.0\n",
       "18    0.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    0.0\n",
       "23    0.0\n",
       "24    0.0\n",
       "25    0.0\n",
       "26    1.0\n",
       "27    0.0\n",
       "28    0.0\n",
       "29    1.0\n",
       "30    0.0\n",
       "31    0.0\n",
       "32    0.0\n",
       "33    0.0\n",
       "34    0.0\n",
       "35    0.0\n",
       "36    1.0\n",
       "37    1.0\n",
       "38    0.0\n",
       "39    0.0\n",
       "40    0.0\n",
       "41    0.0\n",
       "42    0.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.0.weight tensor([[-0.0565, -0.1205,  0.0296,  ...,  0.2230, -0.0025,  0.0114],\n",
      "        [-0.0879, -0.0202, -0.0235,  ...,  0.0587,  0.0370, -0.0111],\n",
      "        [-0.0381, -0.0511, -0.0141,  ..., -0.0142,  0.0329,  0.0550],\n",
      "        ...,\n",
      "        [ 0.0349, -0.0490, -0.0410,  ..., -0.0243, -0.0495,  0.0048],\n",
      "        [ 0.0487,  0.1016, -0.0085,  ..., -0.1036,  0.0225, -0.0505],\n",
      "        [-0.0129,  0.1087,  0.0454,  ..., -0.1197,  0.0375,  0.0101]])\n",
      "layer1.0.bias tensor([-0.0296, -0.0339,  0.0066, -0.0166, -0.0347, -0.0489,  0.0233,  0.0351,\n",
      "         0.0348,  0.0116,  0.0404, -0.0197, -0.0154,  0.0126,  0.0236,  0.0361,\n",
      "        -0.0178, -0.0001, -0.0028, -0.0274, -0.0495, -0.0317,  0.0020,  0.0040,\n",
      "         0.0019,  0.0077,  0.0134, -0.0460,  0.0494,  0.0400, -0.0072, -0.0119,\n",
      "         0.0044, -0.0115,  0.0237, -0.0051, -0.0136, -0.0101,  0.0195,  0.0419,\n",
      "        -0.0333, -0.0286,  0.0231, -0.0157,  0.0131,  0.0034, -0.0038,  0.0113,\n",
      "        -0.0342,  0.0022, -0.0403,  0.0045,  0.0368, -0.0412, -0.0265,  0.0073,\n",
      "         0.0281,  0.0489, -0.0224, -0.0353, -0.0270,  0.0293, -0.0182,  0.0238,\n",
      "         0.0492,  0.0268,  0.0054, -0.0453, -0.0368, -0.0456, -0.0042, -0.0114,\n",
      "         0.0184, -0.0176,  0.0122, -0.0008,  0.0443, -0.0175, -0.0142,  0.0456,\n",
      "         0.0210, -0.0015, -0.0053,  0.0494, -0.0356, -0.0446,  0.0353, -0.0413,\n",
      "        -0.0138,  0.0264, -0.0138,  0.0239,  0.0239, -0.0406, -0.0066,  0.0318,\n",
      "        -0.0107,  0.0155, -0.0385, -0.0457, -0.0217, -0.0321,  0.0310, -0.0050,\n",
      "        -0.0381, -0.0156,  0.0157, -0.0302,  0.0393,  0.0008,  0.0229, -0.0228,\n",
      "        -0.0309,  0.0328,  0.0005,  0.0439,  0.0028,  0.0360, -0.0042,  0.0088,\n",
      "        -0.0314, -0.0466, -0.0220, -0.0228,  0.0237,  0.0239, -0.0307,  0.0453,\n",
      "         0.0329,  0.0349, -0.0221, -0.0098,  0.0226,  0.0481,  0.0167,  0.0323,\n",
      "        -0.0268,  0.0228,  0.0485, -0.0443,  0.0335,  0.0312,  0.0197, -0.0286,\n",
      "         0.0466, -0.0496,  0.0195, -0.0330,  0.0122, -0.0012,  0.0474, -0.0334,\n",
      "         0.0289,  0.0292,  0.0017,  0.0107,  0.0175, -0.0181, -0.0057,  0.0273,\n",
      "         0.0200,  0.0319, -0.0083,  0.0171,  0.0426,  0.0274, -0.0409,  0.0243,\n",
      "        -0.0078,  0.0461,  0.0331, -0.0404,  0.0284,  0.0241, -0.0382, -0.0323,\n",
      "        -0.0196, -0.0103, -0.0421,  0.0310, -0.0475, -0.0364, -0.0091, -0.0065,\n",
      "        -0.0075,  0.0139,  0.0052,  0.0198,  0.0273,  0.0429,  0.0285, -0.0189,\n",
      "         0.0003,  0.0293, -0.0074,  0.0034, -0.0308, -0.0453, -0.0052,  0.0491,\n",
      "        -0.0164, -0.0174, -0.0105,  0.0064,  0.0330, -0.0178, -0.0432, -0.0326,\n",
      "        -0.0172,  0.0131, -0.0105,  0.0036, -0.0133, -0.0358,  0.0205,  0.0050,\n",
      "         0.0117,  0.0358, -0.0050, -0.0465,  0.0437,  0.0382, -0.0406,  0.0342,\n",
      "        -0.0039, -0.0102, -0.0305,  0.0462, -0.0189,  0.0109,  0.0156,  0.0486,\n",
      "        -0.0352,  0.0466, -0.0362,  0.0174,  0.0249,  0.0121,  0.0045, -0.0139,\n",
      "        -0.0131, -0.0221,  0.0172, -0.0261, -0.0400,  0.0163, -0.0023, -0.0367,\n",
      "         0.0451, -0.0103,  0.0202, -0.0446, -0.0080,  0.0331, -0.0087, -0.0047])\n",
      "layer1.1.weight tensor([1.0543, 1.0026, 0.9529, 0.9930, 0.9804, 0.9381, 0.9887, 1.0181, 1.3591,\n",
      "        0.9947, 0.9440, 0.9238, 1.0188, 0.9941, 0.9750, 0.9654, 1.0311, 1.0246,\n",
      "        0.9704, 0.9845, 1.0102, 0.9843, 0.9939, 0.9649, 1.0927, 1.1654, 0.9758,\n",
      "        0.9636, 1.0126, 0.9536, 1.0806, 0.9525, 0.9579, 0.9856, 0.9407, 0.9693,\n",
      "        0.9402, 1.0998, 0.9559, 0.9616, 1.0285, 0.9483, 1.0569, 0.9598, 0.9758,\n",
      "        0.9606, 0.9784, 0.9570, 0.9713, 0.9745, 1.0181, 1.0555, 0.9997, 0.9530,\n",
      "        0.9576, 0.9488, 0.9400, 0.9601, 0.9809, 0.9516, 0.9940, 0.9563, 1.0968,\n",
      "        0.9425, 0.9743, 1.0133, 0.9653, 1.1313, 1.0063, 0.9513, 1.2053, 0.9754,\n",
      "        0.9650, 0.9459, 0.9965, 0.9641, 0.9772, 1.0243, 0.9510, 0.9320, 0.9907,\n",
      "        0.9788, 1.0122, 1.0071, 0.9641, 0.9579, 1.1537, 0.9829, 0.9348, 1.0536,\n",
      "        0.9752, 0.9476, 0.9320, 1.0961, 0.9682, 0.9551, 1.0997, 0.9738, 0.9502,\n",
      "        0.9723, 0.9532, 0.9421, 1.0103, 0.9597, 1.0276, 0.9726, 0.9488, 0.9493,\n",
      "        0.9718, 0.9464, 0.9359, 1.0518, 0.9688, 0.9973, 0.9829, 0.9552, 0.9926,\n",
      "        0.9318, 1.1189, 0.9734, 1.0136, 1.0211, 1.1543, 1.0242, 0.9966, 0.9609,\n",
      "        0.9532, 0.9632, 0.9638, 0.9995, 1.0706, 1.2656, 1.0072, 1.0146, 1.0994,\n",
      "        0.9740, 0.9531, 1.0132, 0.9401, 1.0987, 0.9823, 1.0166, 1.0076, 0.9821,\n",
      "        0.9629, 0.9700, 1.0205, 0.9578, 1.0034, 0.9603, 0.9256, 0.9741, 0.9436,\n",
      "        1.1408, 0.9683, 0.9890, 0.9576, 0.9858, 0.9450, 0.9762, 0.9716, 0.9857,\n",
      "        0.9722, 0.9662, 1.1388, 1.0447, 0.9543, 0.9899, 0.9534, 1.0293, 0.9659,\n",
      "        0.9652, 1.0391, 0.9915, 0.9734, 1.0190, 0.9628, 0.9587, 0.9835, 0.9557,\n",
      "        0.9662, 0.9700, 0.9721, 0.9751, 0.9466, 1.0051, 0.9608, 0.9418, 0.9616,\n",
      "        0.9540, 0.9386, 0.9793, 0.9455, 0.9494, 0.9596, 0.9577, 1.1870, 0.9387,\n",
      "        1.0832, 0.9497, 1.0929, 0.9469, 0.9594, 0.9605, 1.0027, 0.9616, 0.9803,\n",
      "        0.9703, 1.0022, 0.9896, 0.9997, 1.0361, 0.9539, 0.9467, 0.9919, 0.9524,\n",
      "        0.9626, 0.9502, 0.9668, 1.1326, 0.9875, 1.0050, 0.9409, 1.0002, 0.9510,\n",
      "        0.9608, 0.9515, 0.9672, 0.9675, 1.0145, 1.0126, 1.0117, 0.9585, 0.9675,\n",
      "        0.9777, 0.9710, 0.9834, 1.1106, 0.9546, 0.9559, 0.9482, 0.9359, 0.9625,\n",
      "        0.9448, 0.9875, 0.9419, 0.9797, 0.9734, 1.0407, 0.9971, 0.9410, 0.9882,\n",
      "        0.9700, 0.9617, 0.9896, 0.9808])\n",
      "layer1.1.bias tensor([ 0.0453,  0.0241, -0.0505, -0.0232, -0.0577, -0.0721,  0.0315, -0.0061,\n",
      "         0.0808,  0.0042, -0.0511, -0.0356,  0.0082,  0.0235, -0.0111,  0.0091,\n",
      "        -0.0469,  0.0067, -0.0420, -0.0269, -0.0116, -0.0002, -0.0145, -0.0298,\n",
      "         0.0468,  0.0831, -0.0057, -0.0144,  0.0346, -0.0472,  0.0046, -0.0278,\n",
      "        -0.0359, -0.0035, -0.0414, -0.0530, -0.0214,  0.0057, -0.0362, -0.0383,\n",
      "         0.0049, -0.0249,  0.0879, -0.0336,  0.0092, -0.0274, -0.0124, -0.0407,\n",
      "         0.0249, -0.0224,  0.0245, -0.0011, -0.0500, -0.0545, -0.0306, -0.0362,\n",
      "        -0.0262, -0.0363, -0.0222, -0.0485, -0.0457, -0.0340,  0.0623, -0.0656,\n",
      "        -0.0472, -0.0040,  0.0202,  0.0939,  0.0504, -0.0124,  0.1581, -0.0275,\n",
      "        -0.0311, -0.0313, -0.0377, -0.0105, -0.0219,  0.0396, -0.0215, -0.0541,\n",
      "         0.0313, -0.0159,  0.0051, -0.0322, -0.0650, -0.0638,  0.1269,  0.0325,\n",
      "        -0.0127,  0.0025, -0.0383, -0.0019, -0.0304,  0.0603, -0.0517, -0.0490,\n",
      "         0.0615, -0.0521, -0.0420, -0.0156, -0.0182, -0.0318, -0.0394, -0.0332,\n",
      "         0.0085, -0.0176, -0.0462, -0.0274,  0.0113, -0.0159, -0.0646,  0.0320,\n",
      "        -0.0337, -0.0111, -0.0506, -0.0191, -0.0149, -0.0349,  0.0042, -0.0751,\n",
      "         0.0237,  0.0079,  0.0560,  0.0476, -0.0440, -0.0315, -0.0526, -0.0280,\n",
      "        -0.0255, -0.0052,  0.0083,  0.1634, -0.0207,  0.0299,  0.0531,  0.0486,\n",
      "        -0.0296, -0.0142, -0.0345,  0.0608, -0.0170, -0.0334,  0.0234, -0.0233,\n",
      "        -0.0080, -0.0628, -0.0103, -0.0211, -0.0157, -0.0268, -0.0607, -0.0041,\n",
      "        -0.0442,  0.0705,  0.0504, -0.0203, -0.0289, -0.0262, -0.0366, -0.0557,\n",
      "        -0.0434,  0.0295, -0.0221, -0.0399,  0.1607,  0.0627, -0.0258,  0.0372,\n",
      "        -0.0028,  0.0355, -0.0461, -0.0278,  0.0041, -0.0111, -0.0156, -0.0463,\n",
      "        -0.0400, -0.0635, -0.0304, -0.0536, -0.0209, -0.0195, -0.0341, -0.0342,\n",
      "        -0.0113, -0.0032, -0.0328, -0.0393, -0.0565,  0.0103, -0.0485, -0.0362,\n",
      "         0.0448, -0.0292, -0.0124, -0.0273,  0.1589, -0.0610,  0.0671, -0.0247,\n",
      "         0.0505, -0.0319, -0.0130, -0.0454,  0.0191, -0.0244, -0.0111, -0.0171,\n",
      "        -0.0051, -0.0271, -0.0062,  0.0734, -0.0318, -0.0160, -0.0424, -0.0499,\n",
      "        -0.0272, -0.0263,  0.0187,  0.1053, -0.0019, -0.0242, -0.0582,  0.0288,\n",
      "        -0.0535, -0.0423, -0.0635, -0.0212, -0.0191,  0.0121,  0.0152, -0.0035,\n",
      "        -0.0330, -0.0343, -0.0404, -0.0321, -0.0270,  0.0617, -0.0283, -0.0453,\n",
      "        -0.0607, -0.0292, -0.0565, -0.0464, -0.0083, -0.0198, -0.0132, -0.0766,\n",
      "         0.0538, -0.0385, -0.0541, -0.0003, -0.0083, -0.0426, -0.0276, -0.0277])\n",
      "layer2.0.weight tensor([[-0.0163,  0.0263,  0.0218,  ..., -0.0967,  0.0156,  0.0105],\n",
      "        [-0.0522, -0.0449,  0.0215,  ..., -0.0324, -0.0184,  0.0182],\n",
      "        [ 0.0422,  0.0070,  0.0411,  ...,  0.0558,  0.0299,  0.0019],\n",
      "        ...,\n",
      "        [ 0.0493, -0.0322, -0.0337,  ...,  0.0173,  0.0147, -0.0171],\n",
      "        [-0.0296, -0.0210, -0.0163,  ...,  0.0227,  0.0137, -0.0562],\n",
      "        [ 0.0282,  0.0394,  0.0259,  ...,  0.0094,  0.0067,  0.0486]])\n",
      "layer2.0.bias tensor([-0.0604, -0.0613,  0.0348,  0.0436,  0.0475,  0.0515,  0.0059, -0.0128,\n",
      "         0.0378, -0.0207,  0.0542,  0.0261,  0.0211, -0.0375, -0.0479,  0.0064,\n",
      "         0.0352, -0.0484,  0.0122,  0.0089,  0.0133,  0.0003,  0.0068, -0.0451,\n",
      "         0.0169, -0.0488,  0.0247, -0.0605, -0.0118,  0.0411, -0.0161,  0.0565,\n",
      "         0.0277, -0.0389, -0.0478,  0.0508,  0.0215, -0.0234,  0.0101,  0.0033,\n",
      "        -0.0417, -0.0411,  0.0051,  0.0259,  0.0112,  0.0247,  0.0465, -0.0558,\n",
      "         0.0354, -0.0163, -0.0328, -0.0269, -0.0410, -0.0317,  0.0026, -0.0495,\n",
      "         0.0258, -0.0097,  0.0296,  0.0282,  0.0211,  0.0254,  0.0217, -0.0031,\n",
      "         0.0474, -0.0321, -0.0401, -0.0512,  0.0529,  0.0175, -0.0365,  0.0139,\n",
      "         0.0285, -0.0031,  0.0229,  0.0554, -0.0087, -0.0225,  0.0534,  0.0102,\n",
      "        -0.0117,  0.0120, -0.0551,  0.0136,  0.0420,  0.0340, -0.0566,  0.0161,\n",
      "        -0.0286,  0.0448,  0.0400,  0.0561,  0.0053, -0.0277, -0.0146,  0.0201,\n",
      "         0.0278,  0.0577,  0.0026,  0.0097, -0.0232, -0.0103,  0.0562, -0.0150,\n",
      "         0.0318,  0.0545, -0.0133,  0.0257,  0.0521, -0.0492, -0.0415,  0.0575,\n",
      "         0.0273, -0.0348,  0.0407,  0.0224, -0.0134,  0.0508,  0.0162, -0.0108,\n",
      "        -0.0385, -0.0458, -0.0352, -0.0646,  0.0572,  0.0406,  0.0331,  0.0130])\n",
      "layer2.1.weight tensor([0.9613, 1.0475, 1.0010, 0.9392, 1.0344, 0.9671, 1.0034, 1.1226, 0.9615,\n",
      "        1.0508, 0.9742, 1.0172, 0.9995, 0.9541, 0.9533, 0.9548, 0.9846, 1.1078,\n",
      "        1.1053, 1.0107, 0.9783, 0.9653, 1.0068, 1.0774, 0.9704, 1.0177, 0.9810,\n",
      "        0.9845, 0.9522, 1.0674, 0.9781, 0.9977, 0.9818, 1.0031, 0.9531, 1.0444,\n",
      "        1.0160, 1.0373, 1.0434, 0.9564, 1.0378, 0.9935, 1.0403, 0.9438, 0.9588,\n",
      "        0.9968, 0.9936, 1.0114, 1.0069, 0.9975, 1.0479, 1.0201, 0.9579, 1.0324,\n",
      "        1.0037, 0.9983, 0.9907, 1.0427, 0.9711, 0.9804, 1.0222, 0.9770, 1.0041,\n",
      "        0.9864, 0.9818, 0.9704, 0.9547, 0.9659, 1.0392, 1.0374, 0.9591, 0.9856,\n",
      "        1.0427, 0.9606, 0.9982, 0.9646, 1.0630, 0.9772, 0.9811, 0.9855, 0.9293,\n",
      "        1.0613, 1.0292, 1.0194, 1.0508, 0.9637, 1.1035, 0.9961, 1.0145, 1.0209,\n",
      "        0.9505, 1.0620, 0.9405, 0.9742, 0.9636, 1.0114, 1.0882, 1.0284, 1.0017,\n",
      "        1.0713, 0.9807, 1.0086, 0.9554, 1.0239, 1.0211, 0.9505, 1.0052, 1.0249,\n",
      "        0.9842, 1.0019, 0.9609, 1.0182, 0.9800, 1.0274, 1.0270, 0.9745, 1.0085,\n",
      "        0.9902, 0.9659, 0.9994, 1.0481, 0.9465, 0.9692, 1.0124, 1.0340, 0.9958,\n",
      "        0.9650, 0.9584])\n",
      "layer2.1.bias tensor([-3.3632e-02, -1.0531e-02, -3.9815e-02, -5.3454e-02,  3.4553e-03,\n",
      "        -4.2636e-02, -3.5241e-02,  6.7848e-02, -2.7361e-02,  2.4047e-02,\n",
      "        -1.6313e-02, -2.8308e-02, -3.9380e-02, -1.7013e-02, -1.2474e-02,\n",
      "        -1.6568e-02,  2.9685e-02,  5.9898e-02,  8.8914e-02,  8.4402e-03,\n",
      "        -3.1797e-02, -2.5944e-02,  1.3087e-02,  3.0514e-02, -2.9099e-02,\n",
      "        -3.4053e-02, -1.0561e-02, -3.3698e-02, -1.6890e-02, -2.2441e-02,\n",
      "        -2.8737e-02,  1.4771e-02,  1.2317e-03, -3.8425e-03, -6.0187e-03,\n",
      "        -2.0330e-02,  1.3631e-03,  1.1908e-03, -4.2749e-02, -1.9610e-02,\n",
      "        -5.1234e-03, -1.1312e-02,  5.1386e-02, -2.8814e-02, -5.9600e-02,\n",
      "        -6.9483e-03,  2.6689e-03, -1.9948e-02, -2.7281e-02,  1.8556e-02,\n",
      "        -2.7163e-02, -7.9423e-02, -5.0906e-02, -1.5404e-02, -3.7304e-02,\n",
      "        -4.5451e-03, -6.8602e-03, -3.7263e-02, -1.3598e-02,  8.3878e-03,\n",
      "         1.0625e-02, -1.2431e-02,  2.4046e-03,  8.8591e-03,  3.5623e-03,\n",
      "        -2.1075e-02, -5.0911e-02,  3.3220e-03,  7.3397e-03,  1.2624e-02,\n",
      "        -2.7113e-02, -9.7818e-03,  3.8295e-02, -3.5996e-02, -4.4027e-03,\n",
      "        -6.1831e-03,  7.9379e-05, -6.9035e-03, -3.7248e-03, -2.9304e-02,\n",
      "        -3.3609e-02, -4.9656e-02,  2.8775e-02,  2.0694e-02,  3.1142e-02,\n",
      "        -3.4996e-02, -5.2912e-02, -2.7226e-02, -8.7165e-03, -7.9831e-02,\n",
      "        -3.4923e-02,  1.6893e-02, -1.9217e-02, -1.2025e-04, -2.4480e-02,\n",
      "         8.3395e-03, -2.0882e-02,  7.1040e-02,  9.8776e-03,  8.4546e-02,\n",
      "        -4.6718e-03, -1.2601e-02, -3.4672e-02,  4.7202e-02, -7.7692e-03,\n",
      "        -3.0968e-02, -2.4136e-02,  4.0197e-02,  1.8163e-03, -8.8145e-03,\n",
      "        -4.8762e-02, -2.5213e-02, -1.8892e-02, -3.4188e-02,  1.4136e-02,\n",
      "        -9.4315e-03, -7.7451e-03,  7.3673e-03,  2.9620e-03, -8.7451e-03,\n",
      "         5.1112e-02, -2.6812e-02,  1.3600e-02,  1.1149e-02, -6.7495e-03,\n",
      "        -9.1601e-03, -4.1967e-02, -2.4559e-02])\n",
      "layer3.0.weight tensor([[-0.0475,  0.0049, -0.0305,  ..., -0.0959, -0.0193, -0.0498],\n",
      "        [ 0.0476,  0.0125, -0.0632,  ...,  0.0559, -0.0873, -0.0563],\n",
      "        [-0.0611,  0.0562,  0.0944,  ...,  0.0271, -0.0053,  0.0391],\n",
      "        ...,\n",
      "        [-0.0332,  0.1086, -0.0952,  ...,  0.0282, -0.0768, -0.0400],\n",
      "        [-0.0533,  0.0318,  0.0123,  ...,  0.0516, -0.0466,  0.0648],\n",
      "        [-0.0028, -0.0263, -0.0079,  ...,  0.0050, -0.0584, -0.0270]])\n",
      "layer3.0.bias tensor([-0.0864,  0.0066,  0.0272,  0.0414,  0.0265, -0.0724,  0.0081, -0.0026,\n",
      "         0.0090, -0.0017, -0.0632,  0.0474,  0.0010,  0.0513, -0.0701,  0.0224,\n",
      "         0.0710,  0.0793,  0.0045, -0.0487,  0.0904, -0.0718, -0.0645,  0.0604,\n",
      "         0.0616,  0.0063, -0.0180, -0.0622, -0.0654, -0.0706,  0.0485,  0.0171,\n",
      "         0.0422,  0.0428, -0.0145, -0.0604, -0.0029,  0.0437, -0.0610, -0.0750,\n",
      "        -0.0723,  0.0333,  0.0454,  0.0449, -0.0565, -0.0309,  0.0858, -0.0418,\n",
      "         0.0134, -0.0809,  0.0819, -0.0303, -0.0396,  0.0419, -0.0036, -0.0205,\n",
      "         0.0124,  0.0358,  0.0826,  0.0011, -0.0844,  0.0698,  0.0577,  0.0164])\n",
      "layer3.1.weight tensor([1.0830, 0.9978, 0.9785, 1.2189, 1.0479, 1.2179, 1.1423, 1.0221, 1.2209,\n",
      "        1.1106, 1.1230, 1.1783, 1.2140, 1.0997, 1.1747, 1.1660, 0.9775, 1.1345,\n",
      "        1.2364, 1.2392, 1.1082, 1.0455, 1.0523, 1.1933, 1.1867, 1.2126, 1.1887,\n",
      "        1.1772, 1.1870, 1.1890, 1.2267, 1.1849, 1.1846, 1.1480, 1.2154, 1.0959,\n",
      "        1.1951, 1.0215, 1.2021, 1.2693, 1.2102, 1.0501, 1.2439, 1.1928, 1.1395,\n",
      "        1.0154, 1.2521, 1.2279, 1.2349, 1.1956, 1.0306, 1.2408, 1.0883, 1.0951,\n",
      "        1.0982, 1.1461, 1.1568, 1.1664, 1.1719, 1.1948, 1.0316, 1.2075, 1.1764,\n",
      "        1.1313])\n",
      "layer3.1.bias tensor([ 0.0915, -0.0282, -0.0143,  0.2714,  0.0145,  0.2964,  0.2684,  0.0075,\n",
      "         0.2234,  0.1543,  0.1794,  0.1890,  0.2182,  0.0831,  0.2497,  0.1692,\n",
      "        -0.0144,  0.1800,  0.2716,  0.2873,  0.1167,  0.1014,  0.1085,  0.2057,\n",
      "         0.1829,  0.2182,  0.1975,  0.2033,  0.2191,  0.2082,  0.2647,  0.1941,\n",
      "         0.2544,  0.1868,  0.2324,  0.1946,  0.2205,  0.0303,  0.2813,  0.2636,\n",
      "         0.2980,  0.0259,  0.2997,  0.2090,  0.1250, -0.0026,  0.2421,  0.2573,\n",
      "         0.2519,  0.2493,  0.0357,  0.2008,  0.0534,  0.0487,  0.1670,  0.2083,\n",
      "         0.2069,  0.2459,  0.1904,  0.2156,  0.0678,  0.1993,  0.2226,  0.1382])\n",
      "layer4.0.weight tensor([[ 0.1443, -0.1018, -0.1090, -0.0516,  0.1599,  0.0069, -0.0503,  0.1055,\n",
      "         -0.0097, -0.0815, -0.1210, -0.1320,  0.0117,  0.1893,  0.0297, -0.0609,\n",
      "         -0.0963, -0.0788,  0.0810,  0.0670,  0.1692,  0.0684,  0.0730, -0.0411,\n",
      "          0.1759,  0.1943,  0.1316, -0.0388,  0.0772,  0.0503, -0.0200,  0.0197,\n",
      "         -0.0622, -0.0458, -0.0191,  0.0823,  0.1046,  0.1087, -0.0157,  0.0328,\n",
      "          0.0674, -0.1792,  0.0546, -0.0750,  0.2092,  0.0876,  0.1790, -0.0397,\n",
      "          0.1453,  0.0945,  0.0643,  0.1934,  0.0981,  0.1405,  0.0046, -0.1102,\n",
      "         -0.1080, -0.1053,  0.0836, -0.0286,  0.1281,  0.1765,  0.1460,  0.1653],\n",
      "        [ 0.0217,  0.0608,  0.0180,  0.1182, -0.0015,  0.2358,  0.0999, -0.0263,\n",
      "          0.2130,  0.0464,  0.1344,  0.1936,  0.1836,  0.0360,  0.2525,  0.0794,\n",
      "          0.0240,  0.2377,  0.0799,  0.0862,  0.0153,  0.0383,  0.0203,  0.2627,\n",
      "          0.0624,  0.1321,  0.2048,  0.1786,  0.1144,  0.1500,  0.1790,  0.2333,\n",
      "          0.1601,  0.2412,  0.1343,  0.0168,  0.2571, -0.0316,  0.1852,  0.1524,\n",
      "          0.1819,  0.0625,  0.1196,  0.2069,  0.0415, -0.0076,  0.1371,  0.1301,\n",
      "          0.1420,  0.1877,  0.0073,  0.0249, -0.0140, -0.0378,  0.0512,  0.2081,\n",
      "          0.1792,  0.1329,  0.2212,  0.1911,  0.0125,  0.0667,  0.0923,  0.0203],\n",
      "        [-0.2432, -0.0389, -0.0607, -0.2514, -0.1295, -0.0640, -0.2343, -0.1205,\n",
      "         -0.0664, -0.1287, -0.1257, -0.1201, -0.1826, -0.1296, -0.0727, -0.2364,\n",
      "         -0.0779, -0.0961, -0.2272, -0.1283, -0.1555, -0.1959,  0.0120, -0.0102,\n",
      "         -0.2502, -0.1883, -0.1268, -0.2563, -0.1923, -0.1318, -0.0212,  0.0008,\n",
      "         -0.2428, -0.1623, -0.0560, -0.2609, -0.1249, -0.1706, -0.0733, -0.0552,\n",
      "         -0.0518,  0.0199, -0.2394, -0.1281, -0.1758, -0.1558, -0.2302, -0.2144,\n",
      "         -0.1794, -0.1492, -0.1079, -0.1032, -0.1590, -0.1594, -0.1735, -0.0209,\n",
      "         -0.0855, -0.0201, -0.2071, -0.0804, -0.0605, -0.2281, -0.1177, -0.1835],\n",
      "        [-0.1199, -0.0040, -0.0171, -0.1126, -0.0389, -0.1439, -0.0756, -0.2350,\n",
      "         -0.2176, -0.1180, -0.2137, -0.1639, -0.2511, -0.1544, -0.1507, -0.2416,\n",
      "         -0.1334, -0.2039, -0.2148, -0.1279, -0.2169, -0.0966, -0.2507, -0.1037,\n",
      "         -0.0338, -0.2607, -0.0781, -0.0964, -0.0657, -0.1267, -0.2049, -0.1176,\n",
      "         -0.2286, -0.0985, -0.2631, -0.1282, -0.1944, -0.1586, -0.0471, -0.1824,\n",
      "         -0.1434, -0.1002, -0.1454, -0.1895, -0.2000, -0.0785, -0.0276, -0.0718,\n",
      "         -0.1264, -0.1293, -0.2575, -0.0849, -0.1897, -0.1408, -0.1570, -0.2139,\n",
      "         -0.1875, -0.2081, -0.0471, -0.0203, -0.2226, -0.1819, -0.1165, -0.1302],\n",
      "        [-0.1802, -0.0633, -0.0637, -0.2384, -0.0146, -0.0645, -0.0368, -0.2012,\n",
      "         -0.0591, -0.1984, -0.2079, -0.0333, -0.1293, -0.0126, -0.0276, -0.2091,\n",
      "         -0.0411, -0.1115, -0.1910, -0.1666, -0.2572, -0.1108, -0.0301, -0.0069,\n",
      "         -0.0419, -0.1471, -0.2321, -0.2270, -0.2011, -0.0748, -0.2039, -0.1080,\n",
      "         -0.1286, -0.0987, -0.0976, -0.1672, -0.1203, -0.1282, -0.0689, -0.0554,\n",
      "         -0.1317, -0.0058, -0.0384,  0.0061, -0.0375, -0.0419, -0.0470, -0.1376,\n",
      "         -0.1174, -0.2775, -0.0460, -0.2670, -0.0307, -0.2332, -0.2090, -0.1205,\n",
      "          0.0200, -0.2760, -0.0058, -0.1297, -0.1080, -0.1665, -0.2090, -0.2020],\n",
      "        [-0.1231, -0.0062, -0.0950, -0.1043, -0.2140,  0.0014, -0.0336, -0.0853,\n",
      "         -0.2615, -0.0879, -0.0022, -0.0751, -0.2024, -0.1064, -0.2189, -0.1478,\n",
      "         -0.0348, -0.0073, -0.2251, -0.0484, -0.2678, -0.2492, -0.2124, -0.1391,\n",
      "         -0.1951, -0.1726, -0.2075, -0.2298, -0.0884, -0.1018, -0.2566, -0.0414,\n",
      "          0.0069, -0.0555, -0.0833, -0.1223, -0.1051, -0.0751, -0.0328, -0.2043,\n",
      "         -0.1451, -0.0688, -0.1671, -0.2221, -0.1884, -0.1681, -0.2421, -0.1808,\n",
      "         -0.0997, -0.1051, -0.0809, -0.2211, -0.1743, -0.1355, -0.2134, -0.1541,\n",
      "         -0.1121, -0.0627, -0.2451, -0.0142, -0.1448, -0.0595, -0.0637, -0.2183],\n",
      "        [-0.1407, -0.0914, -0.0005, -0.1951, -0.0161, -0.0542, -0.1097, -0.0301,\n",
      "         -0.0765, -0.1972, -0.0196, -0.2088, -0.1064, -0.1356, -0.0803, -0.0849,\n",
      "          0.0189, -0.0439, -0.0596, -0.1871, -0.1199, -0.0753, -0.2501, -0.2427,\n",
      "         -0.1096, -0.1046, -0.0102, -0.1465, -0.1557, -0.1363, -0.1542, -0.0851,\n",
      "         -0.1840, -0.1841, -0.2426, -0.1027, -0.0040, -0.0706, -0.2566, -0.1660,\n",
      "         -0.1931, -0.1065, -0.1912, -0.1641, -0.2157, -0.0099, -0.2577, -0.0814,\n",
      "         -0.1111, -0.1409, -0.0185, -0.2288, -0.1723, -0.0902, -0.0752, -0.0525,\n",
      "         -0.0377, -0.0278, -0.0338, -0.1065, -0.1842, -0.1288, -0.2489, -0.2255],\n",
      "        [-0.2539, -0.1380, -0.1654, -0.0267, -0.1212, -0.1274, -0.2463, -0.0753,\n",
      "         -0.2290, -0.0399, -0.0709, -0.2486, -0.1969, -0.0137, -0.2001, -0.2162,\n",
      "         -0.0443, -0.2057, -0.1781, -0.2061, -0.1792, -0.2439, -0.1128, -0.0377,\n",
      "         -0.1224, -0.2723, -0.1398, -0.1423, -0.1756, -0.0747, -0.2065, -0.2079,\n",
      "         -0.0225, -0.0912, -0.2301, -0.0589, -0.1865, -0.2143, -0.0564, -0.1112,\n",
      "         -0.0200, -0.0838, -0.1945, -0.0198, -0.2092, -0.0651, -0.0361, -0.1678,\n",
      "         -0.1863, -0.1500, -0.2503, -0.2740, -0.1245, -0.0233, -0.0282, -0.1324,\n",
      "         -0.1591, -0.2734, -0.0080, -0.2291, -0.2594, -0.1609, -0.1763, -0.2036],\n",
      "        [-0.0516, -0.0618, -0.0515, -0.1324, -0.0758, -0.0121, -0.1110,  0.0086,\n",
      "         -0.0043, -0.2348, -0.0616, -0.0385, -0.1168, -0.0838, -0.0131, -0.1502,\n",
      "         -0.0839,  0.0026, -0.1464, -0.2231, -0.0360,  0.0006, -0.1124, -0.0058,\n",
      "         -0.1015, -0.0259, -0.2408, -0.1184, -0.2530, -0.2854, -0.0473, -0.2345,\n",
      "         -0.1317, -0.1904, -0.1330, -0.0268, -0.0028, -0.0418, -0.2312, -0.1631,\n",
      "         -0.1685, -0.0413, -0.1153, -0.2217, -0.2219, -0.0316, -0.1949, -0.1124,\n",
      "         -0.0946, -0.2711, -0.2002, -0.2090, -0.0699, -0.1576, -0.0864, -0.1298,\n",
      "         -0.0196, -0.0162, -0.0367, -0.1147, -0.1285, -0.0883, -0.0282, -0.1284],\n",
      "        [-0.2205, -0.1128, -0.2114, -0.1163, -0.0732, -0.0474, -0.0949, -0.1668,\n",
      "         -0.2371, -0.2560, -0.0541, -0.0704, -0.0962, -0.2574, -0.2749, -0.0283,\n",
      "         -0.0677, -0.2434, -0.1809, -0.0916, -0.2321, -0.1687, -0.0626, -0.1199,\n",
      "         -0.2002, -0.1164, -0.2182, -0.1223, -0.2658, -0.0749, -0.0277, -0.2505,\n",
      "         -0.1637, -0.1010, -0.2258, -0.1584, -0.0216, -0.0381, -0.0874, -0.1867,\n",
      "         -0.2840, -0.1811, -0.1091, -0.1530, -0.0389, -0.1132, -0.0818, -0.1548,\n",
      "         -0.0786, -0.2039, -0.0594, -0.2796, -0.2199, -0.0509, -0.0241, -0.0649,\n",
      "         -0.0618, -0.0783, -0.1577, -0.0774, -0.0268, -0.0769, -0.2652, -0.1091]])\n",
      "layer4.0.bias tensor([ 0.1278,  0.0571, -0.1977, -0.2206, -0.1804, -0.0446, -0.1893, -0.0693,\n",
      "        -0.1943, -0.1235])\n"
     ]
    }
   ],
   "source": [
    "#num_ftrs = model.forward.in_features\n",
    " \n",
    "for name, param in model.named_parameters():\n",
    "    print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-cd914773920e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.layer1 = Sequential(\n\u001b[0m\u001b[1;32m      2\u001b[0m                       Linear(4096, 2))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model.layer1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'out_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-d6ee396a1192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'out_features'"
     ]
    }
   ],
   "source": [
    "nn.Linear(num_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'parameter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ea8074fb84b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'parameter'"
     ]
    }
   ],
   "source": [
    "list(model.children())[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-45e4dc8164de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-3c96f51ab486>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLPRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_features' is not defined"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-d5aee46402fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-558e02a0941d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrn_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_X' is not defined"
     ]
    }
   ],
   "source": [
    "trn = data_utils.TensorDataset(trn_X, trn_y)\n",
    "trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val = data_utils.TensorDataset(val_X, val_y)\n",
    "val_loader = data_utils.DataLoader(val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_X_pd = df2_mod.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>ENSG00000069482</th>\n",
       "      <th>ENSG00000072657</th>\n",
       "      <th>ENSG00000078399</th>\n",
       "      <th>ENSG00000080572</th>\n",
       "      <th>ENSG00000100678</th>\n",
       "      <th>ENSG00000104435</th>\n",
       "      <th>ENSG00000104888</th>\n",
       "      <th>ENSG00000105146</th>\n",
       "      <th>ENSG00000109321</th>\n",
       "      <th>ENSG00000112499</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000274576</th>\n",
       "      <th>ENSG00000275756</th>\n",
       "      <th>ENSG00000276775</th>\n",
       "      <th>ENSG00000277247</th>\n",
       "      <th>ENSG00000278196</th>\n",
       "      <th>ENSG00000278698</th>\n",
       "      <th>ENSG00000279834</th>\n",
       "      <th>ENSG00000279970</th>\n",
       "      <th>ENSG00000280411</th>\n",
       "      <th>ENSG00000281880</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1910</th>\n",
       "      <td>0.970585</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.044476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043732</td>\n",
       "      <td>2.308592</td>\n",
       "      <td>1.014494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.920597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.604301</td>\n",
       "      <td>0.299376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894232</td>\n",
       "      <td>1.612154</td>\n",
       "      <td>0.761720</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-0982</th>\n",
       "      <td>0.395276</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.090384</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>0.242661</td>\n",
       "      <td>0.691196</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>...</td>\n",
       "      <td>24.797152</td>\n",
       "      <td>0.259035</td>\n",
       "      <td>4.625172</td>\n",
       "      <td>0.188089</td>\n",
       "      <td>4.211878</td>\n",
       "      <td>0.270091</td>\n",
       "      <td>0.034947</td>\n",
       "      <td>0.311310</td>\n",
       "      <td>0.357217</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>1.403594</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.133845</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.041762</td>\n",
       "      <td>0.074384</td>\n",
       "      <td>0.984290</td>\n",
       "      <td>2.329158</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>...</td>\n",
       "      <td>4.017149</td>\n",
       "      <td>0.289083</td>\n",
       "      <td>0.893372</td>\n",
       "      <td>0.314861</td>\n",
       "      <td>4.817979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>15.996040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1321</th>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.162223</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.240456</td>\n",
       "      <td>1.740308</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>...</td>\n",
       "      <td>2.576079</td>\n",
       "      <td>0.166843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121147</td>\n",
       "      <td>1.356422</td>\n",
       "      <td>0.521892</td>\n",
       "      <td>0.157563</td>\n",
       "      <td>2.033770</td>\n",
       "      <td>1.495528</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-30-1892</th>\n",
       "      <td>0.206074</td>\n",
       "      <td>0.133216</td>\n",
       "      <td>0.119614</td>\n",
       "      <td>0.056072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055381</td>\n",
       "      <td>0.280458</td>\n",
       "      <td>0.592872</td>\n",
       "      <td>0.914734</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>...</td>\n",
       "      <td>1.058604</td>\n",
       "      <td>0.114269</td>\n",
       "      <td>2.825069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.716018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294278</td>\n",
       "      <td>1.890974</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <td>0.319288</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.033696</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>0.060742</td>\n",
       "      <td>0.663423</td>\n",
       "      <td>0.094262</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.038608</td>\n",
       "      <td>0.567030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>4.616723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-0968</th>\n",
       "      <td>0.237050</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>0.185222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307004</td>\n",
       "      <td>0.213121</td>\n",
       "      <td>1.291373</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>...</td>\n",
       "      <td>15.221570</td>\n",
       "      <td>0.525782</td>\n",
       "      <td>4.332951</td>\n",
       "      <td>2.720169</td>\n",
       "      <td>31.845646</td>\n",
       "      <td>0.205584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710875</td>\n",
       "      <td>6.117782</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-30-1891</th>\n",
       "      <td>0.772034</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.110194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.200678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098616</td>\n",
       "      <td>2.959271</td>\n",
       "      <td>0.077290</td>\n",
       "      <td>...</td>\n",
       "      <td>47.331214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.631492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.568652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.395413</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0366</th>\n",
       "      <td>0.195435</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.631170</td>\n",
       "      <td>0.026487</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.006339</td>\n",
       "      <td>0.303848</td>\n",
       "      <td>0.703636</td>\n",
       "      <td>5.424154</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225023</td>\n",
       "      <td>0.534375</td>\n",
       "      <td>0.100086</td>\n",
       "      <td>1.481522</td>\n",
       "      <td>3.712525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058985</td>\n",
       "      <td>2.477118</td>\n",
       "      <td>0.602935</td>\n",
       "      <td>0.001573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0884</th>\n",
       "      <td>0.784894</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.035967</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.023577</td>\n",
       "      <td>0.643764</td>\n",
       "      <td>0.967456</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>...</td>\n",
       "      <td>2.586317</td>\n",
       "      <td>0.074447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162171</td>\n",
       "      <td>7.989302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060262</td>\n",
       "      <td>0.191723</td>\n",
       "      <td>3.849928</td>\n",
       "      <td>0.000402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 395 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID            ENSG00000069482  ENSG00000072657  ENSG00000078399  \\\n",
       "TCGA-61-1910         0.970585         0.003561         0.044476   \n",
       "TCGA-24-0982         0.395276         0.005010         0.090384   \n",
       "TCGA-36-1580         1.403594         0.008641         0.133845   \n",
       "TCGA-25-1321         0.308600         0.003129         0.004478   \n",
       "TCGA-30-1892         0.206074         0.133216         0.119614   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-04-1347         0.319288         0.000491         0.033696   \n",
       "TCGA-24-0968         0.237050         0.009708         0.185222   \n",
       "TCGA-30-1891         0.772034         0.000481         0.110194   \n",
       "TCGA-09-0366         0.195435         0.000085         1.631170   \n",
       "TCGA-13-0884         0.784894         0.000393         0.035967   \n",
       "\n",
       "ID            ENSG00000080572  ENSG00000100678  ENSG00000104435  \\\n",
       "TCGA-61-1910         0.000000         0.000000         0.000000   \n",
       "TCGA-24-0982         0.007062         0.000000         0.006438   \n",
       "TCGA-36-1580         0.001970         0.002559         0.041762   \n",
       "TCGA-25-1321         0.162223         0.000788         0.000000   \n",
       "TCGA-30-1892         0.056072         0.000000         0.055381   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-04-1347         0.005704         0.000988         0.011701   \n",
       "TCGA-24-0968         0.000000         0.000000         0.000000   \n",
       "TCGA-30-1891         0.000000         0.000646         0.200678   \n",
       "TCGA-09-0366         0.026487         0.001376         0.006339   \n",
       "TCGA-13-0884         0.012177         0.001055         0.004163   \n",
       "\n",
       "ID            ENSG00000104888  ENSG00000105146  ENSG00000109321  \\\n",
       "TCGA-61-1910         0.043732         2.308592         1.014494   \n",
       "TCGA-24-0982         0.082034         0.242661         0.691196   \n",
       "TCGA-36-1580         0.074384         0.984290         2.329158   \n",
       "TCGA-25-1321         0.101272         0.240456         1.740308   \n",
       "TCGA-30-1892         0.280458         0.592872         0.914734   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-04-1347         0.060742         0.663423         0.094262   \n",
       "TCGA-24-0968         0.307004         0.213121         1.291373   \n",
       "TCGA-30-1891         0.000000         0.098616         2.959271   \n",
       "TCGA-09-0366         0.303848         0.703636         5.424154   \n",
       "TCGA-13-0884         0.023577         0.643764         0.967456   \n",
       "\n",
       "ID            ENSG00000112499  ...  ENSG00000274576  ENSG00000275756  \\\n",
       "TCGA-61-1910         0.000000  ...         0.000000         0.920597   \n",
       "TCGA-24-0982         0.004156  ...        24.797152         0.259035   \n",
       "TCGA-36-1580         0.001391  ...         4.017149         0.289083   \n",
       "TCGA-25-1321         0.004819  ...         2.576079         0.166843   \n",
       "TCGA-30-1892         0.004400  ...         1.058604         0.114269   \n",
       "...                       ...  ...              ...              ...   \n",
       "TCGA-04-1347         0.000671  ...         0.000000         0.000000   \n",
       "TCGA-24-0968         0.003796  ...        15.221570         0.525782   \n",
       "TCGA-30-1891         0.077290  ...        47.331214         0.000000   \n",
       "TCGA-09-0366         0.008418  ...         0.225023         0.534375   \n",
       "TCGA-13-0884         0.005017  ...         2.586317         0.074447   \n",
       "\n",
       "ID            ENSG00000276775  ENSG00000277247  ENSG00000278196  \\\n",
       "TCGA-61-1910         0.000000         1.604301         0.299376   \n",
       "TCGA-24-0982         4.625172         0.188089         4.211878   \n",
       "TCGA-36-1580         0.893372         0.314861         4.817979   \n",
       "TCGA-25-1321         0.000000         0.121147         1.356422   \n",
       "TCGA-30-1892         2.825069         0.000000         3.716018   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-04-1347         0.000000         3.038608         0.567030   \n",
       "TCGA-24-0968         4.332951         2.720169        31.845646   \n",
       "TCGA-30-1891         2.631492         0.000000        65.568652   \n",
       "TCGA-09-0366         0.100086         1.481522         3.712525   \n",
       "TCGA-13-0884         0.000000         0.162171         7.989302   \n",
       "\n",
       "ID            ENSG00000278698  ENSG00000279834  ENSG00000279970  \\\n",
       "TCGA-61-1910         0.000000         0.894232         1.612154   \n",
       "TCGA-24-0982         0.270091         0.034947         0.311310   \n",
       "TCGA-36-1580         0.000000         0.000000         0.707253   \n",
       "TCGA-25-1321         0.521892         0.157563         2.033770   \n",
       "TCGA-30-1892         0.000000         0.000000         0.294278   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-04-1347         0.000000         0.000000         0.071847   \n",
       "TCGA-24-0968         0.205584         0.000000         0.710875   \n",
       "TCGA-30-1891         0.000000         0.000000         0.000000   \n",
       "TCGA-09-0366         0.000000         0.058985         2.477118   \n",
       "TCGA-13-0884         0.000000         0.060262         0.191723   \n",
       "\n",
       "ID            ENSG00000280411  ENSG00000281880  \n",
       "TCGA-61-1910         0.761720         0.000000  \n",
       "TCGA-24-0982         0.357217         0.000000  \n",
       "TCGA-36-1580        15.996040         0.000000  \n",
       "TCGA-25-1321         1.495528         0.000000  \n",
       "TCGA-30-1892         1.890974         0.000000  \n",
       "...                       ...              ...  \n",
       "TCGA-04-1347         4.616723         0.000000  \n",
       "TCGA-24-0968         6.117782         0.000000  \n",
       "TCGA-30-1891        80.395413         0.000000  \n",
       "TCGA-09-0366         0.602935         0.001573  \n",
       "TCGA-13-0884         3.849928         0.000402  \n",
       "\n",
       "[214 rows x 395 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_X_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_y_pd = df2_mod.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCGA-61-1910    0.007666\n",
       "TCGA-24-0982    0.007190\n",
       "TCGA-36-1580    0.027081\n",
       "TCGA-25-1321    0.002315\n",
       "TCGA-30-1892    0.057091\n",
       "                  ...   \n",
       "TCGA-04-1347    0.000000\n",
       "TCGA-24-0968    0.013682\n",
       "TCGA-30-1891    0.034186\n",
       "TCGA-09-0366    0.032361\n",
       "TCGA-13-0884    0.018597\n",
       "Name: ENSG00000048545, Length: 214, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_y_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_X = torch.from_numpy(trn_X_pd.astype(float).values)\n",
    "trn_y = torch.from_numpy(trn_y_pd.astype(float).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = data_utils.TensorDataset(trn_X, trn_y)\n",
    "trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dictionary batch\n",
    "class Dataset(data_utils.Dataset):\n",
    "   \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        return {'X': self.X[idx], 'y': self.y[idx]}\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = Dataset(trn_X, trn_y)\n",
    "trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
