{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils \n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('./Platin_Data/Semi_Final/common_patient.csv', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLATINUM_STATUS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1331</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1332</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1362</th>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1364</th>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2110</th>\n",
       "      <td>Resistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2111</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2113</th>\n",
       "      <td>Sensitive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PLATINUM_STATUS\n",
       "PATIENT_ID                  \n",
       "TCGA-04-1331       Sensitive\n",
       "TCGA-04-1332       Sensitive\n",
       "TCGA-04-1347       Sensitive\n",
       "TCGA-04-1362       Resistant\n",
       "TCGA-04-1364       Resistant\n",
       "...                      ...\n",
       "TCGA-61-2098       Sensitive\n",
       "TCGA-61-2109       Sensitive\n",
       "TCGA-61-2110       Resistant\n",
       "TCGA-61-2111       Sensitive\n",
       "TCGA-61-2113       Sensitive\n",
       "\n",
       "[210 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.loc[df_label['PLATINUM_STATUS'] == 'Sensitive', 'label'] = 0\n",
    "df_label.loc[df_label['PLATINUM_STATUS'] == 'Resistant', 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLATINUM_STATUS</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1331</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1332</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1362</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1364</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2110</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2111</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2113</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PLATINUM_STATUS  label\n",
       "PATIENT_ID                         \n",
       "TCGA-04-1331       Sensitive    0.0\n",
       "TCGA-04-1332       Sensitive    0.0\n",
       "TCGA-04-1347       Sensitive    0.0\n",
       "TCGA-04-1362       Resistant    1.0\n",
       "TCGA-04-1364       Resistant    1.0\n",
       "...                      ...    ...\n",
       "TCGA-61-2098       Sensitive    0.0\n",
       "TCGA-61-2109       Sensitive    0.0\n",
       "TCGA-61-2110       Resistant    1.0\n",
       "TCGA-61-2111       Sensitive    0.0\n",
       "TCGA-61-2113       Sensitive    0.0\n",
       "\n",
       "[210 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('./Platin_Data/Semi_Final/PC_tpm_300_minmax.csv', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-04-1331</th>\n",
       "      <th>TCGA-04-1332</th>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <th>TCGA-04-1362</th>\n",
       "      <th>TCGA-04-1364</th>\n",
       "      <th>TCGA-04-1365</th>\n",
       "      <th>TCGA-04-1514</th>\n",
       "      <th>TCGA-04-1530</th>\n",
       "      <th>TCGA-04-1536</th>\n",
       "      <th>TCGA-04-1542</th>\n",
       "      <th>...</th>\n",
       "      <th>TCGA-61-2000</th>\n",
       "      <th>TCGA-61-2008</th>\n",
       "      <th>TCGA-61-2009</th>\n",
       "      <th>TCGA-61-2092</th>\n",
       "      <th>TCGA-61-2097</th>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <th>TCGA-61-2110</th>\n",
       "      <th>TCGA-61-2111</th>\n",
       "      <th>TCGA-61-2113</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000131096</th>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>4.124503e-04</td>\n",
       "      <td>0.200155</td>\n",
       "      <td>2.717863e-04</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.023144</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000187581</th>\n",
       "      <td>0.057252</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.008426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015051</td>\n",
       "      <td>1.777907e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.618373e-03</td>\n",
       "      <td>0.018865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.222856</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.154442</td>\n",
       "      <td>0.051745</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.096016</td>\n",
       "      <td>0.010557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000047936</th>\n",
       "      <td>0.115277</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.007940</td>\n",
       "      <td>2.697600e-05</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>1.381244e-05</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000186198</th>\n",
       "      <td>0.016083</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.020709</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>1.216050e-03</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.846397e-04</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.002652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000179914</th>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.056473</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>1.127380e-03</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>4.617982e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032674</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.118942</td>\n",
       "      <td>0.030643</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000148604</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.741721e-04</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.297173e-05</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000105370</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>4.025857e-04</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000118733</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>3.460289e-04</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>1.955000e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000215262</th>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.166664e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000155052</th>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.211643e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.539190e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TCGA-04-1331  TCGA-04-1332  TCGA-04-1347  TCGA-04-1362  \\\n",
       "ID                                                                        \n",
       "ENSG00000131096      0.000866      0.000566      0.000096      0.001492   \n",
       "ENSG00000187581      0.057252      0.001385      0.002826      0.008426   \n",
       "ENSG00000047936      0.115277      0.002034      0.000060      0.001151   \n",
       "ENSG00000186198      0.016083      0.004467      0.004142      0.002964   \n",
       "ENSG00000179914      0.006483      0.056473      0.001344      0.000687   \n",
       "...                       ...           ...           ...           ...   \n",
       "ENSG00000148604      0.000000      0.000167      0.000000      0.000540   \n",
       "ENSG00000105370      0.000000      0.000000      0.000000      0.000000   \n",
       "ENSG00000118733      0.000115      0.001841      0.000060      0.012785   \n",
       "ENSG00000215262      0.000074      0.000075      0.000044      0.000000   \n",
       "ENSG00000155052      0.000031      0.000004      0.000000      0.000000   \n",
       "\n",
       "                 TCGA-04-1364  TCGA-04-1365  TCGA-04-1514  TCGA-04-1530  \\\n",
       "ID                                                                        \n",
       "ENSG00000131096      0.001883      0.000146  4.124503e-04      0.200155   \n",
       "ENSG00000187581      1.000000      0.015051  1.777907e-02      0.000000   \n",
       "ENSG00000047936      0.000016      0.007940  2.697600e-05      0.000705   \n",
       "ENSG00000186198      0.020709      0.005042  1.216050e-03      0.001000   \n",
       "ENSG00000179914      0.000372      0.001071  1.127380e-03      0.000742   \n",
       "...                       ...           ...           ...           ...   \n",
       "ENSG00000148604      0.000000      0.000000  1.741721e-04      0.000027   \n",
       "ENSG00000105370      0.000133      0.000104  4.025857e-04      0.000199   \n",
       "ENSG00000118733      0.000006      0.002048  3.460289e-04      0.000416   \n",
       "ENSG00000215262      0.000007      0.000000  9.166664e-06      0.000000   \n",
       "ENSG00000155052      0.000007      0.000000  5.211643e-07      0.000000   \n",
       "\n",
       "                 TCGA-04-1536  TCGA-04-1542  ...  TCGA-61-2000  TCGA-61-2008  \\\n",
       "ID                                           ...                               \n",
       "ENSG00000131096  2.717863e-04      0.000401  ...      0.000119      0.000052   \n",
       "ENSG00000187581  1.618373e-03      0.018865  ...      0.015682      0.001707   \n",
       "ENSG00000047936  1.381244e-05      0.000171  ...      0.000045      0.000044   \n",
       "ENSG00000186198  2.846397e-04      0.001728  ...      0.005363      0.001585   \n",
       "ENSG00000179914  4.617982e-03      0.000000  ...      0.032674      0.001082   \n",
       "...                       ...           ...  ...           ...           ...   \n",
       "ENSG00000148604  1.297173e-05      0.000756  ...      0.000209      0.000000   \n",
       "ENSG00000105370  0.000000e+00      0.000000  ...      0.000000      0.000000   \n",
       "ENSG00000118733  1.955000e-06      0.000000  ...      0.000063      0.000031   \n",
       "ENSG00000215262  0.000000e+00      0.000000  ...      0.000000      0.000000   \n",
       "ENSG00000155052  8.539190e-07      0.000000  ...      0.000000      0.000000   \n",
       "\n",
       "                 TCGA-61-2009  TCGA-61-2092  TCGA-61-2097  TCGA-61-2098  \\\n",
       "ID                                                                        \n",
       "ENSG00000131096      0.000138      0.000038      0.000651      0.000309   \n",
       "ENSG00000187581      0.222856      0.000508      0.005218      0.154442   \n",
       "ENSG00000047936      0.000303      0.000000      0.000134      0.000215   \n",
       "ENSG00000186198      0.002821      0.000372      0.003824      0.001345   \n",
       "ENSG00000179914      0.001927      0.000023      0.006381      0.001390   \n",
       "...                       ...           ...           ...           ...   \n",
       "ENSG00000148604      0.000000      0.000027      0.000000      0.000042   \n",
       "ENSG00000105370      0.000000      0.000000      0.000000      0.000229   \n",
       "ENSG00000118733      0.000018      0.000001      0.000079      0.000070   \n",
       "ENSG00000215262      0.000024      0.000004      0.000000      0.000002   \n",
       "ENSG00000155052      0.000013      0.000002      0.000000      0.000003   \n",
       "\n",
       "                 TCGA-61-2109  TCGA-61-2110  TCGA-61-2111  TCGA-61-2113  \n",
       "ID                                                                       \n",
       "ENSG00000131096      0.000587      0.000163      0.023144      0.000137  \n",
       "ENSG00000187581      0.051745      0.006289      0.096016      0.010557  \n",
       "ENSG00000047936      0.002650      0.000069      0.000012      0.000103  \n",
       "ENSG00000186198      0.012640      0.000263      0.001709      0.002652  \n",
       "ENSG00000179914      0.118942      0.030643      0.001957      0.000410  \n",
       "...                       ...           ...           ...           ...  \n",
       "ENSG00000148604      0.000000      0.000108      0.000027      0.000000  \n",
       "ENSG00000105370      0.000000      0.000000      0.000100      0.000000  \n",
       "ENSG00000118733      0.000391      0.001829      0.000004      0.000009  \n",
       "ENSG00000215262      0.000000      0.000007      0.000000      0.000000  \n",
       "ENSG00000155052      0.000006      0.000001      0.000003      0.000004  \n",
       "\n",
       "[300 rows x 210 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_mod = df_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>ENSG00000131096</th>\n",
       "      <th>ENSG00000187581</th>\n",
       "      <th>ENSG00000047936</th>\n",
       "      <th>ENSG00000186198</th>\n",
       "      <th>ENSG00000179914</th>\n",
       "      <th>ENSG00000186897</th>\n",
       "      <th>ENSG00000138136</th>\n",
       "      <th>ENSG00000139219</th>\n",
       "      <th>ENSG00000136944</th>\n",
       "      <th>ENSG00000182870</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000169469</th>\n",
       "      <th>ENSG00000164756</th>\n",
       "      <th>ENSG00000144227</th>\n",
       "      <th>ENSG00000225110</th>\n",
       "      <th>ENSG00000108242</th>\n",
       "      <th>ENSG00000148604</th>\n",
       "      <th>ENSG00000105370</th>\n",
       "      <th>ENSG00000118733</th>\n",
       "      <th>ENSG00000215262</th>\n",
       "      <th>ENSG00000155052</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1331</th>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.057252</td>\n",
       "      <td>0.115277</td>\n",
       "      <td>0.016083</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.287149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057276</td>\n",
       "      <td>0.048614</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016503</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1332</th>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.056473</td>\n",
       "      <td>0.046285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.002826</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.793124</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1362</th>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.008426</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.007866</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.027998</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1364</th>\n",
       "      <td>0.001883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.020709</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.154442</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.233778</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108658</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.051745</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.118942</td>\n",
       "      <td>0.459733</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.029329</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2110</th>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.030643</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2111</th>\n",
       "      <td>0.023144</td>\n",
       "      <td>0.096016</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.021030</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2113</th>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.010557</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.138558</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125198</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID            ENSG00000131096  ENSG00000187581  ENSG00000047936  \\\n",
       "TCGA-04-1331         0.000866         0.057252         0.115277   \n",
       "TCGA-04-1332         0.000566         0.001385         0.002034   \n",
       "TCGA-04-1347         0.000096         0.002826         0.000060   \n",
       "TCGA-04-1362         0.001492         0.008426         0.001151   \n",
       "TCGA-04-1364         0.001883         1.000000         0.000016   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-61-2098         0.000309         0.154442         0.000215   \n",
       "TCGA-61-2109         0.000587         0.051745         0.002650   \n",
       "TCGA-61-2110         0.000163         0.006289         0.000069   \n",
       "TCGA-61-2111         0.023144         0.096016         0.000012   \n",
       "TCGA-61-2113         0.000137         0.010557         0.000103   \n",
       "\n",
       "ID            ENSG00000186198  ENSG00000179914  ENSG00000186897  \\\n",
       "TCGA-04-1331         0.016083         0.006483         0.287149   \n",
       "TCGA-04-1332         0.004467         0.056473         0.046285   \n",
       "TCGA-04-1347         0.004142         0.001344         0.793124   \n",
       "TCGA-04-1362         0.002964         0.000687         0.007866   \n",
       "TCGA-04-1364         0.020709         0.000372         0.245882   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-61-2098         0.001345         0.001390         0.016812   \n",
       "TCGA-61-2109         0.012640         0.118942         0.459733   \n",
       "TCGA-61-2110         0.000263         0.030643         0.001324   \n",
       "TCGA-61-2111         0.001709         0.001957         0.002696   \n",
       "TCGA-61-2113         0.002652         0.000410         0.138558   \n",
       "\n",
       "ID            ENSG00000138136  ENSG00000139219  ENSG00000136944  \\\n",
       "TCGA-04-1331         0.000000         0.057276         0.048614   \n",
       "TCGA-04-1332         0.000000         0.005921         0.029110   \n",
       "TCGA-04-1347         0.000461         0.001680         0.000038   \n",
       "TCGA-04-1362         0.001649         0.027998         0.005270   \n",
       "TCGA-04-1364         0.000000         0.010063         0.000123   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-61-2098         0.000855         0.233778         0.002315   \n",
       "TCGA-61-2109         0.001407         0.029329         0.002209   \n",
       "TCGA-61-2110         0.000000         0.015528         0.001865   \n",
       "TCGA-61-2111         0.021030         0.000892         0.000157   \n",
       "TCGA-61-2113         0.004919         0.003812         0.000630   \n",
       "\n",
       "ID            ENSG00000182870  ...  ENSG00000169469  ENSG00000164756  \\\n",
       "TCGA-04-1331         0.001766  ...         0.016503         0.000025   \n",
       "TCGA-04-1332         0.000781  ...         0.000000         0.000000   \n",
       "TCGA-04-1347         0.000037  ...         0.000000         0.000029   \n",
       "TCGA-04-1362         0.000579  ...         0.672711         0.000000   \n",
       "TCGA-04-1364         0.000088  ...         0.000631         0.000005   \n",
       "...                       ...  ...              ...              ...   \n",
       "TCGA-61-2098         0.000060  ...         0.108658         0.000011   \n",
       "TCGA-61-2109         0.002394  ...         0.000000         0.000671   \n",
       "TCGA-61-2110         0.008710  ...         0.000000         0.000000   \n",
       "TCGA-61-2111         0.000115  ...         0.000949         0.000007   \n",
       "TCGA-61-2113         0.000292  ...         0.125198         0.000188   \n",
       "\n",
       "ID            ENSG00000144227  ENSG00000225110  ENSG00000108242  \\\n",
       "TCGA-04-1331         0.000352         0.000000         0.000000   \n",
       "TCGA-04-1332         0.000088         0.000796         0.000000   \n",
       "TCGA-04-1347         0.000000         0.000000         0.000095   \n",
       "TCGA-04-1362         0.000018         0.000000         0.000189   \n",
       "TCGA-04-1364         0.000010         0.001047         0.000184   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-61-2098         0.000006         0.000000         0.000381   \n",
       "TCGA-61-2109         0.000137         0.001239         0.000193   \n",
       "TCGA-61-2110         0.000000         0.000000         0.000000   \n",
       "TCGA-61-2111         0.000007         0.000000         0.000660   \n",
       "TCGA-61-2113         0.000207         0.000000         0.000000   \n",
       "\n",
       "ID            ENSG00000148604  ENSG00000105370  ENSG00000118733  \\\n",
       "TCGA-04-1331         0.000000         0.000000         0.000115   \n",
       "TCGA-04-1332         0.000167         0.000000         0.001841   \n",
       "TCGA-04-1347         0.000000         0.000000         0.000060   \n",
       "TCGA-04-1362         0.000540         0.000000         0.012785   \n",
       "TCGA-04-1364         0.000000         0.000133         0.000006   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-61-2098         0.000042         0.000229         0.000070   \n",
       "TCGA-61-2109         0.000000         0.000000         0.000391   \n",
       "TCGA-61-2110         0.000108         0.000000         0.001829   \n",
       "TCGA-61-2111         0.000027         0.000100         0.000004   \n",
       "TCGA-61-2113         0.000000         0.000000         0.000009   \n",
       "\n",
       "ID            ENSG00000215262  ENSG00000155052  \n",
       "TCGA-04-1331         0.000074         0.000031  \n",
       "TCGA-04-1332         0.000075         0.000004  \n",
       "TCGA-04-1347         0.000044         0.000000  \n",
       "TCGA-04-1362         0.000000         0.000000  \n",
       "TCGA-04-1364         0.000007         0.000007  \n",
       "...                       ...              ...  \n",
       "TCGA-61-2098         0.000002         0.000003  \n",
       "TCGA-61-2109         0.000000         0.000006  \n",
       "TCGA-61-2110         0.000007         0.000001  \n",
       "TCGA-61-2111         0.000000         0.000003  \n",
       "TCGA-61-2113         0.000000         0.000004  \n",
       "\n",
       "[210 rows x 300 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_label_mi = pd.read_csv('./Platin_Data/miRNA_patient.csv', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_mi = pd.read_csv('./Platin_Data/Semi_Final/MIR_rpm_100_minmax.csv', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_mi = df_data_mi.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_lnc = pd.read_csv('./Platin_Data/Semi_Final/LNC_tpm_100_minmax.csv', sep = '\\t', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCGA-04-1331</th>\n",
       "      <th>TCGA-04-1332</th>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <th>TCGA-04-1362</th>\n",
       "      <th>TCGA-04-1364</th>\n",
       "      <th>TCGA-04-1365</th>\n",
       "      <th>TCGA-04-1514</th>\n",
       "      <th>TCGA-04-1530</th>\n",
       "      <th>TCGA-04-1536</th>\n",
       "      <th>TCGA-04-1542</th>\n",
       "      <th>...</th>\n",
       "      <th>TCGA-61-2000</th>\n",
       "      <th>TCGA-61-2008</th>\n",
       "      <th>TCGA-61-2009</th>\n",
       "      <th>TCGA-61-2092</th>\n",
       "      <th>TCGA-61-2097</th>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <th>TCGA-61-2109</th>\n",
       "      <th>TCGA-61-2110</th>\n",
       "      <th>TCGA-61-2111</th>\n",
       "      <th>TCGA-61-2113</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000233048</th>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000083622</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.007278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000269994</th>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.002408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.029038</td>\n",
       "      <td>0.004058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000258752</th>\n",
       "      <td>0.098097</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.050686</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>0.248185</td>\n",
       "      <td>0.013590</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053335</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.040338</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.029168</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.008254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000249790</th>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.010075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.011822</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000256904</th>\n",
       "      <td>0.011139</td>\n",
       "      <td>0.024870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000232197</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038062</td>\n",
       "      <td>0.010317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023344</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000224957</th>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000259181</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000229520</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162982</td>\n",
       "      <td>0.350370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TCGA-04-1331  TCGA-04-1332  TCGA-04-1347  TCGA-04-1362  \\\n",
       "ID                                                                        \n",
       "ENSG00000233048      0.000801      0.000000      0.000000      0.000000   \n",
       "ENSG00000083622      0.000000      0.001047      0.000000      0.001600   \n",
       "ENSG00000269994      0.000294      0.000547      0.001422      0.002408   \n",
       "ENSG00000258752      0.098097      0.002003      0.002169      0.003266   \n",
       "ENSG00000249790      0.001326      0.002467      0.006410      0.001810   \n",
       "...                       ...           ...           ...           ...   \n",
       "ENSG00000256904      0.011139      0.024870      0.000000      0.015204   \n",
       "ENSG00000232197      0.000000      0.001466      1.000000      0.005378   \n",
       "ENSG00000224957      0.000161      0.000060      0.001206      0.000000   \n",
       "ENSG00000259181      0.000000      0.000388      0.001261      0.000000   \n",
       "ENSG00000229520      0.000000      0.042520      0.000000      0.000000   \n",
       "\n",
       "                 TCGA-04-1364  TCGA-04-1365  TCGA-04-1514  TCGA-04-1530  \\\n",
       "ID                                                                        \n",
       "ENSG00000233048      0.003353      0.000284      0.000174      0.000000   \n",
       "ENSG00000083622      0.000000      0.000581      0.000000      0.003550   \n",
       "ENSG00000269994      0.000000      0.001458      0.000447      0.003711   \n",
       "ENSG00000258752      0.050686      0.005930      0.248185      0.013590   \n",
       "ENSG00000249790      0.002100      0.003286      0.010075      0.000000   \n",
       "...                       ...           ...           ...           ...   \n",
       "ENSG00000256904      0.000000      0.000000      0.000000      0.000000   \n",
       "ENSG00000232197      1.000000      0.151355      1.000000      0.000000   \n",
       "ENSG00000224957      0.000013      0.000000      0.000049      0.000244   \n",
       "ENSG00000259181      0.003306      0.003879      0.001586      0.005268   \n",
       "ENSG00000229520      0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "                 TCGA-04-1536  TCGA-04-1542  ...  TCGA-61-2000  TCGA-61-2008  \\\n",
       "ID                                           ...                               \n",
       "ENSG00000233048      0.000000      0.000297  ...      0.000000      0.000510   \n",
       "ENSG00000083622      0.000000      0.000000  ...      0.000000      0.000000   \n",
       "ENSG00000269994      0.002415      0.000000  ...      0.003453      0.001311   \n",
       "ENSG00000258752      0.004913      0.000000  ...      0.000000      0.053335   \n",
       "ENSG00000249790      0.000000      0.000000  ...      0.010379      0.011822   \n",
       "...                       ...           ...  ...           ...           ...   \n",
       "ENSG00000256904      0.045749      0.000000  ...      0.000000      0.000000   \n",
       "ENSG00000232197      0.000000      0.000000  ...      0.000000      0.000000   \n",
       "ENSG00000224957      0.000000      0.000000  ...      0.000063      0.000143   \n",
       "ENSG00000259181      0.000000      0.000000  ...      0.000000      0.000000   \n",
       "ENSG00000229520      0.000000      0.000000  ...      0.000000      0.056602   \n",
       "\n",
       "                 TCGA-61-2009  TCGA-61-2092  TCGA-61-2097  TCGA-61-2098  \\\n",
       "ID                                                                        \n",
       "ENSG00000233048      0.000000      0.000000      0.000000      0.000316   \n",
       "ENSG00000083622      0.000000      0.000000      0.000000      0.000000   \n",
       "ENSG00000269994      0.000431      0.000268      0.000000      0.000541   \n",
       "ENSG00000258752      0.002633      0.040338      0.001441      0.029168   \n",
       "ENSG00000249790      0.011671      0.006041      0.014375      0.006709   \n",
       "...                       ...           ...           ...           ...   \n",
       "ENSG00000256904      0.016342      0.000000      0.000000      0.000000   \n",
       "ENSG00000232197      1.000000      0.028724      0.000000      0.038062   \n",
       "ENSG00000224957      0.000094      0.000147      0.000000      0.000030   \n",
       "ENSG00000259181      0.001531      0.000000      0.000000      0.000480   \n",
       "ENSG00000229520      0.000000      0.000000      0.045882      0.000000   \n",
       "\n",
       "                 TCGA-61-2109  TCGA-61-2110  TCGA-61-2111  TCGA-61-2113  \n",
       "ID                                                                       \n",
       "ENSG00000233048      0.000031      0.000000      0.000452      0.000000  \n",
       "ENSG00000083622      0.000038      0.000021      0.003009      0.007278  \n",
       "ENSG00000269994      0.000047      0.000036      0.029038      0.004058  \n",
       "ENSG00000258752      0.000032      0.000164      0.001181      0.008254  \n",
       "ENSG00000249790      0.000071      0.000000      0.000000      0.018295  \n",
       "...                       ...           ...           ...           ...  \n",
       "ENSG00000256904      0.000000      0.000340      0.000000      0.000000  \n",
       "ENSG00000232197      0.010317      0.000000      0.023344      0.000000  \n",
       "ENSG00000224957      0.000002      0.000008      0.000032      0.000222  \n",
       "ENSG00000259181      0.000000      0.000000      0.003091      0.003600  \n",
       "ENSG00000229520      0.000000      0.000000      0.162982      0.350370  \n",
       "\n",
       "[100 rows x 210 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_lnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_lnc = df_data_lnc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mi = pd.concat([df_label_mi,df_data_mi], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_label,df_data_mod,df_data_mi,df_data_lnc], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(df, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLATINUM_STATUS</th>\n",
       "      <th>label</th>\n",
       "      <th>ENSG00000131096</th>\n",
       "      <th>ENSG00000187581</th>\n",
       "      <th>ENSG00000047936</th>\n",
       "      <th>ENSG00000186198</th>\n",
       "      <th>ENSG00000179914</th>\n",
       "      <th>ENSG00000186897</th>\n",
       "      <th>ENSG00000138136</th>\n",
       "      <th>ENSG00000139219</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000272457</th>\n",
       "      <th>ENSG00000260426</th>\n",
       "      <th>ENSG00000250685</th>\n",
       "      <th>ENSG00000280916</th>\n",
       "      <th>ENSG00000255580</th>\n",
       "      <th>ENSG00000256904</th>\n",
       "      <th>ENSG00000232197</th>\n",
       "      <th>ENSG00000224957</th>\n",
       "      <th>ENSG00000259181</th>\n",
       "      <th>ENSG00000229520</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-24-0970</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.084063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023367</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.640174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078707</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2045</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.017942</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.023254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017825</td>\n",
       "      <td>0.267083</td>\n",
       "      <td>0.011205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-10-0937</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.020261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-1488</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.030282</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.024278</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1711</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0366</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.021954</td>\n",
       "      <td>0.019088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.046552</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117877</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1316</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.019078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1105</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.698923</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.051929</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.075984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1778</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012885</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0884</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PLATINUM_STATUS  label  ENSG00000131096  ENSG00000187581  \\\n",
       "PATIENT_ID                                                              \n",
       "TCGA-24-0970       Resistant    1.0         0.000724         0.084063   \n",
       "TCGA-09-2045       Sensitive    0.0         0.000772         0.006801   \n",
       "TCGA-10-0937       Resistant    1.0         0.000051         0.000000   \n",
       "TCGA-13-1488       Sensitive    0.0         0.000783         0.004499   \n",
       "TCGA-29-1711       Sensitive    0.0         0.000111         0.005844   \n",
       "...                      ...    ...              ...              ...   \n",
       "TCGA-09-0366       Resistant    1.0         0.000504         0.018500   \n",
       "TCGA-25-1316       Resistant    1.0         0.000171         0.000250   \n",
       "TCGA-24-1105       Sensitive    0.0         0.000153         0.698923   \n",
       "TCGA-29-1778       Sensitive    0.0         0.000179         0.006308   \n",
       "TCGA-13-0884       Sensitive    0.0         0.000180         0.000000   \n",
       "\n",
       "              ENSG00000047936  ENSG00000186198  ENSG00000179914  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-24-0970         0.000000         0.023367         0.001182   \n",
       "TCGA-09-2045         0.002786         0.017942         0.008317   \n",
       "TCGA-10-0937         0.001408         0.015682         0.001212   \n",
       "TCGA-13-1488         0.030282         0.001758         0.011818   \n",
       "TCGA-29-1711         0.000000         0.000286         0.005426   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-09-0366         0.000589         0.002169         0.021954   \n",
       "TCGA-25-1316         0.000002         0.000477         0.000000   \n",
       "TCGA-24-1105         0.000367         0.002126         0.002464   \n",
       "TCGA-29-1778         0.000323         0.000809         0.001286   \n",
       "TCGA-13-0884         0.000401         0.003401         0.000000   \n",
       "\n",
       "              ENSG00000186897  ENSG00000138136  ENSG00000139219  ...  \\\n",
       "PATIENT_ID                                                       ...   \n",
       "TCGA-24-0970         0.640174         0.000000         0.003232  ...   \n",
       "TCGA-09-2045         0.005012         0.002218         0.023254  ...   \n",
       "TCGA-10-0937         0.020261         0.000000         0.001906  ...   \n",
       "TCGA-13-1488         0.675253         0.000000         0.000390  ...   \n",
       "TCGA-29-1711         0.002153         0.000000         0.000072  ...   \n",
       "...                       ...              ...              ...  ...   \n",
       "TCGA-09-0366         0.019088         0.000000         0.008939  ...   \n",
       "TCGA-25-1316         0.006338         0.000000         0.001350  ...   \n",
       "TCGA-24-1105         0.051929         0.000169         0.000231  ...   \n",
       "TCGA-29-1778         0.008716         0.000000         0.001436  ...   \n",
       "TCGA-13-0884         0.037804         0.000000         0.000136  ...   \n",
       "\n",
       "              ENSG00000272457  ENSG00000260426  ENSG00000250685  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-24-0970         0.000000         0.000000         0.000000   \n",
       "TCGA-09-2045         0.160571         0.000000         0.017825   \n",
       "TCGA-10-0937         0.000000         0.000000         0.000000   \n",
       "TCGA-13-1488         0.000000         0.000000         0.000000   \n",
       "TCGA-29-1711         0.000000         0.008103         0.000000   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-09-0366         0.000000         0.000000         0.002989   \n",
       "TCGA-25-1316         0.000000         0.000000         0.007614   \n",
       "TCGA-24-1105         0.000000         0.003237         0.000000   \n",
       "TCGA-29-1778         0.012885         0.002304         0.001430   \n",
       "TCGA-13-0884         0.000000         0.000000         0.000000   \n",
       "\n",
       "              ENSG00000280916  ENSG00000255580  ENSG00000256904  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-24-0970         0.000000         0.003489         0.000000   \n",
       "TCGA-09-2045         0.267083         0.011205         0.000000   \n",
       "TCGA-10-0937         0.007069         0.000000         0.000000   \n",
       "TCGA-13-1488         0.003821         0.004568         0.024278   \n",
       "TCGA-29-1711         0.000000         0.001054         0.000000   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-09-0366         0.046552         0.000235         0.000000   \n",
       "TCGA-25-1316         0.000000         0.000399         0.019078   \n",
       "TCGA-24-1105         0.002113         0.000211         0.003357   \n",
       "TCGA-29-1778         0.013536         0.000000         0.028671   \n",
       "TCGA-13-0884         0.000118         0.000000         0.000249   \n",
       "\n",
       "              ENSG00000232197  ENSG00000224957  ENSG00000259181  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-24-0970         0.078707         0.000804         0.005211   \n",
       "TCGA-09-2045         0.000000         0.000000         0.000000   \n",
       "TCGA-10-0937         0.000000         0.000000         0.000000   \n",
       "TCGA-13-1488         0.022900         0.000023         0.001516   \n",
       "TCGA-29-1711         0.000000         0.000000         0.000000   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-09-0366         0.117877         0.000141         0.000000   \n",
       "TCGA-25-1316         0.000000         0.000037         0.001192   \n",
       "TCGA-24-1105         0.075984         0.000000         0.000314   \n",
       "TCGA-29-1778         0.001690         0.000097         0.000224   \n",
       "TCGA-13-0884         0.000264         0.000004         0.000000   \n",
       "\n",
       "              ENSG00000229520  \n",
       "PATIENT_ID                     \n",
       "TCGA-24-0970         0.000000  \n",
       "TCGA-09-2045         0.000000  \n",
       "TCGA-10-0937         0.000000  \n",
       "TCGA-13-1488         0.000000  \n",
       "TCGA-29-1711         0.000000  \n",
       "...                       ...  \n",
       "TCGA-09-0366         0.008536  \n",
       "TCGA-25-1316         0.000000  \n",
       "TCGA-24-1105         0.000000  \n",
       "TCGA-29-1778         0.000000  \n",
       "TCGA-13-0884         0.000284  \n",
       "\n",
       "[168 rows x 502 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train_platin_total_lnc__100_500.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLATINUM_STATUS</th>\n",
       "      <th>label</th>\n",
       "      <th>ENSG00000131096</th>\n",
       "      <th>ENSG00000187581</th>\n",
       "      <th>ENSG00000047936</th>\n",
       "      <th>ENSG00000186198</th>\n",
       "      <th>ENSG00000179914</th>\n",
       "      <th>ENSG00000186897</th>\n",
       "      <th>ENSG00000138136</th>\n",
       "      <th>ENSG00000139219</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000272457</th>\n",
       "      <th>ENSG00000260426</th>\n",
       "      <th>ENSG00000250685</th>\n",
       "      <th>ENSG00000280916</th>\n",
       "      <th>ENSG00000255580</th>\n",
       "      <th>ENSG00000256904</th>\n",
       "      <th>ENSG00000232197</th>\n",
       "      <th>ENSG00000224957</th>\n",
       "      <th>ENSG00000259181</th>\n",
       "      <th>ENSG00000229520</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1544</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.463682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-2393</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.048461</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-20-1682</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.031677</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.051462</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1626</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.050532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034617</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184072</td>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1028</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.075687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082711</td>\n",
       "      <td>0.011095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028963</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2056</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1568</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.032611</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.039247</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070571</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1563</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.072323</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-57-1586</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.015883</td>\n",
       "      <td>0.021943</td>\n",
       "      <td>0.015131</td>\n",
       "      <td>0.007014</td>\n",
       "      <td>0.137535</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.049734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021394</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1728</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.463339</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012769</td>\n",
       "      <td>0.027406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0886</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-2027</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.013494</td>\n",
       "      <td>0.015298</td>\n",
       "      <td>0.033416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.046730</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109407</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1552</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005673</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2113</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.010557</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.138558</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.350370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0887</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.020691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0901</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.035130</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0.013127</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014892</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.285647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2000</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.015682</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.032674</td>\n",
       "      <td>0.251694</td>\n",
       "      <td>0.028988</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0726</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0765</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.009607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1766</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.187622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0795</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.045838</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.013763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.035548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1930</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1923</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>0.050349</td>\n",
       "      <td>0.079004</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.029882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-30-1860</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.013389</td>\n",
       "      <td>0.013881</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.070193</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014791</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-0968</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.063953</td>\n",
       "      <td>0.234121</td>\n",
       "      <td>0.082941</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.046097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-31-1946</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>0.251260</td>\n",
       "      <td>0.013985</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1651</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.103842</td>\n",
       "      <td>0.073152</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015254</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0885</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.055562</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.371642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-1770</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.009779</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.048647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1633</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.297922</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065815</td>\n",
       "      <td>0.012975</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064161</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1574</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1118</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.009664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-23-1029</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.016615</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.022183</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.015210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-2098</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.154442</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.233778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.030677</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038062</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-29-2414</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.352454</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.019763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038342</td>\n",
       "      <td>0.008639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1910</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.012419</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.033558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1530</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.010581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1464</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.028075</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-31-1951</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.012095</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1328</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120687</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-1928</th>\n",
       "      <td>Resistant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.056282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>0.093112</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-2051</th>\n",
       "      <td>Sensitive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071890</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PLATINUM_STATUS  label  ENSG00000131096  ENSG00000187581  \\\n",
       "PATIENT_ID                                                              \n",
       "TCGA-24-1544       Sensitive    0.0         0.000033         0.002162   \n",
       "TCGA-25-2393       Resistant    1.0         0.000183         0.000385   \n",
       "TCGA-20-1682       Sensitive    0.0         0.000010         0.000217   \n",
       "TCGA-25-1626       Resistant    1.0         0.000124         0.000782   \n",
       "TCGA-23-1028       Resistant    1.0         0.000177         0.002233   \n",
       "TCGA-09-2056       Sensitive    0.0         0.000349         0.000404   \n",
       "TCGA-36-1568       Sensitive    0.0         0.000060         0.002655   \n",
       "TCGA-24-1563       Sensitive    0.0         0.000142         0.004161   \n",
       "TCGA-57-1586       Resistant    1.0         0.000721         0.015883   \n",
       "TCGA-61-1728       Sensitive    0.0         0.000241         0.001594   \n",
       "TCGA-13-0886       Sensitive    0.0         0.000116         0.000000   \n",
       "TCGA-24-2027       Sensitive    0.0         0.000169         0.000574   \n",
       "TCGA-24-1552       Resistant    1.0         0.000053         0.001173   \n",
       "TCGA-61-2113       Sensitive    0.0         0.000137         0.010557   \n",
       "TCGA-13-0887       Sensitive    0.0         0.000011         0.000000   \n",
       "TCGA-13-0901       Sensitive    0.0         0.000678         0.035130   \n",
       "TCGA-61-2000       Resistant    1.0         0.000119         0.015682   \n",
       "TCGA-13-0726       Sensitive    0.0         0.000042         0.001857   \n",
       "TCGA-13-0765       Sensitive    0.0         0.000076         0.003349   \n",
       "TCGA-29-1766       Sensitive    0.0         0.000112         1.000000   \n",
       "TCGA-13-0795       Resistant    1.0         0.000116         0.045838   \n",
       "TCGA-24-1930       Sensitive    0.0         0.000164         0.003900   \n",
       "TCGA-24-1923       Resistant    1.0         0.000476         0.006991   \n",
       "TCGA-30-1860       Sensitive    0.0         0.000074         0.000934   \n",
       "TCGA-24-0968       Sensitive    0.0         0.000205         0.003607   \n",
       "TCGA-31-1946       Sensitive    0.0         0.000371         0.002042   \n",
       "TCGA-04-1651       Sensitive    0.0         0.000315         0.008930   \n",
       "TCGA-13-0885       Sensitive    0.0         0.000056         0.055562   \n",
       "TCGA-29-1770       Sensitive    0.0         0.000388         0.009779   \n",
       "TCGA-25-1633       Sensitive    0.0         0.000051         0.000898   \n",
       "TCGA-36-1574       Sensitive    0.0         0.000383         0.000000   \n",
       "TCGA-23-1118       Sensitive    0.0         0.000172         0.002761   \n",
       "TCGA-23-1029       Sensitive    0.0         0.000771         0.016615   \n",
       "TCGA-61-2098       Sensitive    0.0         0.000309         0.154442   \n",
       "TCGA-29-2414       Sensitive    0.0         0.000351         0.005801   \n",
       "TCGA-61-1910       Sensitive    0.0         0.000395         0.012419   \n",
       "TCGA-04-1530       Sensitive    0.0         0.200155         0.000000   \n",
       "TCGA-24-1464       Resistant    1.0         0.000355         0.002932   \n",
       "TCGA-31-1951       Sensitive    0.0         0.000073         0.008563   \n",
       "TCGA-25-1328       Resistant    1.0         0.001108         0.008139   \n",
       "TCGA-24-1928       Resistant    1.0         0.001119         0.005800   \n",
       "TCGA-09-2051       Sensitive    0.0         0.000236         0.008907   \n",
       "\n",
       "              ENSG00000047936  ENSG00000186198  ENSG00000179914  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-24-1544         0.000018         0.000211         0.004113   \n",
       "TCGA-25-2393         0.000039         0.000338         0.001097   \n",
       "TCGA-20-1682         0.002671         0.000191         0.000443   \n",
       "TCGA-25-1626         0.000053         0.002981         0.000213   \n",
       "TCGA-23-1028         0.000086         0.001309         0.002579   \n",
       "TCGA-09-2056         0.000010         0.000296         0.000055   \n",
       "TCGA-36-1568         0.000317         0.003502         0.001443   \n",
       "TCGA-24-1563         0.000142         0.000305         0.000707   \n",
       "TCGA-57-1586         0.021943         0.015131         0.007014   \n",
       "TCGA-61-1728         0.000277         0.002804         0.000361   \n",
       "TCGA-13-0886         0.001048         0.001500         0.002433   \n",
       "TCGA-24-2027         0.000000         0.002775         0.000585   \n",
       "TCGA-24-1552         0.000055         0.000172         0.000000   \n",
       "TCGA-61-2113         0.000103         0.002652         0.000410   \n",
       "TCGA-13-0887         0.000028         0.000598         0.000170   \n",
       "TCGA-13-0901         0.000180         0.004119         0.013127   \n",
       "TCGA-61-2000         0.000045         0.005363         0.032674   \n",
       "TCGA-13-0726         0.000005         0.000272         0.000168   \n",
       "TCGA-13-0765         0.000000         0.000147         0.000000   \n",
       "TCGA-29-1766         0.003653         0.000310         0.002875   \n",
       "TCGA-13-0795         0.000006         0.000533         0.000395   \n",
       "TCGA-24-1930         0.001788         0.001143         0.000303   \n",
       "TCGA-24-1923         0.000955         0.014858         0.050349   \n",
       "TCGA-30-1860         0.001048         0.000411         0.013389   \n",
       "TCGA-24-0968         0.000339         0.000132         0.063953   \n",
       "TCGA-31-1946         0.000802         0.002394         0.003884   \n",
       "TCGA-04-1651         0.000064         0.000945         0.002629   \n",
       "TCGA-13-0885         0.000962         0.000000         0.001221   \n",
       "TCGA-29-1770         0.002817         0.003225         0.002658   \n",
       "TCGA-25-1633         0.000027         0.001250         0.297922   \n",
       "TCGA-36-1574         0.000082         0.001589         0.000000   \n",
       "TCGA-23-1118         0.000147         0.004552         0.000281   \n",
       "TCGA-23-1029         0.000561         0.001482         0.000736   \n",
       "TCGA-61-2098         0.000215         0.001345         0.001390   \n",
       "TCGA-29-2414         0.000149         0.004818         0.008670   \n",
       "TCGA-61-1910         0.001717         0.000728         0.000337   \n",
       "TCGA-04-1530         0.000705         0.001000         0.000742   \n",
       "TCGA-24-1464         0.000017         0.028075         0.000133   \n",
       "TCGA-31-1951         0.000987         0.001098         0.000727   \n",
       "TCGA-25-1328         0.000104         0.004772         0.000000   \n",
       "TCGA-24-1928         0.000520         0.005526         0.001182   \n",
       "TCGA-09-2051         0.000013         0.003264         0.001614   \n",
       "\n",
       "              ENSG00000186897  ENSG00000138136  ENSG00000139219  ...  \\\n",
       "PATIENT_ID                                                       ...   \n",
       "TCGA-24-1544         0.463682         0.000000         0.019233  ...   \n",
       "TCGA-25-2393         0.048461         0.000502         0.000829  ...   \n",
       "TCGA-20-1682         0.031677         0.000780         0.000089  ...   \n",
       "TCGA-25-1626         0.050532         0.000000         0.031889  ...   \n",
       "TCGA-23-1028         0.075687         0.000000         0.000622  ...   \n",
       "TCGA-09-2056         0.000099         0.000000         0.002284  ...   \n",
       "TCGA-36-1568         0.032611         0.001732         0.020821  ...   \n",
       "TCGA-24-1563         0.072323         0.001018         0.000735  ...   \n",
       "TCGA-57-1586         0.137535         0.000648         0.049734  ...   \n",
       "TCGA-61-1728         0.463339         0.000173         0.007447  ...   \n",
       "TCGA-13-0886         0.008169         0.000417         0.000523  ...   \n",
       "TCGA-24-2027         0.013494         0.015298         0.033416  ...   \n",
       "TCGA-24-1552         0.001585         0.000191         0.000065  ...   \n",
       "TCGA-61-2113         0.138558         0.004919         0.003812  ...   \n",
       "TCGA-13-0887         0.020691         0.000000         0.000338  ...   \n",
       "TCGA-13-0901         0.030636         0.000000         0.002024  ...   \n",
       "TCGA-61-2000         0.251694         0.028988         0.002137  ...   \n",
       "TCGA-13-0726         0.004106         0.000000         0.000161  ...   \n",
       "TCGA-13-0765         0.000165         0.000000         0.000100  ...   \n",
       "TCGA-29-1766         0.187622         0.000000         0.000052  ...   \n",
       "TCGA-13-0795         0.013763         0.000000         0.000189  ...   \n",
       "TCGA-24-1930         0.003832         0.000000         0.000186  ...   \n",
       "TCGA-24-1923         0.079004         0.001140         0.029882  ...   \n",
       "TCGA-30-1860         0.013881         0.000152         0.000104  ...   \n",
       "TCGA-24-0968         0.234121         0.082941         0.000704  ...   \n",
       "TCGA-31-1946         0.251260         0.013985         0.000304  ...   \n",
       "TCGA-04-1651         0.103842         0.073152         0.002453  ...   \n",
       "TCGA-13-0885         0.371642         0.000000         0.000015  ...   \n",
       "TCGA-29-1770         0.048647         0.000000         0.000500  ...   \n",
       "TCGA-25-1633         0.001213         0.000293         0.006325  ...   \n",
       "TCGA-36-1574         0.003256         0.000000         0.000179  ...   \n",
       "TCGA-23-1118         0.009664         0.000000         0.000051  ...   \n",
       "TCGA-23-1029         0.022183         0.000118         0.015210  ...   \n",
       "TCGA-61-2098         0.016812         0.000855         0.233778  ...   \n",
       "TCGA-29-2414         0.352454         0.000631         0.019763  ...   \n",
       "TCGA-61-1910         0.033558         0.000000         0.000185  ...   \n",
       "TCGA-04-1530         1.000000         0.000223         0.000735  ...   \n",
       "TCGA-24-1464         0.015365         0.003507         0.008972  ...   \n",
       "TCGA-31-1951         0.012095         0.000349         0.000438  ...   \n",
       "TCGA-25-1328         0.005998         0.000000         0.000908  ...   \n",
       "TCGA-24-1928         0.056282         0.000000         0.009162  ...   \n",
       "TCGA-09-2051         0.012764         1.000000         0.001655  ...   \n",
       "\n",
       "              ENSG00000272457  ENSG00000260426  ENSG00000250685  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-24-1544         0.443868         0.000000         0.001332   \n",
       "TCGA-25-2393         0.000000         0.000000         0.000000   \n",
       "TCGA-20-1682         0.088176         0.000000         0.003263   \n",
       "TCGA-25-1626         0.000000         0.034617         0.003581   \n",
       "TCGA-23-1028         0.082711         0.011095         0.000000   \n",
       "TCGA-09-2056         0.000000         0.000000         0.000000   \n",
       "TCGA-36-1568         0.000000         0.000000         0.004977   \n",
       "TCGA-24-1563         0.000000         0.000000         0.000000   \n",
       "TCGA-57-1586         0.000000         0.007292         0.001509   \n",
       "TCGA-61-1728         0.012769         0.027406         0.000000   \n",
       "TCGA-13-0886         0.000000         0.000000         0.000000   \n",
       "TCGA-24-2027         0.011121         0.000000         0.003704   \n",
       "TCGA-24-1552         0.000000         0.000000         0.000000   \n",
       "TCGA-61-2113         0.000000         0.000000         0.000000   \n",
       "TCGA-13-0887         0.032206         0.000000         0.000000   \n",
       "TCGA-13-0901         0.000000         0.014892         0.001541   \n",
       "TCGA-61-2000         0.000000         0.000000         0.000000   \n",
       "TCGA-13-0726         0.000000         0.000000         0.001091   \n",
       "TCGA-13-0765         0.000000         0.000000         0.000000   \n",
       "TCGA-29-1766         0.000000         0.000000         0.000000   \n",
       "TCGA-13-0795         0.012904         0.000000         0.000000   \n",
       "TCGA-24-1930         0.000000         0.000000         0.004440   \n",
       "TCGA-24-1923         0.000000         0.000000         0.000000   \n",
       "TCGA-30-1860         0.000000         0.000000         0.001391   \n",
       "TCGA-24-0968         0.000000         0.001702         0.001409   \n",
       "TCGA-31-1946         0.000000         0.000000         0.000000   \n",
       "TCGA-04-1651         0.007744         0.005194         0.000000   \n",
       "TCGA-13-0885         0.000000         0.000000         0.001393   \n",
       "TCGA-29-1770         0.000000         0.000000         0.004456   \n",
       "TCGA-25-1633         0.000000         0.000000         0.065815   \n",
       "TCGA-36-1574         0.000000         0.003346         0.000000   \n",
       "TCGA-23-1118         0.000000         0.000000         0.002377   \n",
       "TCGA-23-1029         0.003177         0.004261         0.000353   \n",
       "TCGA-61-2098         0.000000         0.009885         0.030677   \n",
       "TCGA-29-2414         0.049341         0.000000         0.038342   \n",
       "TCGA-61-1910         0.000000         0.000000         0.000000   \n",
       "TCGA-04-1530         0.101091         0.000000         0.000000   \n",
       "TCGA-24-1464         0.000000         0.000000         0.000000   \n",
       "TCGA-31-1951         0.000000         0.169450         0.000000   \n",
       "TCGA-25-1328         0.000000         0.065398         0.000000   \n",
       "TCGA-24-1928         0.000000         0.000000         0.000000   \n",
       "TCGA-09-2051         0.008926         0.000000         0.000000   \n",
       "\n",
       "              ENSG00000280916  ENSG00000255580  ENSG00000256904  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-24-1544         0.004201         0.000419         0.000000   \n",
       "TCGA-25-2393         0.000706         0.000000         0.000000   \n",
       "TCGA-20-1682         0.051462         0.001025         0.000000   \n",
       "TCGA-25-1626         0.016944         0.000000         0.000000   \n",
       "TCGA-23-1028         0.028963         0.001443         0.000000   \n",
       "TCGA-09-2056         0.000000         0.002707         0.000000   \n",
       "TCGA-36-1568         0.039247         0.003128         0.000000   \n",
       "TCGA-24-1563         0.008534         0.006802         0.000000   \n",
       "TCGA-57-1586         0.002380         0.000000         0.000000   \n",
       "TCGA-61-1728         0.017886         0.000000         0.000000   \n",
       "TCGA-13-0886         0.000077         0.000061         0.000000   \n",
       "TCGA-24-2027         0.046730         0.001552         0.000000   \n",
       "TCGA-24-1552         0.005673         0.001357         0.000000   \n",
       "TCGA-61-2113         0.084657         0.000000         0.000000   \n",
       "TCGA-13-0887         0.006579         0.002622         0.000000   \n",
       "TCGA-13-0901         0.001215         0.000484         0.285647   \n",
       "TCGA-61-2000         0.013722         0.001367         0.000000   \n",
       "TCGA-13-0726         0.000000         0.002400         0.000000   \n",
       "TCGA-13-0765         0.002849         0.000284         0.004527   \n",
       "TCGA-29-1766         0.001720         0.000000         0.000000   \n",
       "TCGA-13-0795         0.002259         0.000000         0.007179   \n",
       "TCGA-24-1930         0.007004         0.000000         0.000000   \n",
       "TCGA-24-1923         0.053361         0.000000         0.000000   \n",
       "TCGA-30-1860         0.070193         0.000437         0.000000   \n",
       "TCGA-24-0968         0.046097         0.000000         0.003529   \n",
       "TCGA-31-1946         0.000000         0.000000         0.000000   \n",
       "TCGA-04-1651         0.015254         0.000405         0.004308   \n",
       "TCGA-13-0885         0.001098         0.000875         0.000000   \n",
       "TCGA-29-1770         0.000000         0.000000         0.000000   \n",
       "TCGA-25-1633         0.012975         0.002069         0.000000   \n",
       "TCGA-36-1574         0.001092         0.005222         0.006938   \n",
       "TCGA-23-1118         0.001874         0.001494         0.000000   \n",
       "TCGA-23-1029         0.005284         0.000111         0.000000   \n",
       "TCGA-61-2098         0.013709         0.000000         0.000000   \n",
       "TCGA-29-2414         0.008639         0.000000         0.000000   \n",
       "TCGA-61-1910         0.008754         0.000000         0.018543   \n",
       "TCGA-04-1530         0.008850         0.010581         0.000000   \n",
       "TCGA-24-1464         0.001177         0.000939         0.007482   \n",
       "TCGA-31-1951         0.000000         0.004198         0.000000   \n",
       "TCGA-25-1328         0.021340         0.000000         0.067804   \n",
       "TCGA-24-1928         0.009560         0.001270         0.060749   \n",
       "TCGA-09-2051         0.071890         0.000623         0.000000   \n",
       "\n",
       "              ENSG00000232197  ENSG00000224957  ENSG00000259181  \\\n",
       "PATIENT_ID                                                        \n",
       "TCGA-24-1544         0.000000         0.000308         0.001876   \n",
       "TCGA-25-2393         0.000000         0.000026         0.002523   \n",
       "TCGA-20-1682         0.000000         0.000142         0.000000   \n",
       "TCGA-25-1626         0.184072         0.001348         0.000000   \n",
       "TCGA-23-1028         0.000000         0.000000         0.000000   \n",
       "TCGA-09-2056         0.000000         0.000000         0.000000   \n",
       "TCGA-36-1568         0.070571         0.000072         0.000000   \n",
       "TCGA-24-1563         0.000000         0.000392         0.000000   \n",
       "TCGA-57-1586         0.021394         0.000022         0.000000   \n",
       "TCGA-61-1728         1.000000         0.000000         0.000665   \n",
       "TCGA-13-0886         0.000000         0.000001         0.000000   \n",
       "TCGA-24-2027         0.109407         0.000018         0.000000   \n",
       "TCGA-24-1552         0.000000         0.001687         0.000675   \n",
       "TCGA-61-2113         0.000000         0.000222         0.003600   \n",
       "TCGA-13-0887         0.001056         0.000000         0.000000   \n",
       "TCGA-13-0901         0.000000         0.000045         0.000000   \n",
       "TCGA-61-2000         0.000000         0.000063         0.000000   \n",
       "TCGA-13-0726         0.000000         0.000047         0.002560   \n",
       "TCGA-13-0765         0.009607         0.000000         0.001696   \n",
       "TCGA-29-1766         0.000000         0.000047         0.000000   \n",
       "TCGA-13-0795         0.035548         0.000000         0.001345   \n",
       "TCGA-24-1930         0.000000         0.000064         0.008338   \n",
       "TCGA-24-1923         0.000000         0.000070         0.000000   \n",
       "TCGA-30-1860         0.014791         0.000020         0.000000   \n",
       "TCGA-24-0968         0.000000         0.000000         0.000000   \n",
       "TCGA-31-1946         0.000000         0.000000         0.001014   \n",
       "TCGA-04-1651         0.002286         0.000000         0.000000   \n",
       "TCGA-13-0885         0.000000         0.000040         0.000000   \n",
       "TCGA-29-1770         0.000000         0.000387         0.000000   \n",
       "TCGA-25-1633         0.064161         0.001096         0.000000   \n",
       "TCGA-36-1574         0.000000         0.000020         0.000650   \n",
       "TCGA-23-1118         0.000000         0.000000         0.001116   \n",
       "TCGA-23-1029         0.000625         0.000005         0.000000   \n",
       "TCGA-61-2098         0.038062         0.000030         0.000480   \n",
       "TCGA-29-2414         1.000000         0.000079         0.005143   \n",
       "TCGA-61-1910         0.000000         0.000000         0.006949   \n",
       "TCGA-04-1530         0.000000         0.000244         0.005268   \n",
       "TCGA-24-1464         0.000000         0.000000         0.000701   \n",
       "TCGA-31-1951         0.000000         0.000048         0.004702   \n",
       "TCGA-25-1328         0.000000         0.000000         0.120687   \n",
       "TCGA-24-1928         0.093112         0.000292         0.005691   \n",
       "TCGA-09-2051         0.005269         0.000043         0.000000   \n",
       "\n",
       "              ENSG00000229520  \n",
       "PATIENT_ID                     \n",
       "TCGA-24-1544         0.000000  \n",
       "TCGA-25-2393         0.000000  \n",
       "TCGA-20-1682         0.000000  \n",
       "TCGA-25-1626         0.000000  \n",
       "TCGA-23-1028         0.000000  \n",
       "TCGA-09-2056         0.000000  \n",
       "TCGA-36-1568         0.000000  \n",
       "TCGA-24-1563         0.000000  \n",
       "TCGA-57-1586         0.318849  \n",
       "TCGA-61-1728         0.000000  \n",
       "TCGA-13-0886         0.000000  \n",
       "TCGA-24-2027         0.091663  \n",
       "TCGA-24-1552         0.000000  \n",
       "TCGA-61-2113         0.350370  \n",
       "TCGA-13-0887         0.000000  \n",
       "TCGA-13-0901         0.000000  \n",
       "TCGA-61-2000         0.000000  \n",
       "TCGA-13-0726         0.000000  \n",
       "TCGA-13-0765         0.000000  \n",
       "TCGA-29-1766         0.000000  \n",
       "TCGA-13-0795         0.000000  \n",
       "TCGA-24-1930         0.000000  \n",
       "TCGA-24-1923         0.000000  \n",
       "TCGA-30-1860         0.000000  \n",
       "TCGA-24-0968         0.100563  \n",
       "TCGA-31-1946         0.000000  \n",
       "TCGA-04-1651         0.000000  \n",
       "TCGA-13-0885         0.000000  \n",
       "TCGA-29-1770         0.000000  \n",
       "TCGA-25-1633         0.000000  \n",
       "TCGA-36-1574         0.000000  \n",
       "TCGA-23-1118         0.000000  \n",
       "TCGA-23-1029         0.000000  \n",
       "TCGA-61-2098         0.000000  \n",
       "TCGA-29-2414         0.000000  \n",
       "TCGA-61-1910         0.000000  \n",
       "TCGA-04-1530         0.000000  \n",
       "TCGA-24-1464         0.000000  \n",
       "TCGA-31-1951         0.000000  \n",
       "TCGA-25-1328         0.000000  \n",
       "TCGA-24-1928         0.000000  \n",
       "TCGA-09-2051         0.000000  \n",
       "\n",
       "[42 rows x 502 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv(\"val_platin_total_lnc__100_500.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_platin_total_lnc__100_500.csv\")\n",
    "val = pd.read_csv(\"val_platin_total_lnc__100_500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of Training Data\n",
      "Samples : 168\n",
      "Features : 500\n"
     ]
    }
   ],
   "source": [
    "trn_X_pd = train.drop([\"PATIENT_ID\",\"PLATINUM_STATUS\",\"label\"],axis=1).values\n",
    "trn_y_pd = train.label.values\n",
    "\n",
    "print(\"Information of Training Data\")\n",
    "print(\"Samples : {}\".format(trn_X_pd.shape[0]))\n",
    "print(\"Features : {}\".format(trn_X_pd.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of Training Data\n",
      "Samples : 42\n",
      "Features : 500\n"
     ]
    }
   ],
   "source": [
    "val_X_pd = val.drop([\"PATIENT_ID\",\"PLATINUM_STATUS\",\"label\"],axis=1).values\n",
    "val_y_pd = val.label.values\n",
    "\n",
    "print(\"Information of Training Data\")\n",
    "print(\"Samples : {}\".format(val_X_pd.shape[0]))\n",
    "print(\"Features : {}\".format(val_X_pd.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "31\n",
      "50\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "item = []\n",
    "item_2 = []\n",
    "\n",
    "print( (val_y_pd == 1.0).sum())\n",
    "print( (val_y_pd == 0.0).sum())\n",
    "\n",
    "print( (trn_y_pd == 1.0).sum())\n",
    "print( (trn_y_pd == 0.0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([  1,   2,   3,   4,   5,   6,   7,   9,  11,  12,  13,  14,  16,\n",
       "          17,  18,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,\n",
       "          33,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,\n",
       "          47,  48,  49,  50,  54,  56,  57,  58,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  70,  73,  74,  75,  77,  78,  79,  80,  81,\n",
       "          82,  83,  84,  85,  90,  92,  93,  94,  95,  96,  97,  98, 100,\n",
       "         102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 124, 125, 127, 128, 129, 130, 131,\n",
       "         132, 133, 135, 136, 137, 138, 139, 140, 142, 143, 144, 146, 147,\n",
       "         148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161,\n",
       "         162, 164, 166, 167]),\n",
       "  array([  0,   8,  10,  15,  19,  31,  32,  34,  51,  52,  53,  55,  59,\n",
       "          69,  71,  72,  76,  86,  87,  88,  89,  91,  99, 101, 106, 108,\n",
       "         123, 126, 134, 141, 145, 153, 163, 165])),\n",
       " (array([  0,   1,   3,   5,   6,   8,   9,  10,  11,  12,  13,  14,  15,\n",
       "          16,  17,  18,  19,  20,  21,  23,  24,  25,  26,  27,  28,  29,\n",
       "          30,  31,  32,  34,  35,  36,  37,  38,  39,  41,  42,  45,  46,\n",
       "          47,  49,  51,  52,  53,  54,  55,  56,  57,  59,  60,  61,  62,\n",
       "          63,  65,  66,  68,  69,  71,  72,  73,  74,  75,  76,  77,  79,\n",
       "          80,  82,  83,  85,  86,  87,  88,  89,  90,  91,  92,  94,  95,\n",
       "          96,  98,  99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 111,\n",
       "         113, 116, 119, 120, 121, 122, 123, 126, 128, 129, 130, 131, 132,\n",
       "         133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
       "         146, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 160, 161,\n",
       "         163, 164, 165, 167]),\n",
       "  array([  2,   4,   7,  22,  33,  40,  43,  44,  48,  50,  58,  64,  67,\n",
       "          70,  78,  81,  84,  93,  97, 102, 110, 112, 114, 115, 117, 118,\n",
       "         124, 125, 127, 147, 151, 152, 162, 166])),\n",
       " (array([  0,   2,   3,   4,   6,   7,   8,  10,  11,  14,  15,  19,  20,\n",
       "          21,  22,  24,  25,  26,  27,  28,  29,  31,  32,  33,  34,  37,\n",
       "          40,  41,  43,  44,  46,  47,  48,  49,  50,  51,  52,  53,  55,\n",
       "          58,  59,  60,  61,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
       "          72,  73,  75,  76,  77,  78,  80,  81,  82,  83,  84,  85,  86,\n",
       "          87,  88,  89,  91,  92,  93,  96,  97,  98,  99, 100, 101, 102,\n",
       "         103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "         145, 146, 147, 148, 150, 151, 152, 153, 156, 158, 159, 161, 162,\n",
       "         163, 164, 165, 166]),\n",
       "  array([  1,   5,   9,  12,  13,  16,  17,  18,  23,  30,  35,  36,  38,\n",
       "          39,  42,  45,  54,  56,  57,  62,  74,  79,  90,  94,  95, 107,\n",
       "         131, 136, 149, 154, 155, 157, 160, 167])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  15,  16,  17,  18,  19,  21,  22,  23,  26,  27,  29,  30,\n",
       "          31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  42,  43,  44,\n",
       "          45,  46,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
       "          59,  60,  62,  63,  64,  65,  66,  67,  69,  70,  71,  72,  73,\n",
       "          74,  75,  76,  78,  79,  81,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  97,  99, 101, 102, 106, 107, 108, 110,\n",
       "         112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125,\n",
       "         126, 127, 128, 130, 131, 134, 136, 137, 138, 141, 143, 145, 147,\n",
       "         148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n",
       "         162, 163, 165, 166, 167]),\n",
       "  array([ 14,  20,  24,  25,  28,  41,  47,  61,  68,  77,  80,  82,  83,\n",
       "          96,  98, 100, 103, 104, 105, 109, 111, 121, 129, 132, 133, 135,\n",
       "         139, 140, 142, 144, 146, 161, 164])),\n",
       " (array([  0,   1,   2,   4,   5,   7,   8,   9,  10,  12,  13,  14,  15,\n",
       "          16,  17,  18,  19,  20,  22,  23,  24,  25,  28,  30,  31,  32,\n",
       "          33,  34,  35,  36,  38,  39,  40,  41,  42,  43,  44,  45,  47,\n",
       "          48,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  61,  62,\n",
       "          64,  67,  68,  69,  70,  71,  72,  74,  76,  77,  78,  79,  80,\n",
       "          81,  82,  83,  84,  86,  87,  88,  89,  90,  91,  93,  94,  95,\n",
       "          96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
       "         109, 110, 111, 112, 114, 115, 117, 118, 121, 123, 124, 125, 126,\n",
       "         127, 129, 131, 132, 133, 134, 135, 136, 139, 140, 141, 142, 144,\n",
       "         145, 146, 147, 149, 151, 152, 153, 154, 155, 157, 160, 161, 162,\n",
       "         163, 164, 165, 166, 167]),\n",
       "  array([  3,   6,  11,  21,  26,  27,  29,  37,  46,  49,  60,  63,  65,\n",
       "          66,  73,  75,  85,  92, 113, 116, 119, 120, 122, 128, 130, 137,\n",
       "         138, 143, 148, 150, 156, 158, 159]))]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 5 # Number of K-fold Splits\n",
    "\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True).split(trn_X_pd, trn_y_pd))\n",
    "splits[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "24\n",
      "10\n",
      "24\n",
      "10\n",
      "24\n",
      "10\n",
      "23\n",
      "10\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "\n",
    "    print( (trn_y_pd[valid_idx.astype(int)] == 1.0).sum())\n",
    "    print( (trn_y_pd[valid_idx.astype(int)] == 0.0).sum())\n",
    "    \n",
    "    #print( (trn_y_pd[train_idx.astype(int)] == 1.0).sum())\n",
    "    #print( (trn_y_pd[train_idx.astype(int)] == 0.0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dictionary batch\n",
    "class Dataset(data_utils.Dataset):\n",
    "   \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        return {'X': self.X[idx], 'y': self.y[idx]}\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_seq_1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_1, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 150, bias=True),\n",
    "            torch.nn.BatchNorm1d(150),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "        )\n",
    "        self.classifier2 = nn.Sequential(\n",
    "\n",
    "            torch.nn.Linear(150, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            \n",
    "\n",
    "            #torch.nn.Dropout(0.3)\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(250,1, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[150,200,100,50]\n",
    "#[150,200,100,50,20]\n",
    "\n",
    "class DNN_seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 200, bias=True),\n",
    "            torch.nn.BatchNorm1d(200),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        \n",
    "        self.classifier2 = nn.Sequential(    \n",
    "            torch.nn.Linear(200, 300, bias=True),\n",
    "            torch.nn.BatchNorm1d(300),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier3 = nn.Sequential(  \n",
    "            torch.nn.Linear(300, 300, bias=True),\n",
    "            torch.nn.BatchNorm1d(300),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            torch.nn.Linear(300, 300, bias=True),\n",
    "            torch.nn.BatchNorm1d(300),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(300, 1, bias=True),\n",
    "            #nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.classifier3(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[150,200,100,50]\n",
    "#[150,200,100,50,20]\n",
    "\n",
    "class DNN_seq_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_2, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 150, bias=True),\n",
    "            torch.nn.BatchNorm1d(150),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "        \n",
    "        self.classifier2 = nn.Sequential(    \n",
    "            torch.nn.Linear(150, 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier3 = nn.Sequential(  \n",
    "            torch.nn.Linear(100, 150, bias=True),\n",
    "            torch.nn.BatchNorm1d(150),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            torch.nn.Linear(150, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(250, 1, bias=True),\n",
    "            torch.nn.BatchNorm1d(1)\n",
    "            #nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.classifier3(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN_seq_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(object):\n",
    "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
    "                 step_size=2000, mode='triangular', gamma=1.,\n",
    "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
    "\n",
    "        if not isinstance(optimizer, Optimizer):\n",
    "            raise TypeError('{} is not an Optimizer'.format(\n",
    "                type(optimizer).__name__))\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
    "            if len(base_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(base_lr)))\n",
    "            self.base_lrs = list(base_lr)\n",
    "        else:\n",
    "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
    "            if len(max_lr) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
    "                    len(optimizer.param_groups), len(max_lr)))\n",
    "            self.max_lrs = list(max_lr)\n",
    "        else:\n",
    "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
    "\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
    "                and scale_fn is None:\n",
    "            raise ValueError('mode is invalid and scale_fn is None')\n",
    "\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "\n",
    "        if scale_fn is None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = self._triangular_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = self._triangular2_scale_fn\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = self._exp_range_scale_fn\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "\n",
    "        self.batch_step(last_batch_iteration + 1)\n",
    "        self.last_batch_iteration = last_batch_iteration\n",
    "\n",
    "    def batch_step(self, batch_iteration=None):\n",
    "        if batch_iteration is None:\n",
    "            batch_iteration = self.last_batch_iteration + 1\n",
    "        self.last_batch_iteration = batch_iteration\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def _triangular_scale_fn(self, x):\n",
    "        return 1.\n",
    "\n",
    "    def _triangular2_scale_fn(self, x):\n",
    "        return 1 / (2. ** (x - 1))\n",
    "\n",
    "    def _exp_range_scale_fn(self, x):\n",
    "        return self.gamma**(x)\n",
    "\n",
    "    def get_lr(self):\n",
    "        step_size = float(self.step_size)\n",
    "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
    "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
    "\n",
    "        lrs = []\n",
    "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
    "        for param_group, base_lr, max_lr in param_lrs:\n",
    "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
    "            if self.scale_mode == 'cycle':\n",
    "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
    "            else:\n",
    "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
    "            lrs.append(lr)\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "import time # ??\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "print(trn_X_pd.shape[0])\n",
    "          \n",
    "train_preds = np.zeros(trn_X_pd.shape[0])\n",
    "\n",
    "## Addiction\n",
    "train_y_sort = np.zeros(trn_X_pd.shape[0])\n",
    "\n",
    "test_preds = np.zeros(val_X_pd.shape[0])\n",
    "\n",
    "\n",
    "train_target = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Fold 1\n",
      "Epoch 1/50 \t loss=0.6902 \t val_loss=0.6334 \t time=0.15s\n",
      "Epoch 2/50 \t loss=0.5012 \t val_loss=0.5276 \t time=0.14s\n",
      "Epoch 3/50 \t loss=0.4540 \t val_loss=0.4702 \t time=0.12s\n",
      "Epoch 4/50 \t loss=0.3691 \t val_loss=0.4792 \t time=0.14s\n",
      "Epoch 5/50 \t loss=0.3000 \t val_loss=0.5257 \t time=0.13s\n",
      "Epoch 6/50 \t loss=0.2823 \t val_loss=0.5139 \t time=0.14s\n",
      "Epoch 7/50 \t loss=0.2368 \t val_loss=0.5746 \t time=0.16s\n",
      "Epoch 8/50 \t loss=0.2792 \t val_loss=0.5287 \t time=0.19s\n",
      "Epoch 9/50 \t loss=0.1583 \t val_loss=0.5479 \t time=0.14s\n",
      "Epoch 10/50 \t loss=0.3958 \t val_loss=0.6679 \t time=0.15s\n",
      "Epoch 11/50 \t loss=0.2241 \t val_loss=0.6661 \t time=0.13s\n",
      "Epoch 12/50 \t loss=0.2229 \t val_loss=0.8455 \t time=0.14s\n",
      "Epoch 13/50 \t loss=0.2604 \t val_loss=0.5137 \t time=0.13s\n",
      "Epoch 14/50 \t loss=0.1821 \t val_loss=0.6715 \t time=0.15s\n",
      "Epoch 15/50 \t loss=0.1699 \t val_loss=0.6508 \t time=0.13s\n",
      "Epoch 16/50 \t loss=0.1984 \t val_loss=0.6658 \t time=0.14s\n",
      "Epoch 17/50 \t loss=0.4151 \t val_loss=0.6938 \t time=0.13s\n",
      "Epoch 18/50 \t loss=0.2658 \t val_loss=0.7174 \t time=0.14s\n",
      "Epoch 19/50 \t loss=0.2077 \t val_loss=0.5750 \t time=0.13s\n",
      "Epoch 20/50 \t loss=0.1212 \t val_loss=0.7892 \t time=0.18s\n",
      "Epoch 21/50 \t loss=0.3584 \t val_loss=0.5335 \t time=0.14s\n",
      "Epoch 22/50 \t loss=0.3426 \t val_loss=0.5584 \t time=0.14s\n",
      "Epoch 23/50 \t loss=0.2078 \t val_loss=0.5152 \t time=0.13s\n",
      "Epoch 24/50 \t loss=0.1561 \t val_loss=0.7466 \t time=0.14s\n",
      "Epoch 25/50 \t loss=0.1734 \t val_loss=0.6148 \t time=0.13s\n",
      "Epoch 26/50 \t loss=0.1948 \t val_loss=0.7204 \t time=0.14s\n",
      "Epoch 27/50 \t loss=0.1698 \t val_loss=0.6840 \t time=0.13s\n",
      "Epoch 28/50 \t loss=0.1852 \t val_loss=0.6152 \t time=0.14s\n",
      "Epoch 29/50 \t loss=0.1032 \t val_loss=0.5885 \t time=0.13s\n",
      "Epoch 30/50 \t loss=0.0921 \t val_loss=0.7055 \t time=0.14s\n",
      "Epoch 31/50 \t loss=0.0850 \t val_loss=0.5530 \t time=0.13s\n",
      "Epoch 32/50 \t loss=0.1038 \t val_loss=0.7893 \t time=0.14s\n",
      "Epoch 33/50 \t loss=0.2251 \t val_loss=0.7670 \t time=0.13s\n",
      "Epoch 34/50 \t loss=0.1658 \t val_loss=0.6476 \t time=0.14s\n",
      "Epoch 35/50 \t loss=0.1798 \t val_loss=0.4604 \t time=0.13s\n",
      "Epoch 36/50 \t loss=0.1540 \t val_loss=0.7226 \t time=0.14s\n",
      "Epoch 37/50 \t loss=0.1781 \t val_loss=0.5310 \t time=0.13s\n",
      "Epoch 38/50 \t loss=0.1360 \t val_loss=0.8066 \t time=0.14s\n",
      "Epoch 39/50 \t loss=0.1085 \t val_loss=0.8758 \t time=0.14s\n",
      "Epoch 40/50 \t loss=0.1084 \t val_loss=0.7980 \t time=0.14s\n",
      "Epoch 41/50 \t loss=0.0887 \t val_loss=0.8706 \t time=0.14s\n",
      "Epoch 42/50 \t loss=0.1525 \t val_loss=1.0130 \t time=0.14s\n",
      "Epoch 43/50 \t loss=0.1002 \t val_loss=0.9280 \t time=0.13s\n",
      "Epoch 44/50 \t loss=0.1977 \t val_loss=0.8659 \t time=0.14s\n",
      "Epoch 45/50 \t loss=0.2882 \t val_loss=0.7846 \t time=0.14s\n",
      "Epoch 46/50 \t loss=0.1576 \t val_loss=0.7019 \t time=0.14s\n",
      "Epoch 47/50 \t loss=0.1806 \t val_loss=0.6174 \t time=0.13s\n",
      "Epoch 48/50 \t loss=0.1911 \t val_loss=0.7629 \t time=0.14s\n",
      "Epoch 49/50 \t loss=0.1167 \t val_loss=0.7383 \t time=0.17s\n",
      "Epoch 50/50 \t loss=0.2677 \t val_loss=0.8571 \t time=0.17s\n",
      "[1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 1. 1. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "1\n",
      "Fold 2\n",
      "Epoch 1/50 \t loss=0.6229 \t val_loss=0.6143 \t time=0.15s\n",
      "Epoch 2/50 \t loss=0.5056 \t val_loss=0.6124 \t time=0.17s\n",
      "Epoch 3/50 \t loss=0.4243 \t val_loss=0.6381 \t time=0.15s\n",
      "Epoch 4/50 \t loss=0.3139 \t val_loss=0.6098 \t time=0.18s\n",
      "Epoch 5/50 \t loss=0.2674 \t val_loss=0.6079 \t time=0.16s\n",
      "Epoch 6/50 \t loss=0.2813 \t val_loss=0.6671 \t time=0.17s\n",
      "Epoch 7/50 \t loss=0.2988 \t val_loss=0.6908 \t time=0.17s\n",
      "Epoch 8/50 \t loss=0.2132 \t val_loss=0.8506 \t time=0.17s\n",
      "Epoch 9/50 \t loss=0.1932 \t val_loss=0.5403 \t time=0.17s\n",
      "Epoch 10/50 \t loss=0.1382 \t val_loss=0.7274 \t time=0.14s\n",
      "Epoch 11/50 \t loss=0.1467 \t val_loss=0.8055 \t time=0.13s\n",
      "Epoch 12/50 \t loss=0.1553 \t val_loss=0.8226 \t time=0.14s\n",
      "Epoch 13/50 \t loss=0.1562 \t val_loss=0.8226 \t time=0.13s\n",
      "Epoch 14/50 \t loss=0.2529 \t val_loss=0.7089 \t time=0.14s\n",
      "Epoch 15/50 \t loss=0.1291 \t val_loss=0.6792 \t time=0.13s\n",
      "Epoch 16/50 \t loss=0.1212 \t val_loss=0.7872 \t time=0.14s\n",
      "Epoch 17/50 \t loss=0.1263 \t val_loss=1.1679 \t time=0.13s\n",
      "Epoch 18/50 \t loss=0.3339 \t val_loss=0.9138 \t time=0.14s\n",
      "Epoch 19/50 \t loss=0.1502 \t val_loss=0.7521 \t time=0.13s\n",
      "Epoch 20/50 \t loss=0.2450 \t val_loss=0.7547 \t time=0.14s\n",
      "Epoch 21/50 \t loss=0.0935 \t val_loss=0.7361 \t time=0.13s\n",
      "Epoch 22/50 \t loss=0.1600 \t val_loss=0.7820 \t time=0.14s\n",
      "Epoch 23/50 \t loss=0.0927 \t val_loss=0.8607 \t time=0.13s\n",
      "Epoch 24/50 \t loss=0.2061 \t val_loss=0.9380 \t time=0.13s\n",
      "Epoch 25/50 \t loss=0.1227 \t val_loss=1.0222 \t time=0.13s\n",
      "Epoch 26/50 \t loss=0.1344 \t val_loss=0.9571 \t time=0.13s\n",
      "Epoch 27/50 \t loss=0.1490 \t val_loss=1.1718 \t time=0.13s\n",
      "Epoch 28/50 \t loss=0.1284 \t val_loss=0.9599 \t time=0.14s\n",
      "Epoch 29/50 \t loss=0.1108 \t val_loss=1.0609 \t time=0.13s\n",
      "Epoch 30/50 \t loss=0.1808 \t val_loss=1.3154 \t time=0.14s\n",
      "Epoch 31/50 \t loss=0.1920 \t val_loss=1.1842 \t time=0.13s\n",
      "Epoch 32/50 \t loss=0.1426 \t val_loss=1.0159 \t time=0.15s\n",
      "Epoch 33/50 \t loss=0.2247 \t val_loss=1.0053 \t time=0.15s\n",
      "Epoch 34/50 \t loss=0.1772 \t val_loss=0.9756 \t time=0.18s\n",
      "Epoch 35/50 \t loss=0.1628 \t val_loss=0.9725 \t time=0.18s\n",
      "Epoch 36/50 \t loss=0.1263 \t val_loss=1.0144 \t time=0.16s\n",
      "Epoch 37/50 \t loss=0.1127 \t val_loss=0.8464 \t time=0.14s\n",
      "Epoch 38/50 \t loss=0.2616 \t val_loss=0.8790 \t time=0.14s\n",
      "Epoch 39/50 \t loss=0.1642 \t val_loss=0.8358 \t time=0.14s\n",
      "Epoch 40/50 \t loss=0.1009 \t val_loss=1.0006 \t time=0.14s\n",
      "Epoch 41/50 \t loss=0.1443 \t val_loss=1.0473 \t time=0.14s\n",
      "Epoch 42/50 \t loss=0.1043 \t val_loss=1.0248 \t time=0.14s\n",
      "Epoch 43/50 \t loss=0.1992 \t val_loss=1.3359 \t time=0.13s\n",
      "Epoch 44/50 \t loss=0.2114 \t val_loss=1.2596 \t time=0.14s\n",
      "Epoch 45/50 \t loss=0.0892 \t val_loss=1.2675 \t time=0.13s\n",
      "Epoch 46/50 \t loss=0.0787 \t val_loss=1.1464 \t time=0.16s\n",
      "Epoch 47/50 \t loss=0.0630 \t val_loss=1.3695 \t time=0.16s\n",
      "Epoch 48/50 \t loss=0.4468 \t val_loss=1.3831 \t time=0.14s\n",
      "Epoch 49/50 \t loss=0.1456 \t val_loss=0.9048 \t time=0.14s\n",
      "Epoch 50/50 \t loss=0.2366 \t val_loss=0.8968 \t time=0.15s\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "2\n",
      "Fold 3\n",
      "Epoch 1/50 \t loss=0.6792 \t val_loss=0.6146 \t time=0.15s\n",
      "Epoch 2/50 \t loss=0.4846 \t val_loss=0.5848 \t time=0.16s\n",
      "Epoch 3/50 \t loss=0.4594 \t val_loss=0.4985 \t time=0.14s\n",
      "Epoch 4/50 \t loss=0.3510 \t val_loss=0.5365 \t time=0.15s\n",
      "Epoch 5/50 \t loss=0.3189 \t val_loss=0.5136 \t time=0.14s\n",
      "Epoch 6/50 \t loss=0.2589 \t val_loss=0.4532 \t time=0.14s\n",
      "Epoch 7/50 \t loss=0.2205 \t val_loss=0.4635 \t time=0.14s\n",
      "Epoch 8/50 \t loss=0.1946 \t val_loss=0.5376 \t time=0.18s\n",
      "Epoch 9/50 \t loss=0.1771 \t val_loss=0.5198 \t time=0.16s\n",
      "Epoch 10/50 \t loss=0.2347 \t val_loss=0.5324 \t time=0.14s\n",
      "Epoch 11/50 \t loss=0.2386 \t val_loss=0.5633 \t time=0.14s\n",
      "Epoch 12/50 \t loss=0.2042 \t val_loss=0.5995 \t time=0.15s\n",
      "Epoch 13/50 \t loss=0.4358 \t val_loss=0.5698 \t time=0.16s\n",
      "Epoch 14/50 \t loss=0.2353 \t val_loss=0.5695 \t time=0.18s\n",
      "Epoch 15/50 \t loss=0.2290 \t val_loss=0.4039 \t time=0.16s\n",
      "Epoch 16/50 \t loss=0.1583 \t val_loss=0.4585 \t time=0.14s\n",
      "Epoch 17/50 \t loss=0.2253 \t val_loss=0.4631 \t time=0.13s\n",
      "Epoch 18/50 \t loss=0.1400 \t val_loss=0.4844 \t time=0.14s\n",
      "Epoch 19/50 \t loss=0.2360 \t val_loss=0.5464 \t time=0.13s\n",
      "Epoch 20/50 \t loss=0.1926 \t val_loss=0.4891 \t time=0.14s\n",
      "Epoch 21/50 \t loss=0.1698 \t val_loss=0.4878 \t time=0.14s\n",
      "Epoch 22/50 \t loss=0.3305 \t val_loss=0.6202 \t time=0.14s\n",
      "Epoch 23/50 \t loss=0.2091 \t val_loss=0.5793 \t time=0.13s\n",
      "Epoch 24/50 \t loss=0.1346 \t val_loss=0.4830 \t time=0.14s\n",
      "Epoch 25/50 \t loss=0.2016 \t val_loss=0.6910 \t time=0.15s\n",
      "Epoch 26/50 \t loss=0.3768 \t val_loss=0.4757 \t time=0.16s\n",
      "Epoch 27/50 \t loss=0.3357 \t val_loss=0.5672 \t time=0.13s\n",
      "Epoch 28/50 \t loss=0.2505 \t val_loss=0.5479 \t time=0.14s\n",
      "Epoch 29/50 \t loss=0.2052 \t val_loss=0.5316 \t time=0.19s\n",
      "Epoch 30/50 \t loss=0.2535 \t val_loss=0.4581 \t time=0.18s\n",
      "Epoch 31/50 \t loss=0.1338 \t val_loss=0.4753 \t time=0.16s\n",
      "Epoch 32/50 \t loss=0.3221 \t val_loss=0.5989 \t time=0.18s\n",
      "Epoch 33/50 \t loss=0.1896 \t val_loss=0.4987 \t time=0.16s\n",
      "Epoch 34/50 \t loss=0.1892 \t val_loss=0.5150 \t time=0.18s\n",
      "Epoch 35/50 \t loss=0.2471 \t val_loss=0.4862 \t time=0.18s\n",
      "Epoch 36/50 \t loss=0.4020 \t val_loss=0.4204 \t time=0.19s\n",
      "Epoch 37/50 \t loss=0.1758 \t val_loss=0.4608 \t time=0.16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 \t loss=0.2121 \t val_loss=0.5049 \t time=0.19s\n",
      "Epoch 39/50 \t loss=0.1433 \t val_loss=0.4677 \t time=0.16s\n",
      "Epoch 40/50 \t loss=0.2091 \t val_loss=0.4727 \t time=0.14s\n",
      "Epoch 41/50 \t loss=0.0965 \t val_loss=0.4783 \t time=0.18s\n",
      "Epoch 42/50 \t loss=0.1587 \t val_loss=0.4584 \t time=0.16s\n",
      "Epoch 43/50 \t loss=0.1317 \t val_loss=0.6091 \t time=0.17s\n",
      "Epoch 44/50 \t loss=0.0917 \t val_loss=0.6283 \t time=0.17s\n",
      "Epoch 45/50 \t loss=0.1408 \t val_loss=0.5803 \t time=0.14s\n",
      "Epoch 46/50 \t loss=0.1100 \t val_loss=0.4278 \t time=0.13s\n",
      "Epoch 47/50 \t loss=0.0884 \t val_loss=0.4222 \t time=0.13s\n",
      "Epoch 48/50 \t loss=0.2699 \t val_loss=0.4546 \t time=0.14s\n",
      "Epoch 49/50 \t loss=0.2752 \t val_loss=0.5117 \t time=0.13s\n",
      "Epoch 50/50 \t loss=0.1949 \t val_loss=0.4173 \t time=0.13s\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "3\n",
      "Fold 4\n",
      "Epoch 1/50 \t loss=0.6307 \t val_loss=0.6304 \t time=0.17s\n",
      "Epoch 2/50 \t loss=0.5132 \t val_loss=0.5739 \t time=0.16s\n",
      "Epoch 3/50 \t loss=0.4002 \t val_loss=0.5603 \t time=0.16s\n",
      "Epoch 4/50 \t loss=0.3505 \t val_loss=0.6166 \t time=0.16s\n",
      "Epoch 5/50 \t loss=0.3690 \t val_loss=0.6034 \t time=0.17s\n",
      "Epoch 6/50 \t loss=0.3188 \t val_loss=0.6019 \t time=0.18s\n",
      "Epoch 7/50 \t loss=0.3073 \t val_loss=0.6633 \t time=0.16s\n",
      "Epoch 8/50 \t loss=0.2492 \t val_loss=0.5988 \t time=0.14s\n",
      "Epoch 9/50 \t loss=0.1710 \t val_loss=0.6482 \t time=0.16s\n",
      "Epoch 10/50 \t loss=0.3215 \t val_loss=0.8082 \t time=0.17s\n",
      "Epoch 11/50 \t loss=0.2031 \t val_loss=0.7267 \t time=0.13s\n",
      "Epoch 12/50 \t loss=0.1918 \t val_loss=0.8504 \t time=0.13s\n",
      "Epoch 13/50 \t loss=0.2094 \t val_loss=0.6827 \t time=0.14s\n",
      "Epoch 14/50 \t loss=0.2611 \t val_loss=0.9097 \t time=0.13s\n",
      "Epoch 15/50 \t loss=0.1966 \t val_loss=0.7703 \t time=0.13s\n",
      "Epoch 16/50 \t loss=0.1693 \t val_loss=0.7110 \t time=0.18s\n",
      "Epoch 17/50 \t loss=0.1613 \t val_loss=0.7907 \t time=0.18s\n",
      "Epoch 18/50 \t loss=0.1305 \t val_loss=0.7832 \t time=0.15s\n",
      "Epoch 19/50 \t loss=0.1687 \t val_loss=0.8877 \t time=0.14s\n",
      "Epoch 20/50 \t loss=0.1952 \t val_loss=0.9371 \t time=0.14s\n",
      "Epoch 21/50 \t loss=0.1592 \t val_loss=0.8541 \t time=0.13s\n",
      "Epoch 22/50 \t loss=0.2562 \t val_loss=0.7194 \t time=0.14s\n",
      "Epoch 23/50 \t loss=0.2256 \t val_loss=0.7822 \t time=0.17s\n",
      "Epoch 24/50 \t loss=0.1448 \t val_loss=0.7168 \t time=0.16s\n",
      "Epoch 25/50 \t loss=0.1972 \t val_loss=0.7371 \t time=0.13s\n",
      "Epoch 26/50 \t loss=0.1726 \t val_loss=0.9379 \t time=0.17s\n",
      "Epoch 27/50 \t loss=0.2161 \t val_loss=0.7879 \t time=0.19s\n",
      "Epoch 28/50 \t loss=0.0944 \t val_loss=0.9667 \t time=0.18s\n",
      "Epoch 29/50 \t loss=0.2550 \t val_loss=1.0606 \t time=0.17s\n",
      "Epoch 30/50 \t loss=0.1967 \t val_loss=0.7529 \t time=0.19s\n",
      "Epoch 31/50 \t loss=0.1041 \t val_loss=0.7516 \t time=0.16s\n",
      "Epoch 32/50 \t loss=0.1094 \t val_loss=0.8963 \t time=0.19s\n",
      "Epoch 33/50 \t loss=0.1431 \t val_loss=1.2533 \t time=0.16s\n",
      "Epoch 34/50 \t loss=0.1128 \t val_loss=1.1302 \t time=0.14s\n",
      "Epoch 35/50 \t loss=0.0813 \t val_loss=0.8587 \t time=0.17s\n",
      "Epoch 36/50 \t loss=0.1950 \t val_loss=0.7770 \t time=0.19s\n",
      "Epoch 37/50 \t loss=0.1657 \t val_loss=0.9406 \t time=0.16s\n",
      "Epoch 38/50 \t loss=0.1265 \t val_loss=0.8895 \t time=0.20s\n",
      "Epoch 39/50 \t loss=0.0717 \t val_loss=1.0908 \t time=0.15s\n",
      "Epoch 40/50 \t loss=0.1723 \t val_loss=1.1987 \t time=0.17s\n",
      "Epoch 41/50 \t loss=0.2049 \t val_loss=1.5305 \t time=0.17s\n",
      "Epoch 42/50 \t loss=0.1078 \t val_loss=1.2947 \t time=0.16s\n",
      "Epoch 43/50 \t loss=0.4072 \t val_loss=1.3132 \t time=0.18s\n",
      "Epoch 44/50 \t loss=0.1243 \t val_loss=0.9053 \t time=0.14s\n",
      "Epoch 45/50 \t loss=0.1077 \t val_loss=1.1020 \t time=0.13s\n",
      "Epoch 46/50 \t loss=0.2863 \t val_loss=0.9250 \t time=0.13s\n",
      "Epoch 47/50 \t loss=0.1367 \t val_loss=1.0177 \t time=0.13s\n",
      "Epoch 48/50 \t loss=0.2813 \t val_loss=0.9904 \t time=0.14s\n",
      "Epoch 49/50 \t loss=0.1231 \t val_loss=1.0553 \t time=0.14s\n",
      "Epoch 50/50 \t loss=0.1730 \t val_loss=1.1856 \t time=0.15s\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 0. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "4\n",
      "Fold 5\n",
      "Epoch 1/50 \t loss=0.6653 \t val_loss=0.6098 \t time=0.14s\n",
      "Epoch 2/50 \t loss=0.5392 \t val_loss=0.5330 \t time=0.14s\n",
      "Epoch 3/50 \t loss=0.4372 \t val_loss=0.5029 \t time=0.14s\n",
      "Epoch 4/50 \t loss=0.3359 \t val_loss=0.5340 \t time=0.14s\n",
      "Epoch 5/50 \t loss=0.3091 \t val_loss=0.4858 \t time=0.14s\n",
      "Epoch 6/50 \t loss=0.3083 \t val_loss=0.4419 \t time=0.18s\n",
      "Epoch 7/50 \t loss=0.2669 \t val_loss=0.5124 \t time=0.17s\n",
      "Epoch 8/50 \t loss=0.3180 \t val_loss=0.4544 \t time=0.15s\n",
      "Epoch 9/50 \t loss=0.2134 \t val_loss=0.4531 \t time=0.17s\n",
      "Epoch 10/50 \t loss=0.2086 \t val_loss=0.4176 \t time=0.19s\n",
      "Epoch 11/50 \t loss=0.1931 \t val_loss=0.4564 \t time=0.15s\n",
      "Epoch 12/50 \t loss=0.2203 \t val_loss=0.5992 \t time=0.15s\n",
      "Epoch 13/50 \t loss=0.3127 \t val_loss=0.4677 \t time=0.14s\n",
      "Epoch 14/50 \t loss=0.2222 \t val_loss=0.5033 \t time=0.15s\n",
      "Epoch 15/50 \t loss=0.2196 \t val_loss=0.4620 \t time=0.13s\n",
      "Epoch 16/50 \t loss=0.2757 \t val_loss=0.6161 \t time=0.15s\n",
      "Epoch 17/50 \t loss=0.1398 \t val_loss=0.4787 \t time=0.13s\n",
      "Epoch 18/50 \t loss=0.1212 \t val_loss=0.4596 \t time=0.14s\n",
      "Epoch 19/50 \t loss=0.2012 \t val_loss=0.4550 \t time=0.13s\n",
      "Epoch 20/50 \t loss=0.2631 \t val_loss=0.5844 \t time=0.14s\n",
      "Epoch 21/50 \t loss=0.1683 \t val_loss=0.6414 \t time=0.13s\n",
      "Epoch 22/50 \t loss=0.1180 \t val_loss=0.6474 \t time=0.18s\n",
      "Epoch 23/50 \t loss=0.2378 \t val_loss=0.5104 \t time=0.18s\n",
      "Epoch 24/50 \t loss=0.1308 \t val_loss=0.5711 \t time=0.19s\n",
      "Epoch 25/50 \t loss=0.1829 \t val_loss=0.5378 \t time=0.17s\n",
      "Epoch 26/50 \t loss=0.0558 \t val_loss=0.4747 \t time=0.15s\n",
      "Epoch 27/50 \t loss=0.1956 \t val_loss=0.5290 \t time=0.16s\n",
      "Epoch 28/50 \t loss=0.1251 \t val_loss=0.4338 \t time=0.16s\n",
      "Epoch 29/50 \t loss=0.2704 \t val_loss=0.5128 \t time=0.18s\n",
      "Epoch 30/50 \t loss=0.1681 \t val_loss=0.4027 \t time=0.16s\n",
      "Epoch 31/50 \t loss=0.1063 \t val_loss=0.6926 \t time=0.16s\n",
      "Epoch 32/50 \t loss=0.1169 \t val_loss=0.5258 \t time=0.16s\n",
      "Epoch 33/50 \t loss=0.0690 \t val_loss=0.4741 \t time=0.15s\n",
      "Epoch 34/50 \t loss=0.1682 \t val_loss=0.5674 \t time=0.15s\n",
      "Epoch 35/50 \t loss=0.1046 \t val_loss=0.6070 \t time=0.13s\n",
      "Epoch 36/50 \t loss=0.1780 \t val_loss=0.5860 \t time=0.14s\n",
      "Epoch 37/50 \t loss=0.1802 \t val_loss=0.5020 \t time=0.13s\n",
      "Epoch 38/50 \t loss=0.1997 \t val_loss=0.5510 \t time=0.13s\n",
      "Epoch 39/50 \t loss=0.2715 \t val_loss=0.3408 \t time=0.13s\n",
      "Epoch 40/50 \t loss=0.3379 \t val_loss=0.4627 \t time=0.14s\n",
      "Epoch 41/50 \t loss=0.1964 \t val_loss=0.4922 \t time=0.13s\n",
      "Epoch 42/50 \t loss=0.1974 \t val_loss=0.5260 \t time=0.14s\n",
      "Epoch 43/50 \t loss=0.1975 \t val_loss=0.4599 \t time=0.13s\n",
      "Epoch 44/50 \t loss=0.0887 \t val_loss=0.4631 \t time=0.14s\n",
      "Epoch 45/50 \t loss=0.1715 \t val_loss=0.4153 \t time=0.13s\n",
      "Epoch 46/50 \t loss=0.1453 \t val_loss=0.3519 \t time=0.13s\n",
      "Epoch 47/50 \t loss=0.1190 \t val_loss=0.2977 \t time=0.13s\n",
      "Epoch 48/50 \t loss=0.0809 \t val_loss=0.4008 \t time=0.13s\n",
      "Epoch 49/50 \t loss=0.2416 \t val_loss=0.5569 \t time=0.13s\n",
      "Epoch 50/50 \t loss=0.0873 \t val_loss=0.4562 \t time=0.14s\n",
      "[0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[[34 16]\n",
      " [36 82]]\n",
      "Accuracy :  0.6904761904761905\n",
      "Sensitivity :  0.68\n",
      "Specificity :  0.6949152542372882\n",
      "AUC:  0.6875\n",
      "\n",
      "\n",
      "All \t loss=0.1919 \t val_loss=0.7626 \t auc=0.6875\n"
     ]
    }
   ],
   "source": [
    "avg_losses_f = []\n",
    "avg_val_losses_f = []\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "    \n",
    "    ## ???\n",
    "    x_train_fold = torch.tensor(trn_X_pd[train_idx.astype(int)], dtype=torch.float)   # use_cuse?\n",
    "    y_train_fold = torch.tensor(trn_y_pd[train_idx.astype(int), np.newaxis], dtype=torch.float)    \n",
    "\n",
    "    x_val_fold = torch.tensor(trn_X_pd[valid_idx.astype(int)], dtype=torch.float)\n",
    "    y_val_fold = torch.tensor(trn_y_pd[valid_idx.astype(int), np.newaxis], dtype=torch.float)  \n",
    "    \n",
    "################################################################################    \n",
    "    trn_X = torch.from_numpy(trn_X_pd[train_idx.astype(int)].astype(float))\n",
    "    trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "    \n",
    "    # Train\n",
    "    trn = Dataset(trn_X, trn_y)\n",
    "    trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True, drop_last = True)  # True or False\n",
    "    trn_test_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=False, drop_last = False)  # True or False\n",
    "    \n",
    "    # Valid\n",
    "    valid_X = torch.from_numpy(trn_X_pd[valid_idx.astype(int)].astype(float))\n",
    "    valid_y = torch.from_numpy(trn_y_pd[valid_idx.astype(int)].astype(float))\n",
    "    \n",
    "    valid = Dataset(valid_X, valid_y)\n",
    "    valid_loader = data_utils.DataLoader(valid, batch_size=batch_size, shuffle=False, drop_last = False) # True or False\n",
    "    \n",
    "    # Test\n",
    "    val_X = torch.from_numpy(val_X_pd.astype(float))\n",
    "    val_y = torch.from_numpy(val_y_pd.astype(float))\n",
    "    val = Dataset(val_X, val_y)\n",
    "    test_loader = data_utils.DataLoader(val, batch_size=batch_size, shuffle=False)\n",
    "   ################################################################################    \n",
    "    print(i)\n",
    "    \n",
    "    ## Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "    ## After just second, will modify optimizer(weight_decay,step_size, base_lr, max_lr,scheduler)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "    \n",
    "    model = DNN_seq_1()\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    num_epochs = 50\n",
    "    \n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    ##############################################################################\n",
    "    step_size = 2000\n",
    "    base_lr, max_lr = 0.001, 0.01  \n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                             lr=max_lr)\n",
    "    \n",
    "    scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr, step_size=step_size, mode='exp_range', gamma=0.99994)    \n",
    "    \n",
    "    ##############################################################################\n",
    "    \n",
    "    print(f'Fold {i+1}')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "        #correct = 0.   # Accuracy\n",
    "        \n",
    "        for batch_idx, trn in enumerate(trn_loader):\n",
    "            trn_X, trn_y = trn['X'], trn['y']\n",
    "            if use_cuda:\n",
    "                trn_X, trn_y = trn_X.cuda(), trn_y.cuda()\n",
    "            trn_X, trn_y = Variable(trn_X).float(), Variable(trn_y).float()\n",
    "            optimizer.zero_grad()\n",
    "            trn_pred = model(trn_X)\n",
    "\n",
    "            \n",
    "            if scheduler:\n",
    "                #print('cycle_LR')\n",
    "                scheduler.batch_step()\n",
    "            #print(trn_pred.squeeze())\n",
    "            #print(trn_y)\n",
    "            trn_loss = criterion(trn_pred.squeeze(), trn_y)\n",
    "            trn_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            avg_loss += trn_loss.item()/len(trn_loader)\n",
    "        \n",
    "            #predicted = torch.max(trn_pred.data, 1)[1] \n",
    "            #correct += (predicted == trn_y).sum()\n",
    "        model.eval()\n",
    "        \n",
    "        valid_preds_fold = np.zeros((valid_X.size(0)))\n",
    "        test_preds_fold = np.zeros(val_X_pd.shape[0])  # Test\n",
    "        \n",
    "        avg_val_loss = 0.\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, val in enumerate(valid_loader):\n",
    "                val_X, val_y = val['X'], val['y']\n",
    "                if use_cuda:\n",
    "                    val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "                val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "                optimizer.zero_grad()\n",
    "                val_pred = model(val_X).detach()\n",
    "\n",
    "            \n",
    "                val_loss = criterion(val_pred.squeeze(), val_y)\n",
    "        \n",
    "                avg_val_loss += val_loss.item()/len(valid_loader)\n",
    "            \n",
    "            \n",
    "                #val_pred = torch.max(val_pred, 1)[1]\n",
    "                val_pred = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "                #print(val_pred.cpu().numpy())\n",
    "                #print(val_pred.cpu().numpy()[:,0])\n",
    "            \n",
    "                valid_preds_fold[batch_idx * batch_size:(batch_idx+1) * batch_size] = (val_pred.cpu().numpy())    # modified [:,0]\n",
    "            \n",
    "            #valid_preds_fold_2 = \n",
    "                # Loss function chage -> plus Sigmoid\n",
    "            elapsed_time = time.time() - start_time \n",
    "            print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(epoch + 1, num_epochs, avg_loss, avg_val_loss, elapsed_time))            \n",
    "\n",
    "# Test        \n",
    "    avg_losses_f.append(avg_loss)\n",
    "    avg_val_losses_f.append(avg_val_loss) \n",
    "    \n",
    "    for batch_idx, test in enumerate(test_loader):\n",
    "        test_X, test_y = test['X'], test['y']\n",
    "        if use_cuda:\n",
    "            test_X, test_y = test_X.cuda(), test_y.cuda()\n",
    "        test_X, test_y = Variable(test_X).float(), Variable(test_y).float()        \n",
    "        test_pred = model(test_X).detach()\n",
    "        \n",
    "        \n",
    "        test_pred = (test_pred > 0.5).flatten().type(torch.ByteTensor)\n",
    "        \n",
    "        #print(test_pred)\n",
    "        #print(test_pred.cpu().numpy())\n",
    "        test_preds_fold[batch_idx * batch_size:(batch_idx+1) * batch_size] = (test_pred.cpu().numpy())   # modified [:,0]\n",
    "        \n",
    "        \n",
    "    train_preds[valid_idx.astype(int)] = valid_preds_fold\n",
    "    print(valid_preds_fold)\n",
    "    print(trn_y_pd[valid_idx.astype(int)])\n",
    "    train_y_sort[valid_idx.astype(int)] = trn_y_pd[valid_idx.astype(int)]\n",
    "    test_preds += test_preds_fold / len(splits)\n",
    "\n",
    "#predict_ = pd.DataFrame(predict)\n",
    "\n",
    "#predict_.iloc[:,0]\n",
    "\n",
    "#label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "#test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)    \n",
    "    \n",
    "print(trn_y_pd)\n",
    "print(train_preds)\n",
    "\n",
    "auc  =  round(roc_auc_score(train_y_sort,train_preds.astype(int)),4)\n",
    "\n",
    "\n",
    "cnf = confusion_matrix(train_y_sort, train_preds, labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "print('AUC: ', auc)\n",
    "\n",
    "\n",
    "#fpr, trp, _  =  roc_auc_score(train_y_sort,train_preds.astype(int))\n",
    "\n",
    "#fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "#print(type(fpr))\n",
    "#print(fpr)\n",
    "\n",
    "#auc = auc(fpr, trp)\n",
    "#print('AUC: ', auc(fpr, trp))\n",
    "print('\\n')\n",
    "print('All \\t loss={:.4f} \\t val_loss={:.4f} \\t auc={:.4f}'.format(np.average(avg_losses_f),np.average(avg_val_losses_f),auc))        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 1.])\n",
      "tensor([1, 1, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([1., 1., 0., 1., 0.])\n",
      "tensor([1, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([1., 0., 0., 0., 1.])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 0., 0., 0., 0.])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([1, 0, 1, 1, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 1.])\n",
      "tensor([0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0.])\n",
      "******************** Test ********************\n",
      "Loss: 0.05888558551669121, Accuracy: 0.7142857313156128 %\n",
      "**********************************************\n",
      "Val accuracy:0.714\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(valid_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        #print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        print(val_y)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(valid_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(valid_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.116455e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.524222e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.395531e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.079036e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.036568e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.521262e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.020780e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.498865e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.662610e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.142736e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.046071e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.925134e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.060159e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.251581e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.168493e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.121071e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.040184e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.694609e-10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.227572e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.272015e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.947014e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.080550e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.566988e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.708824e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.334947e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.369329e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.048061e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.936718e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.795704e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.904316e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.531944e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.766656e-10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.031907e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0                \n",
       "2.116455e-02  0.0\n",
       "1.524222e-02  0.0\n",
       "6.395531e-02  0.0\n",
       "7.079036e-01  0.0\n",
       "5.036568e-01  1.0\n",
       "9.521262e-01  1.0\n",
       "8.020780e-01  1.0\n",
       "3.498865e-01  0.0\n",
       "6.662610e-01  1.0\n",
       "7.142736e-01  0.0\n",
       "5.046071e-01  1.0\n",
       "2.925134e-01  0.0\n",
       "1.060159e-02  0.0\n",
       "9.251581e-01  0.0\n",
       "9.168493e-01  1.0\n",
       "1.121071e-01  1.0\n",
       "5.040184e-01  0.0\n",
       "8.694609e-10  0.0\n",
       "3.227572e-02  0.0\n",
       "1.272015e-02  0.0\n",
       "4.947014e-03  0.0\n",
       "1.080550e-01  1.0\n",
       "1.566988e-03  0.0\n",
       "1.708824e-04  0.0\n",
       "1.334947e-03  0.0\n",
       "5.369329e-01  0.0\n",
       "4.048061e-05  0.0\n",
       "9.936718e-01  1.0\n",
       "7.795704e-01  0.0\n",
       "8.904316e-01  1.0\n",
       "1.531944e-01  0.0\n",
       "1.766656e-10  0.0\n",
       "1.031907e-02  0.0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "pd.DataFrame(trn_y_pd[valid_idx.astype(int)], predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  2]\n",
      " [ 6 17]]\n",
      "Accuracy :  0.7575757575757576\n",
      "Sensitivity :  0.8\n",
      "Specificity :  0.7391304347826086\n",
      "AUC:  0.7696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(trn_y_pd[valid_idx.astype(int)])\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "#fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "auc  =  round(roc_auc_score(test_p['label'],test_p['predicted_prob']),4)\n",
    "#print(fpr)\n",
    "#print(trp)\n",
    "#print(fpr)\n",
    "print('AUC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN_seq_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN_seq_1(\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=150, bias=True)\n",
       "    (1): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (classifier2): Sequential(\n",
       "    (0): Linear(in_features=150, out_features=250, bias=True)\n",
       "    (1): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): Linear(in_features=250, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = TheModelClass(*args, **kwargs)                                                                                                     \n",
    "#optimizer = TheOptimizerClass(*args, **kwargs)                                                                                             \n",
    "checkpoint = torch.load(\"./platin_model_save/platin_model_300_100_100_model_1_150_250.pth\")                                                                                  \n",
    "model.load_state_dict(checkpoint['model_state_dict'])                                                                                         \n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])                                                                               \n",
    "#num_epochs = checkpoint['epoch']                                                                                                           \n",
    "loss = checkpoint['loss']                                                                                                                   \n",
    "model.eval()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 1., 1.])\n",
      "tensor([1, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 1., 0.])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 0.])\n",
      "tensor([0, 0, 1, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([1, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 0., 1., 0., 0.])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0, 0, 1, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 1.])\n",
      "tensor([1, 0], dtype=torch.uint8)\n",
      "tensor([1., 0.])\n",
      "******************** Test ********************\n",
      "Loss: 0.27898815274238586, Accuracy: 0.6888889074325562 %\n",
      "**********************************************\n",
      "Val accuracy:0.689\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        #print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        print(val_y)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7.203556e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.058780e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.242305e-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.801773e-02</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.516869e-02</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.916478e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.985192e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.196610e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.878962e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.035347e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.328394e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.553838e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.975958e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.297061e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.455893e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.742571e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.276082e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.200677e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.711503e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.877120e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.624006e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.948066e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.556966e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.386482e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.827072e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.766586e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.150531e-11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.753548e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.337780e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.846450e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.830439e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.892550e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.108983e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.681288e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.344500e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.064114e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.567141e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.825928e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.337545e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.572885e-04</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.723667e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.830339e-07</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0                \n",
       "7.203556e-05  0.0\n",
       "9.058780e-01  1.0\n",
       "3.242305e-08  0.0\n",
       "7.801773e-02  1.0\n",
       "7.516869e-02  1.0\n",
       "8.916478e-01  0.0\n",
       "1.985192e-03  0.0\n",
       "5.196610e-02  0.0\n",
       "9.878962e-01  1.0\n",
       "1.035347e-05  0.0\n",
       "2.328394e-01  0.0\n",
       "2.553838e-04  0.0\n",
       "8.975958e-01  1.0\n",
       "3.297061e-04  0.0\n",
       "3.455893e-01  0.0\n",
       "2.742571e-01  0.0\n",
       "1.276082e-01  1.0\n",
       "9.200677e-01  0.0\n",
       "9.711503e-01  0.0\n",
       "2.877120e-02  0.0\n",
       "9.624006e-01  1.0\n",
       "1.948066e-01  0.0\n",
       "8.556966e-01  1.0\n",
       "5.386482e-06  0.0\n",
       "2.827072e-02  0.0\n",
       "1.766586e-01  0.0\n",
       "2.150531e-11  0.0\n",
       "4.753548e-03  0.0\n",
       "9.337780e-01  0.0\n",
       "3.846450e-03  0.0\n",
       "6.830439e-01  0.0\n",
       "7.892550e-01  0.0\n",
       "1.108983e-01  0.0\n",
       "2.681288e-01  0.0\n",
       "1.344500e-01  0.0\n",
       "1.064114e-04  0.0\n",
       "1.567141e-01  0.0\n",
       "9.825928e-01  1.0\n",
       "7.337545e-01  0.0\n",
       "4.572885e-04  1.0\n",
       "5.723667e-01  1.0\n",
       "8.830339e-07  0.0"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  4]\n",
      " [ 7 24]]\n",
      "Accuracy :  0.7380952380952381\n",
      "Sensitivity :  0.6363636363636364\n",
      "Specificity :  0.7741935483870968\n",
      "<class 'numpy.ndarray'>\n",
      "AUC:  0.7052785923753664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print(type(fpr))\n",
    "#print(fpr)\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "#'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': trn_loss\n",
    "    }, \"./platin_model_save/platin_model_300_100_100_model_1_150_250__.pth\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test (Except Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.8264e-01],\n",
      "        [1.3459e-06],\n",
      "        [9.1461e-01],\n",
      "        [9.0472e-04],\n",
      "        [7.5072e-03]])\n",
      "tensor([1, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.7613e-01],\n",
      "        [9.0459e-02],\n",
      "        [9.8720e-01],\n",
      "        [1.0357e-04],\n",
      "        [2.8245e-04]])\n",
      "tensor([1, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.9562e-01],\n",
      "        [9.1837e-01],\n",
      "        [4.8240e-05],\n",
      "        [4.6706e-01],\n",
      "        [5.3156e-03]])\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.0037],\n",
      "        [0.1023],\n",
      "        [0.9770],\n",
      "        [0.9826],\n",
      "        [0.9663]])\n",
      "tensor([0, 0, 1, 1, 1], dtype=torch.uint8)\n",
      "tensor([[0.9899],\n",
      "        [0.4419],\n",
      "        [0.1809],\n",
      "        [0.0048],\n",
      "        [0.9955]])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[1.7116e-04],\n",
      "        [5.9432e-07],\n",
      "        [9.8805e-04],\n",
      "        [1.4808e-02],\n",
      "        [9.8920e-01]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[1.3996e-03],\n",
      "        [9.5969e-01],\n",
      "        [1.8372e-03],\n",
      "        [2.8016e-02],\n",
      "        [7.0165e-05]])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.0158],\n",
      "        [0.6467],\n",
      "        [0.9958],\n",
      "        [0.0340],\n",
      "        [0.9968]])\n",
      "tensor([0, 1, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([[8.6539e-05],\n",
      "        [2.3085e-04],\n",
      "        [9.9515e-01],\n",
      "        [9.8010e-01],\n",
      "        [1.1860e-06]])\n",
      "tensor([0, 0, 1, 1, 0], dtype=torch.uint8)\n",
      "tensor([[2.3522e-09],\n",
      "        [9.9606e-01],\n",
      "        [9.8898e-03],\n",
      "        [1.3460e-01],\n",
      "        [2.1519e-01]])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[6.0699e-08],\n",
      "        [5.6217e-04],\n",
      "        [2.9710e-01],\n",
      "        [1.3983e-02],\n",
      "        [1.3167e-03]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.8025e-01],\n",
      "        [7.2111e-03],\n",
      "        [1.6939e-02],\n",
      "        [2.9553e-05],\n",
      "        [1.6676e-02]])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[2.9875e-05],\n",
      "        [9.8904e-01],\n",
      "        [9.8761e-01],\n",
      "        [2.6780e-04],\n",
      "        [2.4499e-01]])\n",
      "tensor([0, 1, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[3.1815e-01],\n",
      "        [2.4853e-04],\n",
      "        [2.8629e-13],\n",
      "        [1.4032e-02],\n",
      "        [1.2625e-03]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[5.3221e-05],\n",
      "        [4.5842e-03],\n",
      "        [2.2932e-08],\n",
      "        [5.8473e-06],\n",
      "        [1.3673e-02]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.6246e-01],\n",
      "        [2.4446e-01],\n",
      "        [9.3992e-06],\n",
      "        [2.1285e-02],\n",
      "        [9.9352e-01]])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[9.9212e-01],\n",
      "        [9.8507e-01],\n",
      "        [9.5594e-01],\n",
      "        [9.8443e-01],\n",
      "        [2.3524e-10]])\n",
      "tensor([1, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "tensor([[5.3327e-13],\n",
      "        [1.4253e-02],\n",
      "        [6.8505e-08],\n",
      "        [3.0679e-02],\n",
      "        [9.7160e-01]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[0.9634],\n",
      "        [0.0175],\n",
      "        [0.9685],\n",
      "        [0.0553],\n",
      "        [0.0012]])\n",
      "tensor([1, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.0017],\n",
      "        [0.0027],\n",
      "        [0.9965],\n",
      "        [0.0075],\n",
      "        [0.2261]])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[7.8745e-03],\n",
      "        [2.8086e-05],\n",
      "        [8.5193e-04],\n",
      "        [9.9046e-01],\n",
      "        [1.8913e-06]])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[9.7088e-01],\n",
      "        [9.9235e-01],\n",
      "        [1.4847e-01],\n",
      "        [2.9464e-02],\n",
      "        [2.6306e-04]])\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[6.9253e-02],\n",
      "        [3.5878e-13],\n",
      "        [9.9544e-01],\n",
      "        [4.4275e-08],\n",
      "        [2.3294e-02]])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.1048],\n",
      "        [0.0037],\n",
      "        [0.0762],\n",
      "        [0.9735],\n",
      "        [0.3505]])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[5.1423e-04],\n",
      "        [5.8472e-02],\n",
      "        [2.2244e-06],\n",
      "        [1.6211e-02],\n",
      "        [6.2109e-03]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.8859e-01],\n",
      "        [7.4364e-04],\n",
      "        [6.6917e-02],\n",
      "        [2.2841e-03],\n",
      "        [9.7299e-01]])\n",
      "tensor([1, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[9.9654e-01],\n",
      "        [9.9441e-01],\n",
      "        [3.1758e-06],\n",
      "        [9.9886e-02],\n",
      "        [1.5312e-01]])\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "******************** Test ********************\n",
      "Loss: 0.05610276013612747, Accuracy: 0.9925925731658936 %\n",
      "**********************************************\n",
      "Val accuracy:0.993\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(trn_test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(trn_test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(trn_test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.982645</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.914612</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000905</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.007507</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.996539</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.994407</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000003</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.099886</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.153124</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0            \n",
       "0.982645  1.0\n",
       "0.000001  0.0\n",
       "0.914612  1.0\n",
       "0.000905  0.0\n",
       "0.007507  0.0\n",
       "...       ...\n",
       "0.996539  1.0\n",
       "0.994407  1.0\n",
       "0.000003  0.0\n",
       "0.099886  0.0\n",
       "0.153124  0.0\n",
       "\n",
       "[135 rows x 1 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "#trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "pd.DataFrame(trn_y_pd[train_idx.astype(int)], predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  0]\n",
      " [ 1 94]]\n",
      "Accuracy :  0.9925925925925926\n",
      "Sensitivity :  1.0\n",
      "Specificity :  0.9894736842105263\n",
      "AUC:  0.9947368421052631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(trn_y_pd[train_idx.astype(int)])\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ........................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Train stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ........................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train (Total Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_X = torch.from_numpy(trn_X_pd.astype(float))\n",
    "trn_y = torch.from_numpy(trn_y_pd.astype(float))\n",
    "\n",
    "val_X = torch.from_numpy(val_X_pd.astype(float))\n",
    "val_y = torch.from_numpy(val_y_pd.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = Dataset(trn_X, trn_y)\n",
    "trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "\n",
    "trn_test_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "val = Dataset(val_X, val_y)\n",
    "val_loader = data_utils.DataLoader(val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 1e-3\n",
    "    \n",
    "## After just second, will modify optimizer(weight_decay,step_size, base_lr, max_lr,scheduler)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-5)\n",
    "    \n",
    "model = DNN_seq_1()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "num_epochs = 90\n",
    "    \n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "##############################################################################\n",
    "step_size = 2000\n",
    "base_lr, max_lr = 0.001, 0.01  \n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                             lr=max_lr)\n",
    "    \n",
    "scheduler = CyclicLR(optimizer, base_lr=base_lr, max_lr=max_lr, step_size=step_size, mode='exp_range', gamma=0.99994)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.8801079988479614, Accuracy: 0.6424242258071899 % \t time=0.26s\n",
      "******************** Train ********************\n",
      "Loss: 0.3876979947090149, Accuracy: 0.7757575511932373 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 1.0283232927322388, Accuracy: 0.7636363506317139 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.3658212423324585, Accuracy: 0.8242424130439758 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.3468271791934967, Accuracy: 0.8909090757369995 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.3821912705898285, Accuracy: 0.8666666746139526 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.26507440209388733, Accuracy: 0.8969696760177612 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.10434311628341675, Accuracy: 0.903030276298523 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.02957935258746147, Accuracy: 0.903030276298523 % \t time=0.25s\n",
      "******************** Train ********************\n",
      "Loss: 0.024372901767492294, Accuracy: 0.9575757384300232 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.03705301880836487, Accuracy: 0.9575757384300232 % \t time=0.25s\n",
      "******************** Train ********************\n",
      "Loss: 0.5503559112548828, Accuracy: 0.9272727370262146 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 1.0209078788757324, Accuracy: 0.9515151381492615 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.11966726928949356, Accuracy: 0.9212121367454529 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.33557847142219543, Accuracy: 0.8969696760177612 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.10731393098831177, Accuracy: 0.9272727370262146 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.04641410708427429, Accuracy: 0.8848484754562378 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.3002076745033264, Accuracy: 0.903030276298523 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.030827796086668968, Accuracy: 0.9454545378684998 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.005285901017487049, Accuracy: 0.939393937587738 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.06277326494455338, Accuracy: 0.9151515364646912 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.05315679311752319, Accuracy: 0.9272727370262146 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.08171539008617401, Accuracy: 0.9212121367454529 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.050089381635189056, Accuracy: 0.9575757384300232 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.05292575806379318, Accuracy: 0.939393937587738 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.06465829908847809, Accuracy: 0.9636363387107849 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 1.7496715784072876, Accuracy: 0.903030276298523 % \t time=0.25s\n",
      "******************** Train ********************\n",
      "Loss: 0.052900224924087524, Accuracy: 0.9151515364646912 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.018139859661459923, Accuracy: 0.939393937587738 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.09071991592645645, Accuracy: 0.9636363387107849 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.06392266601324081, Accuracy: 0.9333333373069763 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.08598075807094574, Accuracy: 0.9333333373069763 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.06805004924535751, Accuracy: 0.8727272748947144 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.009006990119814873, Accuracy: 0.9212121367454529 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.010713566094636917, Accuracy: 0.9454545378684998 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.01597818173468113, Accuracy: 0.9515151381492615 % \t time=0.25s\n",
      "******************** Train ********************\n",
      "Loss: 0.015245230868458748, Accuracy: 0.9696969985961914 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.19639459252357483, Accuracy: 0.9636363387107849 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.05904168635606766, Accuracy: 0.9333333373069763 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.011578106321394444, Accuracy: 0.9333333373069763 % \t time=0.26s\n",
      "******************** Train ********************\n",
      "Loss: 0.05718512460589409, Accuracy: 0.9454545378684998 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.006572664715349674, Accuracy: 0.9757575988769531 % \t time=0.26s\n",
      "******************** Train ********************\n",
      "Loss: 0.3694895803928375, Accuracy: 0.9515151381492615 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.018085692077875137, Accuracy: 0.9454545378684998 % \t time=0.25s\n",
      "******************** Train ********************\n",
      "Loss: 0.01993372291326523, Accuracy: 0.9454545378684998 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.015414992347359657, Accuracy: 0.9454545378684998 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.2251739501953125, Accuracy: 0.9090909361839294 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.3582252860069275, Accuracy: 0.9272727370262146 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.1636025607585907, Accuracy: 0.9454545378684998 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.0037062957417219877, Accuracy: 0.9575757384300232 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.5051246285438538, Accuracy: 0.939393937587738 % \t time=0.26s\n",
      "******************** Train ********************\n",
      "Loss: 0.20436625182628632, Accuracy: 0.9636363387107849 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.01036036852747202, Accuracy: 0.9454545378684998 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.08704542368650436, Accuracy: 0.9515151381492615 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.025645237416028976, Accuracy: 0.9333333373069763 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.02956226095557213, Accuracy: 0.9515151381492615 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.45675235986709595, Accuracy: 0.9212121367454529 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.26147985458374023, Accuracy: 0.9333333373069763 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.35316863656044006, Accuracy: 0.9636363387107849 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.0717184916138649, Accuracy: 0.9636363387107849 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.07168993353843689, Accuracy: 0.9636363387107849 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.01865876093506813, Accuracy: 0.9212121367454529 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.008904216811060905, Accuracy: 0.9272727370262146 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.07311175018548965, Accuracy: 0.9515151381492615 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.1461777538061142, Accuracy: 0.9757575988769531 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.012499161064624786, Accuracy: 0.9636363387107849 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.004214325454086065, Accuracy: 0.9757575988769531 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.026559501886367798, Accuracy: 0.9515151381492615 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.03053274378180504, Accuracy: 0.939393937587738 % \t time=0.25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.020077496767044067, Accuracy: 0.939393937587738 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.5951856374740601, Accuracy: 0.8969696760177612 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.12490078061819077, Accuracy: 0.9515151381492615 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.01937979832291603, Accuracy: 0.9636363387107849 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.006360775325447321, Accuracy: 0.939393937587738 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.018852202221751213, Accuracy: 0.9454545378684998 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.39531201124191284, Accuracy: 0.9575757384300232 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.08233354240655899, Accuracy: 0.9696969985961914 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.27668246626853943, Accuracy: 0.9151515364646912 % \t time=0.25s\n",
      "******************** Train ********************\n",
      "Loss: 0.010607350617647171, Accuracy: 0.9878787994384766 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.6846851706504822, Accuracy: 0.9272727370262146 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.030167918652296066, Accuracy: 0.9515151381492615 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.052327610552310944, Accuracy: 0.9878787994384766 % \t time=0.24s\n",
      "******************** Train ********************\n",
      "Loss: 0.21148653328418732, Accuracy: 0.9636363387107849 % \t time=0.22s\n",
      "******************** Train ********************\n",
      "Loss: 0.007610023953020573, Accuracy: 0.9939393997192383 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.013349476270377636, Accuracy: 0.9515151381492615 % \t time=0.20s\n",
      "******************** Train ********************\n",
      "Loss: 0.009953072294592857, Accuracy: 0.9636363387107849 % \t time=0.18s\n",
      "******************** Train ********************\n",
      "Loss: 0.002603159286081791, Accuracy: 0.9878787994384766 % \t time=0.23s\n",
      "******************** Train ********************\n",
      "Loss: 0.013932740315794945, Accuracy: 0.9818181991577148 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.002962624654173851, Accuracy: 0.9454545378684998 % \t time=0.21s\n",
      "******************** Train ********************\n",
      "Loss: 0.025903265923261642, Accuracy: 0.9575757384300232 % \t time=0.21s\n",
      "**********************************************\n",
      "Trn accuracy:0.958 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predict = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    #correct = 0.   # Accuracy\n",
    "    correct_val = 0.\n",
    "        \n",
    "    for batch_idx, trn in enumerate(trn_loader):\n",
    "        trn_X, trn_y = trn['X'], trn['y']\n",
    "        if use_cuda:\n",
    "            trn_X, trn_y = trn_X.cuda(), trn_y.cuda()\n",
    "        trn_X, trn_y = Variable(trn_X).float(), Variable(trn_y).float()\n",
    "        optimizer.zero_grad()\n",
    "        trn_pred = model(trn_X)\n",
    "        for i in trn_pred:\n",
    "            predict.append(i.detach().numpy())\n",
    "            \n",
    "        if scheduler:\n",
    "            #print('cycle_LR')\n",
    "            scheduler.batch_step()\n",
    "        #print(trn_pred.squeeze())\n",
    "        #print(trn_y)\n",
    "        trn_loss = criterion(trn_pred.squeeze(), trn_y)\n",
    "        trn_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += trn_loss.item()/len(trn_loader)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        predicted = (trn_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        correct_val += (predicted == trn_y).sum()\n",
    "    print('*'*20, 'Train', '*'*20)\n",
    "    print('Loss: {}, Accuracy: {} % \\t time={:.2f}s'.format(trn_loss.item(), correct_val/(len(trn_loader)*batch_size), elapsed_time))\n",
    "print('*'*46)\n",
    "print(\"Trn accuracy:{:.3f} \".format(float(correct_val) / (len(trn_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9460e-01],\n",
      "        [1.2316e-03],\n",
      "        [9.9525e-01],\n",
      "        [1.1234e-05],\n",
      "        [4.9585e-03]])\n",
      "tensor([1, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[4.0293e-03],\n",
      "        [7.8686e-16],\n",
      "        [9.9776e-01],\n",
      "        [7.8140e-03],\n",
      "        [9.9880e-01]])\n",
      "tensor([0, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([[3.3409e-05],\n",
      "        [7.0429e-04],\n",
      "        [6.5754e-07],\n",
      "        [9.9197e-01],\n",
      "        [9.6519e-01]])\n",
      "tensor([0, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([[1.7777e-02],\n",
      "        [1.1674e-08],\n",
      "        [4.2539e-05],\n",
      "        [3.6544e-06],\n",
      "        [1.0357e-03]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.9973],\n",
      "        [0.0114],\n",
      "        [0.9978],\n",
      "        [0.9886],\n",
      "        [0.9900]])\n",
      "tensor([1, 0, 1, 1, 1], dtype=torch.uint8)\n",
      "tensor([[0.0503],\n",
      "        [0.9941],\n",
      "        [0.9870],\n",
      "        [0.0170],\n",
      "        [0.9960]])\n",
      "tensor([0, 1, 1, 0, 1], dtype=torch.uint8)\n",
      "tensor([[7.6971e-04],\n",
      "        [9.9719e-01],\n",
      "        [1.5430e-02],\n",
      "        [2.0442e-02],\n",
      "        [1.1107e-05]])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[7.4443e-05],\n",
      "        [9.6406e-01],\n",
      "        [1.0804e-01],\n",
      "        [9.3958e-05],\n",
      "        [9.9004e-01]])\n",
      "tensor([0, 1, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[5.9187e-05],\n",
      "        [1.2117e-03],\n",
      "        [5.8107e-04],\n",
      "        [4.0826e-03],\n",
      "        [2.2094e-02]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.9855],\n",
      "        [0.9796],\n",
      "        [0.0135],\n",
      "        [0.9966],\n",
      "        [0.0017]])\n",
      "tensor([1, 1, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[6.8542e-04],\n",
      "        [1.0200e-04],\n",
      "        [9.9606e-01],\n",
      "        [9.7672e-01],\n",
      "        [2.8931e-06]])\n",
      "tensor([0, 0, 1, 1, 0], dtype=torch.uint8)\n",
      "tensor([[2.1775e-06],\n",
      "        [9.9685e-01],\n",
      "        [4.7265e-04],\n",
      "        [5.5145e-02],\n",
      "        [4.4236e-03]])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.9998],\n",
      "        [0.0049],\n",
      "        [0.0066],\n",
      "        [0.0220],\n",
      "        [0.0047]])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[2.4643e-02],\n",
      "        [2.8794e-02],\n",
      "        [6.9644e-03],\n",
      "        [5.6042e-04],\n",
      "        [9.9620e-01]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[5.3140e-04],\n",
      "        [1.7111e-06],\n",
      "        [5.2200e-04],\n",
      "        [9.8793e-01],\n",
      "        [3.5394e-05]])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[9.9872e-01],\n",
      "        [1.7452e-05],\n",
      "        [9.8001e-01],\n",
      "        [9.9404e-01],\n",
      "        [1.0511e-03]])\n",
      "tensor([1, 0, 1, 1, 0], dtype=torch.uint8)\n",
      "tensor([[0.0010],\n",
      "        [0.1128],\n",
      "        [0.0538],\n",
      "        [0.0950],\n",
      "        [0.1439]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.1594e-03],\n",
      "        [2.3217e-02],\n",
      "        [4.4933e-07],\n",
      "        [3.4791e-03],\n",
      "        [1.8553e-05]])\n",
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.8665e-06],\n",
      "        [8.6412e-03],\n",
      "        [1.3230e-10],\n",
      "        [9.7238e-01],\n",
      "        [1.8558e-01]])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[5.0580e-02],\n",
      "        [1.7832e-06],\n",
      "        [9.8779e-01],\n",
      "        [9.9874e-01],\n",
      "        [9.6918e-01]])\n",
      "tensor([0, 0, 1, 1, 1], dtype=torch.uint8)\n",
      "tensor([[9.8956e-01],\n",
      "        [9.8706e-01],\n",
      "        [1.6869e-05],\n",
      "        [2.4430e-05],\n",
      "        [1.7491e-04]])\n",
      "tensor([1, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[1.5640e-14],\n",
      "        [2.1321e-04],\n",
      "        [9.8349e-01],\n",
      "        [9.9767e-01],\n",
      "        [8.5846e-07]])\n",
      "tensor([0, 0, 1, 1, 0], dtype=torch.uint8)\n",
      "tensor([[9.8013e-01],\n",
      "        [1.5130e-02],\n",
      "        [1.0112e-02],\n",
      "        [4.3315e-04],\n",
      "        [1.0627e-02]])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[4.7044e-05],\n",
      "        [5.8728e-05],\n",
      "        [9.9546e-01],\n",
      "        [1.2334e-03],\n",
      "        [5.4182e-05]])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.8042e-01],\n",
      "        [7.5283e-02],\n",
      "        [8.7703e-12],\n",
      "        [8.6702e-04],\n",
      "        [2.8836e-02]])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[6.7663e-03],\n",
      "        [9.9735e-01],\n",
      "        [1.5090e-04],\n",
      "        [5.1520e-06],\n",
      "        [9.8361e-01]])\n",
      "tensor([0, 1, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[5.5875e-04],\n",
      "        [9.9380e-01],\n",
      "        [2.3352e-04],\n",
      "        [1.1951e-06],\n",
      "        [8.8024e-07]])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[3.2789e-04],\n",
      "        [3.1198e-08],\n",
      "        [2.5997e-03],\n",
      "        [1.1986e-04],\n",
      "        [9.9830e-01]])\n",
      "tensor([0, 0, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([[2.5585e-02],\n",
      "        [1.2827e-04],\n",
      "        [2.0644e-04],\n",
      "        [9.7187e-01],\n",
      "        [1.1572e-05]])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([[3.3087e-05],\n",
      "        [9.9813e-01],\n",
      "        [1.5295e-05],\n",
      "        [1.9563e-02],\n",
      "        [5.1924e-04]])\n",
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.7420e-01],\n",
      "        [1.4998e-04],\n",
      "        [5.2298e-06],\n",
      "        [1.9064e-03],\n",
      "        [3.2393e-05]])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[9.9437e-01],\n",
      "        [2.8415e-03],\n",
      "        [1.7339e-03],\n",
      "        [4.5440e-04],\n",
      "        [1.6257e-06]])\n",
      "tensor([1, 0, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([[0.0025],\n",
      "        [0.1729],\n",
      "        [0.9983],\n",
      "        [0.9969],\n",
      "        [0.9968]])\n",
      "tensor([0, 0, 1, 1, 1], dtype=torch.uint8)\n",
      "tensor([[0.0085],\n",
      "        [0.0146],\n",
      "        [0.0002]])\n",
      "tensor([0, 0, 0], dtype=torch.uint8)\n",
      "******************** Test ********************\n",
      "Loss: 0.007821361534297466, Accuracy: 0.9882352948188782 %\n",
      "**********************************************\n",
      "Val accuracy:0.988\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(trn_test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(trn_test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(trn_test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.994600</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001232</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.995253</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000011</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004959</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.996875</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.996846</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.008547</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.014603</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000170</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0            \n",
       "0.994600  1.0\n",
       "0.001232  0.0\n",
       "0.995253  1.0\n",
       "0.000011  0.0\n",
       "0.004959  0.0\n",
       "...       ...\n",
       "0.996875  1.0\n",
       "0.996846  1.0\n",
       "0.008547  0.0\n",
       "0.014603  0.0\n",
       "0.000170  0.0\n",
       "\n",
       "[168 rows x 1 columns]"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "#trn_y = torch.from_numpy(trn_y_pd[train_idx.astype(int)].astype(float))\n",
    "pd.DataFrame(trn_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50   0]\n",
      " [  0 118]]\n",
      "Accuracy :  1.0\n",
      "Sensitivity :  1.0\n",
      "Specificity :  1.0\n",
      "AUC:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(trn_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 1., 1.])\n",
      "tensor([1, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 1., 0.])\n",
      "tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 0.])\n",
      "tensor([0, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 1., 0., 0., 0.])\n",
      "tensor([1, 1, 1, 0, 0], dtype=torch.uint8)\n",
      "tensor([1., 0., 1., 0., 0.])\n",
      "tensor([0, 0, 0, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0, 1, 1, 1, 0], dtype=torch.uint8)\n",
      "tensor([0., 0., 1., 0., 1.])\n",
      "tensor([1, 0], dtype=torch.uint8)\n",
      "tensor([1., 0.])\n",
      "******************** Test ********************\n",
      "Loss: 0.04022243618965149, Accuracy: 0.6666666865348816 %\n",
      "**********************************************\n",
      "Val accuracy:0.667\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        #print(val_pred)\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        #predicted = torch.max(val_pred.data, 1)[1]\n",
    "        predicted = (val_pred >= 0.5).flatten().type(torch.ByteTensor)\n",
    "        print(predicted)\n",
    "        print(val_y)\n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(test_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(test_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9.721512e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.114642e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.941586e-23</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.027601e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.161286e-04</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.012681e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.848170e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.494056e-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.972969e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.668410e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.170589e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.410485e-10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.578667e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.041243e-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.449922e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.078933e-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.389100e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.042386e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.938863e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.614161e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.710280e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.001716e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.678468e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.575920e-11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.878693e-09</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.980201e-06</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.289283e-15</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.868098e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.705796e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.009127e-11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.588134e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.682527e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.856051e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.035647e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.089754e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.942887e-05</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.857174e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.991251e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.662340e-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.449265e-02</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.227058e-01</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.433845e-10</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0                \n",
       "9.721512e-06  0.0\n",
       "7.114642e-01  1.0\n",
       "1.941586e-23  0.0\n",
       "4.027601e-01  1.0\n",
       "9.161286e-04  1.0\n",
       "9.012681e-01  0.0\n",
       "4.848170e-05  0.0\n",
       "4.494056e-03  0.0\n",
       "9.972969e-01  1.0\n",
       "2.668410e-05  0.0\n",
       "1.170589e-05  0.0\n",
       "8.410485e-10  0.0\n",
       "9.578667e-01  1.0\n",
       "1.041243e-04  0.0\n",
       "4.449922e-02  0.0\n",
       "1.078933e-02  0.0\n",
       "7.389100e-01  1.0\n",
       "7.042386e-01  0.0\n",
       "9.938863e-01  0.0\n",
       "4.614161e-01  0.0\n",
       "9.710280e-01  1.0\n",
       "9.001716e-01  0.0\n",
       "5.678468e-01  1.0\n",
       "8.575920e-11  0.0\n",
       "1.878693e-09  0.0\n",
       "4.980201e-06  0.0\n",
       "4.289283e-15  0.0\n",
       "1.868098e-05  0.0\n",
       "9.705796e-01  0.0\n",
       "8.009127e-11  0.0\n",
       "3.588134e-01  0.0\n",
       "4.682527e-01  0.0\n",
       "7.856051e-05  0.0\n",
       "5.035647e-01  0.0\n",
       "7.089754e-01  0.0\n",
       "2.942887e-05  0.0\n",
       "5.857174e-01  0.0\n",
       "9.991251e-01  1.0\n",
       "9.662340e-01  0.0\n",
       "6.449265e-02  1.0\n",
       "9.227058e-01  1.0\n",
       "7.433845e-10  0.0"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  3]\n",
      " [ 9 22]]\n",
      "Accuracy :  0.7142857142857143\n",
      "Sensitivity :  0.7272727272727273\n",
      "Specificity :  0.7096774193548387\n",
      "<class 'numpy.ndarray'>\n",
      "AUC:  0.718475073313783\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "label = pd.DataFrame(val_y_pd)\n",
    "\n",
    "test_p = pd.concat([predict_.iloc[:,0], label], axis = 1)\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "test_p.columns = ['predict','label']\n",
    "\n",
    "\n",
    "test_p.loc[test_p['predict'] >= 0.5, 'predicted_prob'] = 1\n",
    "test_p.loc[test_p['predict'] < 0.5, 'predicted_prob'] = 0\n",
    "\n",
    "\n",
    "#print(test_p)\n",
    "\n",
    "cnf = confusion_matrix(test_p['label'], test_p['predicted_prob'], labels = [1,0])\n",
    "\n",
    "print(cnf)\n",
    "\n",
    "total1 = sum(sum(cnf))\n",
    "\n",
    "accuracy1=(cnf[0,0]+cnf[1,1])/total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cnf[0,0]/(cnf[0,0]+cnf[0,1])\n",
    "print('Sensitivity : ', sensitivity1 )\n",
    "\n",
    "specificity1 = cnf[1,1]/(cnf[1,0]+cnf[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "fpr, trp, _ = roc_curve(test_p['label'], test_p['predicted_prob'])\n",
    "\n",
    "print(type(fpr))\n",
    "#print(fpr)\n",
    "print('AUC: ', auc(fpr, trp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "#'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': trn_loss\n",
    "    }, \"./platin_model_save/platin_model_300_100_100_model_1_150_250__2.pth\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "#'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': trn_loss\n",
    "    }, \"./platin_model_save/platin_model_500_model_2_200_300.pth\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.59662362e-05, 0.00000000e+00, 1.02076500e-04, ...,\n",
       "        0.00000000e+00, 1.28752303e-02, 1.23934200e-04],\n",
       "       [7.74798159e-07, 3.41406163e-05, 1.16552895e-06, ...,\n",
       "        0.00000000e+00, 4.21414921e-05, 2.42437585e-05],\n",
       "       [6.97953402e-06, 1.15329500e-04, 2.95293198e-06, ...,\n",
       "        0.00000000e+00, 5.33686870e-05, 2.74985439e-05],\n",
       "       ...,\n",
       "       [3.73017687e-05, 6.57464300e-04, 3.46030501e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.34393991e-05, 5.16415500e-04, 2.42411746e-05, ...,\n",
       "        0.00000000e+00, 9.87277592e-06, 1.45977700e-04],\n",
       "       [6.58817034e-08, 9.67667916e-07, 2.47764632e-08, ...,\n",
       "        0.00000000e+00, 1.33158250e-03, 8.23836230e-03]])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_X_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_X = torch.from_numpy(trn_X_pd.astype(float))\n",
    "trn_y = torch.from_numpy(trn_y_pd.astype(float))\n",
    "\n",
    "val_X = torch.from_numpy(val_X_pd.astype(float))\n",
    "val_y = torch.from_numpy(val_y_pd.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dictionary batch\n",
    "class Dataset(data_utils.Dataset):\n",
    "   \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        return {'X': self.X[idx], 'y': self.y[idx]}\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = Dataset(trn_X, trn_y)\n",
    "trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True, drop_last = True)\n",
    "\n",
    "trn_test_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "val = Dataset(val_X, val_y)\n",
    "val_loader = data_utils.DataLoader(val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X': tensor([[6.5677e-05, 8.3347e-02, 3.8531e-05,  ..., 1.9207e-03, 3.3437e-04,\n",
       "          4.4619e-04],\n",
       "         [1.9899e-05, 2.3116e-03, 0.0000e+00,  ..., 0.0000e+00, 9.3073e-05,\n",
       "          1.6355e-04],\n",
       "         [4.5190e-07, 1.4934e-05, 3.8238e-07,  ..., 0.0000e+00, 5.9395e-04,\n",
       "          3.6635e-03],\n",
       "         [3.8192e-04, 3.8086e-01, 4.2333e-04,  ..., 0.0000e+00, 2.8409e-04,\n",
       "          1.2932e-03],\n",
       "         [1.9966e-05, 7.4559e-06, 1.2918e-05,  ..., 0.0000e+00, 6.3502e-04,\n",
       "          1.8207e-02]], dtype=torch.float64),\n",
       " 'y': tensor([0., 1., 0., 0., 1.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = len(trn_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        h1 = nn.Linear((len(train.columns)-3), 32)\n",
    "        h2 = nn.Linear(32, 16)\n",
    "        h3 = nn.Linear(16, 1)\n",
    "        self.hidden = nn.Sequential(\n",
    "            h1,\n",
    "            nn.ReLU(),\n",
    "            h2,\n",
    "            nn.ReLU(),\n",
    "            h3,\n",
    "        )\n",
    "        if use_cuda:\n",
    "            self.hidden = self.hidden.cuda()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.hidden(x)\n",
    "        return o.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "         \n",
    "        self.layer1 = nn.Sequential(\n",
    "            torch.nn.Linear((len(train.columns)-3), 256, bias=True),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    " \n",
    "        self.layer2 = nn.Sequential(\n",
    "            torch.nn.Linear(256, 128, bias=True),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "    \n",
    "        self.layer3 = nn.Sequential(\n",
    "            torch.nn.Linear(128, 64, bias=True),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    " \n",
    "        self.layer4 = nn.Sequential(\n",
    "            torch.nn.Linear(64, 1, bias=True),\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.layer1(x)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        x_out = self.layer2(x_out)\n",
    "        x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        x_out = self.layer3(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        x_out = self.layer4(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_seq_(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq_, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "        )\n",
    "        self.classifier2 = nn.Sequential(\n",
    "\n",
    "            torch.nn.Linear(100, 100, bias=True),\n",
    "            torch.nn.BatchNorm1d(100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            \n",
    "\n",
    "            #torch.nn.Dropout(0.3)\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(100,1, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[150,200,100,50]\n",
    "#[150,200,100,50,20]\n",
    "\n",
    "class DNN_seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_seq, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear((trn_X_pd.shape[1]), 150, bias=True),\n",
    "            torch.nn.BatchNorm1d(150),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        \n",
    "        self.classifier2 = nn.Sequential(    \n",
    "            torch.nn.Linear(150, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier3 = nn.Sequential(  \n",
    "            torch.nn.Linear(250, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            torch.nn.Linear(250, 250, bias=True),\n",
    "            torch.nn.BatchNorm1d(250),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            torch.nn.Linear(250, 1, bias=True),\n",
    "            #nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        x_out = self.classifier(x)\n",
    "        x_out = self.classifier2(x_out)\n",
    "        x_out = self.classifier3(x_out)\n",
    "        x_out = self.output_layer(x_out)\n",
    "        #x_out = F.dropout(x_out, p=0.5, training=self.training)\n",
    "        return torch.sigmoid(x_out)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN_seq(\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=150, bias=True)\n",
       "    (1): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (classifier2): Sequential(\n",
       "    (0): Linear(in_features=150, out_features=250, bias=True)\n",
       "    (1): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (classifier3): Sequential(\n",
       "    (0): Linear(in_features=250, out_features=250, bias=True)\n",
       "    (1): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=250, out_features=250, bias=True)\n",
       "    (5): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): Linear(in_features=250, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_batches = len(trn_loader) # requier modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_X_pd.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.BCELoss()\n",
    "    num_epochs = 20\n",
    "    \n",
    "    #checkpoint = torch.load(\"./platin_model_save/First_platin_model.pth\")                                                                                  \n",
    "    #model.load_state_dict(checkpoint['model_state_dict'])                                                                                         \n",
    "    #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])                                                                               \n",
    "    #num_epochs = checkpoint['epoch']                                                                                                           \n",
    "    #loss = checkpoint['loss']        \n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        trn_loss_summary = 0.0\n",
    "        correct = 0   # Accuracy\n",
    "\n",
    "        for batch_idx, trn in enumerate(trn_loader):\n",
    "            trn_X, trn_y = trn['X'], trn['y']\n",
    "            if use_cuda:\n",
    "                trn_X, trn_y = trn_X.cuda(), trn_y.cuda()\n",
    "            trn_X, trn_y = Variable(trn_X).float(), Variable(trn_y).float()\n",
    "            optimizer.zero_grad()\n",
    "            trn_pred = model(trn_X)\n",
    "            #trn_pred = trn_pred.type()\n",
    "            #type_as(torch.cuda.IntTensor())\n",
    "            trn_loss = criterion(trn_pred.squeeze(), trn_y)\n",
    "            trn_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            trn_loss_summary += trn_loss\n",
    "        \n",
    "            predicted = torch.max(trn_pred.data, 1)[1] \n",
    "            correct += (predicted == trn_y).sum()\n",
    "            #print(correct)\n",
    "            if batch_idx % 2 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(trn_X), len(trn_loader.dataset), 100.*batch_idx / len(trn_loader), trn_loss.data, float(correct*100) / float(batch_size*(batch_idx+1))))\n",
    "    torch.save({\n",
    "    #'epoch': EPOCHS,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': trn_loss\n",
    "        }, \"./platin_model_save/platin_model_2.pth\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/180 (0%)]\tLoss: 0.776929\t Accuracy:80.000%\n",
      "Epoch : 0 [10/180 (6%)]\tLoss: 0.801617\t Accuracy:80.000%\n",
      "Epoch : 0 [20/180 (11%)]\tLoss: 0.696659\t Accuracy:76.000%\n",
      "Epoch : 0 [30/180 (17%)]\tLoss: 0.769450\t Accuracy:74.286%\n",
      "Epoch : 0 [40/180 (22%)]\tLoss: 0.563943\t Accuracy:75.556%\n",
      "Epoch : 0 [50/180 (28%)]\tLoss: 0.615975\t Accuracy:76.364%\n",
      "Epoch : 0 [60/180 (33%)]\tLoss: 0.621697\t Accuracy:72.308%\n",
      "Epoch : 0 [70/180 (39%)]\tLoss: 0.754056\t Accuracy:68.000%\n",
      "Epoch : 0 [80/180 (44%)]\tLoss: 0.327390\t Accuracy:68.235%\n",
      "Epoch : 0 [90/180 (50%)]\tLoss: 0.497569\t Accuracy:69.474%\n",
      "Epoch : 0 [100/180 (56%)]\tLoss: 0.407298\t Accuracy:72.381%\n",
      "Epoch : 0 [110/180 (61%)]\tLoss: 0.496243\t Accuracy:72.174%\n",
      "Epoch : 0 [120/180 (67%)]\tLoss: 0.654800\t Accuracy:71.200%\n",
      "Epoch : 0 [130/180 (72%)]\tLoss: 0.469441\t Accuracy:70.370%\n",
      "Epoch : 0 [140/180 (78%)]\tLoss: 0.593599\t Accuracy:71.034%\n",
      "Epoch : 0 [150/180 (83%)]\tLoss: 0.512662\t Accuracy:71.613%\n",
      "Epoch : 0 [160/180 (89%)]\tLoss: 0.658217\t Accuracy:70.303%\n",
      "Epoch : 0 [170/180 (94%)]\tLoss: 0.585652\t Accuracy:71.429%\n",
      "Epoch : 1 [0/180 (0%)]\tLoss: 0.903949\t Accuracy:60.000%\n",
      "Epoch : 1 [10/180 (6%)]\tLoss: 0.697220\t Accuracy:73.333%\n",
      "Epoch : 1 [20/180 (11%)]\tLoss: 0.402160\t Accuracy:80.000%\n",
      "Epoch : 1 [30/180 (17%)]\tLoss: 0.556274\t Accuracy:77.143%\n",
      "Epoch : 1 [40/180 (22%)]\tLoss: 1.432797\t Accuracy:71.111%\n",
      "Epoch : 1 [50/180 (28%)]\tLoss: 0.475337\t Accuracy:69.091%\n",
      "Epoch : 1 [60/180 (33%)]\tLoss: 0.630593\t Accuracy:67.692%\n",
      "Epoch : 1 [70/180 (39%)]\tLoss: 1.020620\t Accuracy:69.333%\n",
      "Epoch : 1 [80/180 (44%)]\tLoss: 1.011613\t Accuracy:68.235%\n",
      "Epoch : 1 [90/180 (50%)]\tLoss: 0.270993\t Accuracy:69.474%\n",
      "Epoch : 1 [100/180 (56%)]\tLoss: 0.428284\t Accuracy:71.429%\n",
      "Epoch : 1 [110/180 (61%)]\tLoss: 0.416734\t Accuracy:73.043%\n",
      "Epoch : 1 [120/180 (67%)]\tLoss: 1.083241\t Accuracy:73.600%\n",
      "Epoch : 1 [130/180 (72%)]\tLoss: 0.291450\t Accuracy:74.815%\n",
      "Epoch : 1 [140/180 (78%)]\tLoss: 0.209078\t Accuracy:73.793%\n",
      "Epoch : 1 [150/180 (83%)]\tLoss: 1.271690\t Accuracy:73.548%\n",
      "Epoch : 1 [160/180 (89%)]\tLoss: 0.758246\t Accuracy:73.333%\n",
      "Epoch : 1 [170/180 (94%)]\tLoss: 0.348669\t Accuracy:73.143%\n",
      "Epoch : 2 [0/180 (0%)]\tLoss: 0.924242\t Accuracy:60.000%\n",
      "Epoch : 2 [10/180 (6%)]\tLoss: 0.510799\t Accuracy:73.333%\n",
      "Epoch : 2 [20/180 (11%)]\tLoss: 0.304620\t Accuracy:72.000%\n",
      "Epoch : 2 [30/180 (17%)]\tLoss: 0.936546\t Accuracy:68.571%\n",
      "Epoch : 2 [40/180 (22%)]\tLoss: 0.352651\t Accuracy:66.667%\n",
      "Epoch : 2 [50/180 (28%)]\tLoss: 0.606997\t Accuracy:69.091%\n",
      "Epoch : 2 [60/180 (33%)]\tLoss: 0.240269\t Accuracy:70.769%\n",
      "Epoch : 2 [70/180 (39%)]\tLoss: 0.735420\t Accuracy:69.333%\n",
      "Epoch : 2 [80/180 (44%)]\tLoss: 0.303275\t Accuracy:69.412%\n",
      "Epoch : 2 [90/180 (50%)]\tLoss: 0.651138\t Accuracy:70.526%\n",
      "Epoch : 2 [100/180 (56%)]\tLoss: 0.417096\t Accuracy:71.429%\n",
      "Epoch : 2 [110/180 (61%)]\tLoss: 0.334495\t Accuracy:73.913%\n",
      "Epoch : 2 [120/180 (67%)]\tLoss: 1.105323\t Accuracy:72.800%\n",
      "Epoch : 2 [130/180 (72%)]\tLoss: 0.736569\t Accuracy:73.333%\n",
      "Epoch : 2 [140/180 (78%)]\tLoss: 0.663767\t Accuracy:73.103%\n",
      "Epoch : 2 [150/180 (83%)]\tLoss: 1.227339\t Accuracy:70.968%\n",
      "Epoch : 2 [160/180 (89%)]\tLoss: 0.772224\t Accuracy:70.303%\n",
      "Epoch : 2 [170/180 (94%)]\tLoss: 0.502216\t Accuracy:70.857%\n",
      "Epoch : 3 [0/180 (0%)]\tLoss: 0.471038\t Accuracy:100.000%\n",
      "Epoch : 3 [10/180 (6%)]\tLoss: 0.375399\t Accuracy:100.000%\n",
      "Epoch : 3 [20/180 (11%)]\tLoss: 0.604329\t Accuracy:92.000%\n",
      "Epoch : 3 [30/180 (17%)]\tLoss: 0.280962\t Accuracy:85.714%\n",
      "Epoch : 3 [40/180 (22%)]\tLoss: 0.303475\t Accuracy:86.667%\n",
      "Epoch : 3 [50/180 (28%)]\tLoss: 0.759823\t Accuracy:83.636%\n",
      "Epoch : 3 [60/180 (33%)]\tLoss: 0.783568\t Accuracy:80.000%\n",
      "Epoch : 3 [70/180 (39%)]\tLoss: 0.754683\t Accuracy:76.000%\n",
      "Epoch : 3 [80/180 (44%)]\tLoss: 0.564745\t Accuracy:72.941%\n",
      "Epoch : 3 [90/180 (50%)]\tLoss: 0.672486\t Accuracy:72.632%\n",
      "Epoch : 3 [100/180 (56%)]\tLoss: 0.441770\t Accuracy:74.286%\n",
      "Epoch : 3 [110/180 (61%)]\tLoss: 0.414171\t Accuracy:75.652%\n",
      "Epoch : 3 [120/180 (67%)]\tLoss: 0.640614\t Accuracy:73.600%\n",
      "Epoch : 3 [130/180 (72%)]\tLoss: 0.501965\t Accuracy:72.593%\n",
      "Epoch : 3 [140/180 (78%)]\tLoss: 0.399617\t Accuracy:73.793%\n",
      "Epoch : 3 [150/180 (83%)]\tLoss: 0.308561\t Accuracy:72.258%\n",
      "Epoch : 3 [160/180 (89%)]\tLoss: 0.305426\t Accuracy:72.121%\n",
      "Epoch : 3 [170/180 (94%)]\tLoss: 0.780873\t Accuracy:72.000%\n",
      "Epoch : 4 [0/180 (0%)]\tLoss: 0.725277\t Accuracy:60.000%\n",
      "Epoch : 4 [10/180 (6%)]\tLoss: 0.345297\t Accuracy:73.333%\n",
      "Epoch : 4 [20/180 (11%)]\tLoss: 0.454365\t Accuracy:72.000%\n",
      "Epoch : 4 [30/180 (17%)]\tLoss: 0.484711\t Accuracy:68.571%\n",
      "Epoch : 4 [40/180 (22%)]\tLoss: 0.748372\t Accuracy:71.111%\n",
      "Epoch : 4 [50/180 (28%)]\tLoss: 0.802576\t Accuracy:70.909%\n",
      "Epoch : 4 [60/180 (33%)]\tLoss: 0.924361\t Accuracy:69.231%\n",
      "Epoch : 4 [70/180 (39%)]\tLoss: 0.253702\t Accuracy:70.667%\n",
      "Epoch : 4 [80/180 (44%)]\tLoss: 0.357654\t Accuracy:71.765%\n",
      "Epoch : 4 [90/180 (50%)]\tLoss: 0.597006\t Accuracy:69.474%\n",
      "Epoch : 4 [100/180 (56%)]\tLoss: 0.420934\t Accuracy:71.429%\n",
      "Epoch : 4 [110/180 (61%)]\tLoss: 1.094278\t Accuracy:70.435%\n",
      "Epoch : 4 [120/180 (67%)]\tLoss: 0.686223\t Accuracy:70.400%\n",
      "Epoch : 4 [130/180 (72%)]\tLoss: 0.382742\t Accuracy:69.630%\n",
      "Epoch : 4 [140/180 (78%)]\tLoss: 0.373462\t Accuracy:71.034%\n",
      "Epoch : 4 [150/180 (83%)]\tLoss: 0.293971\t Accuracy:71.613%\n",
      "Epoch : 4 [160/180 (89%)]\tLoss: 0.645313\t Accuracy:70.909%\n",
      "Epoch : 4 [170/180 (94%)]\tLoss: 0.343350\t Accuracy:71.429%\n",
      "Epoch : 5 [0/180 (0%)]\tLoss: 0.548121\t Accuracy:60.000%\n",
      "Epoch : 5 [10/180 (6%)]\tLoss: 1.208833\t Accuracy:46.667%\n",
      "Epoch : 5 [20/180 (11%)]\tLoss: 0.328993\t Accuracy:60.000%\n",
      "Epoch : 5 [30/180 (17%)]\tLoss: 0.517027\t Accuracy:65.714%\n",
      "Epoch : 5 [40/180 (22%)]\tLoss: 0.506605\t Accuracy:71.111%\n",
      "Epoch : 5 [50/180 (28%)]\tLoss: 0.271502\t Accuracy:70.909%\n",
      "Epoch : 5 [60/180 (33%)]\tLoss: 0.486907\t Accuracy:69.231%\n",
      "Epoch : 5 [70/180 (39%)]\tLoss: 0.424141\t Accuracy:66.667%\n",
      "Epoch : 5 [80/180 (44%)]\tLoss: 0.286807\t Accuracy:67.059%\n",
      "Epoch : 5 [90/180 (50%)]\tLoss: 0.560264\t Accuracy:68.421%\n",
      "Epoch : 5 [100/180 (56%)]\tLoss: 0.592140\t Accuracy:70.476%\n",
      "Epoch : 5 [110/180 (61%)]\tLoss: 0.749995\t Accuracy:72.174%\n",
      "Epoch : 5 [120/180 (67%)]\tLoss: 0.253586\t Accuracy:71.200%\n",
      "Epoch : 5 [130/180 (72%)]\tLoss: 0.310021\t Accuracy:70.370%\n",
      "Epoch : 5 [140/180 (78%)]\tLoss: 0.501012\t Accuracy:68.966%\n",
      "Epoch : 5 [150/180 (83%)]\tLoss: 0.366294\t Accuracy:70.323%\n",
      "Epoch : 5 [160/180 (89%)]\tLoss: 0.338733\t Accuracy:70.303%\n",
      "Epoch : 5 [170/180 (94%)]\tLoss: 0.393662\t Accuracy:71.429%\n",
      "Epoch : 6 [0/180 (0%)]\tLoss: 0.377780\t Accuracy:60.000%\n",
      "Epoch : 6 [10/180 (6%)]\tLoss: 0.307867\t Accuracy:66.667%\n",
      "Epoch : 6 [20/180 (11%)]\tLoss: 0.465032\t Accuracy:76.000%\n",
      "Epoch : 6 [30/180 (17%)]\tLoss: 0.489213\t Accuracy:74.286%\n",
      "Epoch : 6 [40/180 (22%)]\tLoss: 0.263268\t Accuracy:75.556%\n",
      "Epoch : 6 [50/180 (28%)]\tLoss: 0.599524\t Accuracy:74.545%\n",
      "Epoch : 6 [60/180 (33%)]\tLoss: 0.259703\t Accuracy:78.462%\n",
      "Epoch : 6 [70/180 (39%)]\tLoss: 0.820685\t Accuracy:76.000%\n",
      "Epoch : 6 [80/180 (44%)]\tLoss: 1.255411\t Accuracy:74.118%\n",
      "Epoch : 6 [90/180 (50%)]\tLoss: 0.477308\t Accuracy:72.632%\n",
      "Epoch : 6 [100/180 (56%)]\tLoss: 0.636202\t Accuracy:70.476%\n",
      "Epoch : 6 [110/180 (61%)]\tLoss: 0.195465\t Accuracy:71.304%\n",
      "Epoch : 6 [120/180 (67%)]\tLoss: 0.160195\t Accuracy:71.200%\n",
      "Epoch : 6 [130/180 (72%)]\tLoss: 0.605218\t Accuracy:71.111%\n",
      "Epoch : 6 [140/180 (78%)]\tLoss: 0.389584\t Accuracy:71.034%\n",
      "Epoch : 6 [150/180 (83%)]\tLoss: 0.479339\t Accuracy:70.323%\n",
      "Epoch : 6 [160/180 (89%)]\tLoss: 0.470456\t Accuracy:70.909%\n",
      "Epoch : 6 [170/180 (94%)]\tLoss: 0.447911\t Accuracy:72.000%\n",
      "Epoch : 7 [0/180 (0%)]\tLoss: 0.224166\t Accuracy:60.000%\n",
      "Epoch : 7 [10/180 (6%)]\tLoss: 1.132433\t Accuracy:73.333%\n",
      "Epoch : 7 [20/180 (11%)]\tLoss: 0.209252\t Accuracy:72.000%\n",
      "Epoch : 7 [30/180 (17%)]\tLoss: 0.579808\t Accuracy:68.571%\n",
      "Epoch : 7 [40/180 (22%)]\tLoss: 0.767008\t Accuracy:68.889%\n",
      "Epoch : 7 [50/180 (28%)]\tLoss: 0.376687\t Accuracy:72.727%\n",
      "Epoch : 7 [60/180 (33%)]\tLoss: 0.349208\t Accuracy:75.385%\n",
      "Epoch : 7 [70/180 (39%)]\tLoss: 0.474183\t Accuracy:76.000%\n",
      "Epoch : 7 [80/180 (44%)]\tLoss: 0.754121\t Accuracy:75.294%\n",
      "Epoch : 7 [90/180 (50%)]\tLoss: 0.239004\t Accuracy:75.789%\n",
      "Epoch : 7 [100/180 (56%)]\tLoss: 0.707257\t Accuracy:71.429%\n",
      "Epoch : 7 [110/180 (61%)]\tLoss: 0.156454\t Accuracy:71.304%\n",
      "Epoch : 7 [120/180 (67%)]\tLoss: 0.424200\t Accuracy:73.600%\n",
      "Epoch : 7 [130/180 (72%)]\tLoss: 0.998137\t Accuracy:73.333%\n",
      "Epoch : 7 [140/180 (78%)]\tLoss: 0.570031\t Accuracy:71.724%\n",
      "Epoch : 7 [150/180 (83%)]\tLoss: 0.636262\t Accuracy:70.323%\n",
      "Epoch : 7 [160/180 (89%)]\tLoss: 0.203372\t Accuracy:70.909%\n",
      "Epoch : 7 [170/180 (94%)]\tLoss: 0.203278\t Accuracy:71.429%\n",
      "Epoch : 8 [0/180 (0%)]\tLoss: 0.357691\t Accuracy:60.000%\n",
      "Epoch : 8 [10/180 (6%)]\tLoss: 0.795293\t Accuracy:60.000%\n",
      "Epoch : 8 [20/180 (11%)]\tLoss: 0.443567\t Accuracy:64.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8 [30/180 (17%)]\tLoss: 0.306748\t Accuracy:68.571%\n",
      "Epoch : 8 [40/180 (22%)]\tLoss: 0.185420\t Accuracy:71.111%\n",
      "Epoch : 8 [50/180 (28%)]\tLoss: 0.471007\t Accuracy:72.727%\n",
      "Epoch : 8 [60/180 (33%)]\tLoss: 0.256661\t Accuracy:72.308%\n",
      "Epoch : 8 [70/180 (39%)]\tLoss: 0.274515\t Accuracy:74.667%\n",
      "Epoch : 8 [80/180 (44%)]\tLoss: 0.561807\t Accuracy:74.118%\n",
      "Epoch : 8 [90/180 (50%)]\tLoss: 0.323444\t Accuracy:71.579%\n",
      "Epoch : 8 [100/180 (56%)]\tLoss: 0.683152\t Accuracy:71.429%\n",
      "Epoch : 8 [110/180 (61%)]\tLoss: 0.569845\t Accuracy:71.304%\n",
      "Epoch : 8 [120/180 (67%)]\tLoss: 0.381507\t Accuracy:72.000%\n",
      "Epoch : 8 [130/180 (72%)]\tLoss: 0.238484\t Accuracy:72.593%\n",
      "Epoch : 8 [140/180 (78%)]\tLoss: 0.253200\t Accuracy:72.414%\n",
      "Epoch : 8 [150/180 (83%)]\tLoss: 0.248830\t Accuracy:71.613%\n",
      "Epoch : 8 [160/180 (89%)]\tLoss: 0.293989\t Accuracy:71.515%\n",
      "Epoch : 8 [170/180 (94%)]\tLoss: 0.649500\t Accuracy:71.429%\n",
      "Epoch : 9 [0/180 (0%)]\tLoss: 0.588557\t Accuracy:40.000%\n",
      "Epoch : 9 [10/180 (6%)]\tLoss: 0.303254\t Accuracy:66.667%\n",
      "Epoch : 9 [20/180 (11%)]\tLoss: 0.590371\t Accuracy:68.000%\n",
      "Epoch : 9 [30/180 (17%)]\tLoss: 0.213538\t Accuracy:71.429%\n",
      "Epoch : 9 [40/180 (22%)]\tLoss: 0.410820\t Accuracy:66.667%\n",
      "Epoch : 9 [50/180 (28%)]\tLoss: 0.527336\t Accuracy:67.273%\n",
      "Epoch : 9 [60/180 (33%)]\tLoss: 0.415736\t Accuracy:64.615%\n",
      "Epoch : 9 [70/180 (39%)]\tLoss: 0.680666\t Accuracy:62.667%\n",
      "Epoch : 9 [80/180 (44%)]\tLoss: 0.241650\t Accuracy:62.353%\n",
      "Epoch : 9 [90/180 (50%)]\tLoss: 0.176049\t Accuracy:63.158%\n",
      "Epoch : 9 [100/180 (56%)]\tLoss: 0.281267\t Accuracy:64.762%\n",
      "Epoch : 9 [110/180 (61%)]\tLoss: 0.518066\t Accuracy:67.826%\n",
      "Epoch : 9 [120/180 (67%)]\tLoss: 0.345723\t Accuracy:68.800%\n",
      "Epoch : 9 [130/180 (72%)]\tLoss: 0.438752\t Accuracy:69.630%\n",
      "Epoch : 9 [140/180 (78%)]\tLoss: 0.903838\t Accuracy:70.345%\n",
      "Epoch : 9 [150/180 (83%)]\tLoss: 0.593411\t Accuracy:70.968%\n",
      "Epoch : 9 [160/180 (89%)]\tLoss: 0.219067\t Accuracy:70.909%\n",
      "Epoch : 9 [170/180 (94%)]\tLoss: 1.287532\t Accuracy:71.429%\n",
      "Epoch : 10 [0/180 (0%)]\tLoss: 0.381042\t Accuracy:100.000%\n",
      "Epoch : 10 [10/180 (6%)]\tLoss: 0.298392\t Accuracy:80.000%\n",
      "Epoch : 10 [20/180 (11%)]\tLoss: 0.495875\t Accuracy:80.000%\n",
      "Epoch : 10 [30/180 (17%)]\tLoss: 0.774690\t Accuracy:77.143%\n",
      "Epoch : 10 [40/180 (22%)]\tLoss: 0.375549\t Accuracy:71.111%\n",
      "Epoch : 10 [50/180 (28%)]\tLoss: 0.223266\t Accuracy:72.727%\n",
      "Epoch : 10 [60/180 (33%)]\tLoss: 0.588387\t Accuracy:70.769%\n",
      "Epoch : 10 [70/180 (39%)]\tLoss: 0.813705\t Accuracy:66.667%\n",
      "Epoch : 10 [80/180 (44%)]\tLoss: 0.274829\t Accuracy:70.588%\n",
      "Epoch : 10 [90/180 (50%)]\tLoss: 0.316694\t Accuracy:72.632%\n",
      "Epoch : 10 [100/180 (56%)]\tLoss: 0.338128\t Accuracy:71.429%\n",
      "Epoch : 10 [110/180 (61%)]\tLoss: 0.616288\t Accuracy:71.304%\n",
      "Epoch : 10 [120/180 (67%)]\tLoss: 0.537373\t Accuracy:72.000%\n",
      "Epoch : 10 [130/180 (72%)]\tLoss: 0.174781\t Accuracy:72.593%\n",
      "Epoch : 10 [140/180 (78%)]\tLoss: 0.299508\t Accuracy:74.483%\n",
      "Epoch : 10 [150/180 (83%)]\tLoss: 0.528837\t Accuracy:73.548%\n",
      "Epoch : 10 [160/180 (89%)]\tLoss: 1.005868\t Accuracy:71.515%\n",
      "Epoch : 10 [170/180 (94%)]\tLoss: 0.153860\t Accuracy:72.571%\n",
      "Epoch : 11 [0/180 (0%)]\tLoss: 0.216646\t Accuracy:60.000%\n",
      "Epoch : 11 [10/180 (6%)]\tLoss: 0.180513\t Accuracy:73.333%\n",
      "Epoch : 11 [20/180 (11%)]\tLoss: 0.177318\t Accuracy:72.000%\n",
      "Epoch : 11 [30/180 (17%)]\tLoss: 1.067358\t Accuracy:74.286%\n",
      "Epoch : 11 [40/180 (22%)]\tLoss: 0.347612\t Accuracy:68.889%\n",
      "Epoch : 11 [50/180 (28%)]\tLoss: 0.261263\t Accuracy:67.273%\n",
      "Epoch : 11 [60/180 (33%)]\tLoss: 0.423692\t Accuracy:70.769%\n",
      "Epoch : 11 [70/180 (39%)]\tLoss: 0.136874\t Accuracy:72.000%\n",
      "Epoch : 11 [80/180 (44%)]\tLoss: 0.349344\t Accuracy:74.118%\n",
      "Epoch : 11 [90/180 (50%)]\tLoss: 0.360612\t Accuracy:74.737%\n",
      "Epoch : 11 [100/180 (56%)]\tLoss: 0.321894\t Accuracy:74.286%\n",
      "Epoch : 11 [110/180 (61%)]\tLoss: 0.555947\t Accuracy:74.783%\n",
      "Epoch : 11 [120/180 (67%)]\tLoss: 0.572984\t Accuracy:73.600%\n",
      "Epoch : 11 [130/180 (72%)]\tLoss: 0.350598\t Accuracy:72.593%\n",
      "Epoch : 11 [140/180 (78%)]\tLoss: 0.472499\t Accuracy:71.724%\n",
      "Epoch : 11 [150/180 (83%)]\tLoss: 0.282293\t Accuracy:73.548%\n",
      "Epoch : 11 [160/180 (89%)]\tLoss: 1.011886\t Accuracy:71.515%\n",
      "Epoch : 11 [170/180 (94%)]\tLoss: 0.368592\t Accuracy:72.000%\n",
      "Epoch : 12 [0/180 (0%)]\tLoss: 0.209530\t Accuracy:80.000%\n",
      "Epoch : 12 [10/180 (6%)]\tLoss: 0.340413\t Accuracy:73.333%\n",
      "Epoch : 12 [20/180 (11%)]\tLoss: 0.139228\t Accuracy:68.000%\n",
      "Epoch : 12 [30/180 (17%)]\tLoss: 0.856641\t Accuracy:65.714%\n",
      "Epoch : 12 [40/180 (22%)]\tLoss: 0.347401\t Accuracy:62.222%\n",
      "Epoch : 12 [50/180 (28%)]\tLoss: 0.193065\t Accuracy:67.273%\n",
      "Epoch : 12 [60/180 (33%)]\tLoss: 0.332999\t Accuracy:70.769%\n",
      "Epoch : 12 [70/180 (39%)]\tLoss: 0.549867\t Accuracy:72.000%\n",
      "Epoch : 12 [80/180 (44%)]\tLoss: 0.705366\t Accuracy:74.118%\n",
      "Epoch : 12 [90/180 (50%)]\tLoss: 0.152208\t Accuracy:74.737%\n",
      "Epoch : 12 [100/180 (56%)]\tLoss: 0.655665\t Accuracy:75.238%\n",
      "Epoch : 12 [110/180 (61%)]\tLoss: 0.446853\t Accuracy:74.783%\n",
      "Epoch : 12 [120/180 (67%)]\tLoss: 0.927602\t Accuracy:72.800%\n",
      "Epoch : 12 [130/180 (72%)]\tLoss: 0.096761\t Accuracy:73.333%\n",
      "Epoch : 12 [140/180 (78%)]\tLoss: 0.248953\t Accuracy:72.414%\n",
      "Epoch : 12 [150/180 (83%)]\tLoss: 0.658714\t Accuracy:72.903%\n",
      "Epoch : 12 [160/180 (89%)]\tLoss: 0.690487\t Accuracy:72.121%\n",
      "Epoch : 12 [170/180 (94%)]\tLoss: 0.295153\t Accuracy:72.000%\n",
      "Epoch : 13 [0/180 (0%)]\tLoss: 0.416639\t Accuracy:100.000%\n",
      "Epoch : 13 [10/180 (6%)]\tLoss: 0.360108\t Accuracy:86.667%\n",
      "Epoch : 13 [20/180 (11%)]\tLoss: 0.566394\t Accuracy:76.000%\n",
      "Epoch : 13 [30/180 (17%)]\tLoss: 0.256623\t Accuracy:71.429%\n",
      "Epoch : 13 [40/180 (22%)]\tLoss: 0.102769\t Accuracy:71.111%\n",
      "Epoch : 13 [50/180 (28%)]\tLoss: 0.432229\t Accuracy:70.909%\n",
      "Epoch : 13 [60/180 (33%)]\tLoss: 0.331433\t Accuracy:73.846%\n",
      "Epoch : 13 [70/180 (39%)]\tLoss: 0.698295\t Accuracy:72.000%\n",
      "Epoch : 13 [80/180 (44%)]\tLoss: 0.186389\t Accuracy:70.588%\n",
      "Epoch : 13 [90/180 (50%)]\tLoss: 0.173333\t Accuracy:71.579%\n",
      "Epoch : 13 [100/180 (56%)]\tLoss: 0.297389\t Accuracy:70.476%\n",
      "Epoch : 13 [110/180 (61%)]\tLoss: 0.149112\t Accuracy:71.304%\n",
      "Epoch : 13 [120/180 (67%)]\tLoss: 0.300685\t Accuracy:72.000%\n",
      "Epoch : 13 [130/180 (72%)]\tLoss: 0.360718\t Accuracy:71.852%\n",
      "Epoch : 13 [140/180 (78%)]\tLoss: 0.487736\t Accuracy:71.724%\n",
      "Epoch : 13 [150/180 (83%)]\tLoss: 0.174083\t Accuracy:71.613%\n",
      "Epoch : 13 [160/180 (89%)]\tLoss: 0.526216\t Accuracy:70.909%\n",
      "Epoch : 13 [170/180 (94%)]\tLoss: 0.603398\t Accuracy:70.857%\n",
      "Epoch : 14 [0/180 (0%)]\tLoss: 0.137269\t Accuracy:80.000%\n",
      "Epoch : 14 [10/180 (6%)]\tLoss: 0.306532\t Accuracy:60.000%\n",
      "Epoch : 14 [20/180 (11%)]\tLoss: 0.347875\t Accuracy:60.000%\n",
      "Epoch : 14 [30/180 (17%)]\tLoss: 0.147857\t Accuracy:60.000%\n",
      "Epoch : 14 [40/180 (22%)]\tLoss: 0.560764\t Accuracy:62.222%\n",
      "Epoch : 14 [50/180 (28%)]\tLoss: 0.343237\t Accuracy:65.455%\n",
      "Epoch : 14 [60/180 (33%)]\tLoss: 0.555761\t Accuracy:67.692%\n",
      "Epoch : 14 [70/180 (39%)]\tLoss: 0.478537\t Accuracy:68.000%\n",
      "Epoch : 14 [80/180 (44%)]\tLoss: 0.478890\t Accuracy:67.059%\n",
      "Epoch : 14 [90/180 (50%)]\tLoss: 0.521105\t Accuracy:69.474%\n",
      "Epoch : 14 [100/180 (56%)]\tLoss: 0.147367\t Accuracy:68.571%\n",
      "Epoch : 14 [110/180 (61%)]\tLoss: 0.244469\t Accuracy:69.565%\n",
      "Epoch : 14 [120/180 (67%)]\tLoss: 0.281298\t Accuracy:68.800%\n",
      "Epoch : 14 [130/180 (72%)]\tLoss: 0.704770\t Accuracy:69.630%\n",
      "Epoch : 14 [140/180 (78%)]\tLoss: 0.363114\t Accuracy:68.966%\n",
      "Epoch : 14 [150/180 (83%)]\tLoss: 0.147352\t Accuracy:70.323%\n",
      "Epoch : 14 [160/180 (89%)]\tLoss: 0.340302\t Accuracy:71.515%\n",
      "Epoch : 14 [170/180 (94%)]\tLoss: 0.432974\t Accuracy:72.000%\n",
      "Epoch : 15 [0/180 (0%)]\tLoss: 0.414420\t Accuracy:60.000%\n",
      "Epoch : 15 [10/180 (6%)]\tLoss: 0.345045\t Accuracy:73.333%\n",
      "Epoch : 15 [20/180 (11%)]\tLoss: 0.353019\t Accuracy:76.000%\n",
      "Epoch : 15 [30/180 (17%)]\tLoss: 0.913245\t Accuracy:68.571%\n",
      "Epoch : 15 [40/180 (22%)]\tLoss: 0.284293\t Accuracy:75.556%\n",
      "Epoch : 15 [50/180 (28%)]\tLoss: 0.737772\t Accuracy:70.909%\n",
      "Epoch : 15 [60/180 (33%)]\tLoss: 0.156958\t Accuracy:69.231%\n",
      "Epoch : 15 [70/180 (39%)]\tLoss: 0.326097\t Accuracy:66.667%\n",
      "Epoch : 15 [80/180 (44%)]\tLoss: 0.267910\t Accuracy:67.059%\n",
      "Epoch : 15 [90/180 (50%)]\tLoss: 0.340627\t Accuracy:69.474%\n",
      "Epoch : 15 [100/180 (56%)]\tLoss: 0.249900\t Accuracy:71.429%\n",
      "Epoch : 15 [110/180 (61%)]\tLoss: 0.236807\t Accuracy:72.174%\n",
      "Epoch : 15 [120/180 (67%)]\tLoss: 0.076092\t Accuracy:73.600%\n",
      "Epoch : 15 [130/180 (72%)]\tLoss: 0.129871\t Accuracy:72.593%\n",
      "Epoch : 15 [140/180 (78%)]\tLoss: 0.363347\t Accuracy:73.103%\n",
      "Epoch : 15 [150/180 (83%)]\tLoss: 0.155284\t Accuracy:72.903%\n",
      "Epoch : 15 [160/180 (89%)]\tLoss: 0.198435\t Accuracy:72.121%\n",
      "Epoch : 15 [170/180 (94%)]\tLoss: 0.478545\t Accuracy:72.571%\n",
      "Epoch : 16 [0/180 (0%)]\tLoss: 0.615022\t Accuracy:40.000%\n",
      "Epoch : 16 [10/180 (6%)]\tLoss: 0.171614\t Accuracy:66.667%\n",
      "Epoch : 16 [20/180 (11%)]\tLoss: 0.823210\t Accuracy:64.000%\n",
      "Epoch : 16 [30/180 (17%)]\tLoss: 0.167730\t Accuracy:65.714%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16 [40/180 (22%)]\tLoss: 2.041943\t Accuracy:57.778%\n",
      "Epoch : 16 [50/180 (28%)]\tLoss: 0.523941\t Accuracy:65.455%\n",
      "Epoch : 16 [60/180 (33%)]\tLoss: 0.372615\t Accuracy:63.077%\n",
      "Epoch : 16 [70/180 (39%)]\tLoss: 0.314646\t Accuracy:64.000%\n",
      "Epoch : 16 [80/180 (44%)]\tLoss: 0.347928\t Accuracy:68.235%\n",
      "Epoch : 16 [90/180 (50%)]\tLoss: 0.128908\t Accuracy:70.526%\n",
      "Epoch : 16 [100/180 (56%)]\tLoss: 0.631151\t Accuracy:69.524%\n",
      "Epoch : 16 [110/180 (61%)]\tLoss: 0.184766\t Accuracy:68.696%\n",
      "Epoch : 16 [120/180 (67%)]\tLoss: 0.259879\t Accuracy:68.800%\n",
      "Epoch : 16 [130/180 (72%)]\tLoss: 0.405108\t Accuracy:69.630%\n",
      "Epoch : 16 [140/180 (78%)]\tLoss: 0.653986\t Accuracy:71.034%\n",
      "Epoch : 16 [150/180 (83%)]\tLoss: 0.166828\t Accuracy:71.613%\n",
      "Epoch : 16 [160/180 (89%)]\tLoss: 0.140924\t Accuracy:71.515%\n",
      "Epoch : 16 [170/180 (94%)]\tLoss: 0.225211\t Accuracy:71.429%\n",
      "Epoch : 17 [0/180 (0%)]\tLoss: 0.425675\t Accuracy:60.000%\n",
      "Epoch : 17 [10/180 (6%)]\tLoss: 0.384020\t Accuracy:66.667%\n",
      "Epoch : 17 [20/180 (11%)]\tLoss: 0.150301\t Accuracy:68.000%\n",
      "Epoch : 17 [30/180 (17%)]\tLoss: 0.770658\t Accuracy:65.714%\n",
      "Epoch : 17 [40/180 (22%)]\tLoss: 0.596694\t Accuracy:68.889%\n",
      "Epoch : 17 [50/180 (28%)]\tLoss: 0.571638\t Accuracy:72.727%\n",
      "Epoch : 17 [60/180 (33%)]\tLoss: 0.218603\t Accuracy:70.769%\n",
      "Epoch : 17 [70/180 (39%)]\tLoss: 0.532509\t Accuracy:70.667%\n",
      "Epoch : 17 [80/180 (44%)]\tLoss: 0.475745\t Accuracy:72.941%\n",
      "Epoch : 17 [90/180 (50%)]\tLoss: 0.330204\t Accuracy:73.684%\n",
      "Epoch : 17 [100/180 (56%)]\tLoss: 0.237442\t Accuracy:73.333%\n",
      "Epoch : 17 [110/180 (61%)]\tLoss: 1.002732\t Accuracy:70.435%\n",
      "Epoch : 17 [120/180 (67%)]\tLoss: 0.314048\t Accuracy:72.000%\n",
      "Epoch : 17 [130/180 (72%)]\tLoss: 0.481861\t Accuracy:72.593%\n",
      "Epoch : 17 [140/180 (78%)]\tLoss: 0.316784\t Accuracy:73.103%\n",
      "Epoch : 17 [150/180 (83%)]\tLoss: 0.508637\t Accuracy:73.548%\n",
      "Epoch : 17 [160/180 (89%)]\tLoss: 0.249646\t Accuracy:72.121%\n",
      "Epoch : 17 [170/180 (94%)]\tLoss: 0.337692\t Accuracy:71.429%\n",
      "Epoch : 18 [0/180 (0%)]\tLoss: 0.160943\t Accuracy:80.000%\n",
      "Epoch : 18 [10/180 (6%)]\tLoss: 0.345349\t Accuracy:86.667%\n",
      "Epoch : 18 [20/180 (11%)]\tLoss: 0.276628\t Accuracy:72.000%\n",
      "Epoch : 18 [30/180 (17%)]\tLoss: 0.300175\t Accuracy:74.286%\n",
      "Epoch : 18 [40/180 (22%)]\tLoss: 0.411553\t Accuracy:80.000%\n",
      "Epoch : 18 [50/180 (28%)]\tLoss: 0.228688\t Accuracy:74.545%\n",
      "Epoch : 18 [60/180 (33%)]\tLoss: 0.256591\t Accuracy:75.385%\n",
      "Epoch : 18 [70/180 (39%)]\tLoss: 0.167587\t Accuracy:74.667%\n",
      "Epoch : 18 [80/180 (44%)]\tLoss: 0.259705\t Accuracy:75.294%\n",
      "Epoch : 18 [90/180 (50%)]\tLoss: 0.337004\t Accuracy:74.737%\n",
      "Epoch : 18 [100/180 (56%)]\tLoss: 1.807946\t Accuracy:73.333%\n",
      "Epoch : 18 [110/180 (61%)]\tLoss: 0.213592\t Accuracy:73.043%\n",
      "Epoch : 18 [120/180 (67%)]\tLoss: 0.456844\t Accuracy:75.200%\n",
      "Epoch : 18 [130/180 (72%)]\tLoss: 0.166133\t Accuracy:74.074%\n",
      "Epoch : 18 [140/180 (78%)]\tLoss: 0.187147\t Accuracy:74.483%\n",
      "Epoch : 18 [150/180 (83%)]\tLoss: 1.053456\t Accuracy:72.903%\n",
      "Epoch : 18 [160/180 (89%)]\tLoss: 1.083489\t Accuracy:70.909%\n",
      "Epoch : 18 [170/180 (94%)]\tLoss: 0.383517\t Accuracy:71.429%\n",
      "Epoch : 19 [0/180 (0%)]\tLoss: 0.701625\t Accuracy:40.000%\n",
      "Epoch : 19 [10/180 (6%)]\tLoss: 0.201620\t Accuracy:66.667%\n",
      "Epoch : 19 [20/180 (11%)]\tLoss: 0.298288\t Accuracy:72.000%\n",
      "Epoch : 19 [30/180 (17%)]\tLoss: 0.528771\t Accuracy:62.857%\n",
      "Epoch : 19 [40/180 (22%)]\tLoss: 0.266287\t Accuracy:64.444%\n",
      "Epoch : 19 [50/180 (28%)]\tLoss: 0.212580\t Accuracy:67.273%\n",
      "Epoch : 19 [60/180 (33%)]\tLoss: 0.668155\t Accuracy:63.077%\n",
      "Epoch : 19 [70/180 (39%)]\tLoss: 0.571951\t Accuracy:58.667%\n",
      "Epoch : 19 [80/180 (44%)]\tLoss: 0.491335\t Accuracy:63.529%\n",
      "Epoch : 19 [90/180 (50%)]\tLoss: 0.346169\t Accuracy:66.316%\n",
      "Epoch : 19 [100/180 (56%)]\tLoss: 0.417259\t Accuracy:69.524%\n",
      "Epoch : 19 [110/180 (61%)]\tLoss: 0.404762\t Accuracy:69.565%\n",
      "Epoch : 19 [120/180 (67%)]\tLoss: 0.186688\t Accuracy:69.600%\n",
      "Epoch : 19 [130/180 (72%)]\tLoss: 0.541530\t Accuracy:71.852%\n",
      "Epoch : 19 [140/180 (78%)]\tLoss: 0.439263\t Accuracy:71.724%\n",
      "Epoch : 19 [150/180 (83%)]\tLoss: 0.324640\t Accuracy:72.903%\n",
      "Epoch : 19 [160/180 (89%)]\tLoss: 0.335496\t Accuracy:71.515%\n",
      "Epoch : 19 [170/180 (94%)]\tLoss: 0.288691\t Accuracy:71.429%\n"
     ]
    }
   ],
   "source": [
    "#model = DNN_seq()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "fit(model, trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Train ********************\n",
      "Loss: 0.4637147784233093, Accuracy: 0.7166666388511658 %\n",
      "**********************************************\n",
      "Train accuracy:0.717\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(trn_test_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        predicted = torch.max(val_pred.data, 1)[1] \n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Train', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(trn_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Train accuracy:{:.3f}\".format(float(correct_val) / (len(trn_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Test ********************\n",
      "Loss: 1.1907775402069092, Accuracy: 0.6285714507102966 %\n",
      "**********************************************\n",
      "Val accuracy:0.629\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(val_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        predicted = torch.max(val_pred.data, 1)[1] \n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(val_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(val_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.396110</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.776959</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.542691</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.377997</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.365426</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.380689</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.145689</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.157259</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.366938</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.315552</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.136705</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.129350</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.310886</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.247672</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.442131</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.017527</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.501568</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004528</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.217284</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.997878</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.728765</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.920346</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.360291</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.438812</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.903256</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.151330</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.474630</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.625851</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.991953</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.270746</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.141884</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.745246</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0            \n",
       "0.396110  0.0\n",
       "0.776959  0.0\n",
       "0.542691  0.0\n",
       "0.377997  0.0\n",
       "0.365426  0.0\n",
       "0.380689  1.0\n",
       "0.145689  1.0\n",
       "0.157259  0.0\n",
       "0.366938  0.0\n",
       "0.315552  0.0\n",
       "0.136705  1.0\n",
       "0.129350  0.0\n",
       "0.310886  1.0\n",
       "0.247672  0.0\n",
       "0.442131  0.0\n",
       "0.017527  0.0\n",
       "0.501568  0.0\n",
       "0.004528  0.0\n",
       "0.217284  0.0\n",
       "0.997878  1.0\n",
       "0.728765  0.0\n",
       "0.920346  0.0\n",
       "0.360291  1.0\n",
       "0.438812  1.0\n",
       "0.903256  0.0\n",
       "0.151330  0.0\n",
       "0.474630  0.0\n",
       "0.625851  1.0\n",
       "0.991953  0.0\n",
       "0.270746  0.0\n",
       "0.141884  1.0\n",
       "0.745246  1.0"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./platin_model_save/First_platin_model.pth\")                                                                                  \n",
    "model.load_state_dict(checkpoint['model_state_dict'])                                                                                         \n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])                                                                               \n",
    "#num_epochs = checkpoint['epoch']                                                                                                           \n",
    "loss = checkpoint['loss']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [5 x 400], m2: [500 x 150] at /opt/conda/conda-bld/pytorch_1570710822989/work/aten/src/TH/generic/THTensorMath.cpp:197",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-942fa3fe5a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_pred\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-259-3584ad21feac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mx_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mx_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [5 x 400], m2: [500 x 150] at /opt/conda/conda-bld/pytorch_1570710822989/work/aten/src/TH/generic/THTensorMath.cpp:197"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "predict = []\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(val_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        for i in val_pred:\n",
    "            predict.append(i.numpy())\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "\n",
    "        val_loss = criterion(val_pred, val_y.unsqueeze(1))\n",
    "        val_loss_summary += val_loss\n",
    "        predicted = torch.max(val_pred.data, 1)[1] \n",
    "        correct_val += torch.sum(predicted == val_y).item()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(val_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(val_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1228],\n",
       "        [0.0049]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000213</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.587282</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.206532</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.767732</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000056</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.826447</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.965310</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000252</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.451954</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.036931</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.311384</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.880071</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.939436</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.316955</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.284048</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.724537</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005250</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.327553</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.552429</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.422379</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.129107</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.556009</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.036826</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.911376</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001089</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.777907</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.017233</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.097123</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.034860</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.122783</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004913</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0            \n",
       "0.000213  0.0\n",
       "0.587282  0.0\n",
       "0.206532  0.0\n",
       "0.767732  0.0\n",
       "0.000056  0.0\n",
       "0.826447  0.0\n",
       "0.965310  1.0\n",
       "0.000252  0.0\n",
       "0.451954  0.0\n",
       "0.036931  0.0\n",
       "0.311384  0.0\n",
       "0.880071  0.0\n",
       "0.939436  0.0\n",
       "0.316955  1.0\n",
       "0.284048  1.0\n",
       "0.724537  0.0\n",
       "0.005250  0.0\n",
       "0.327553  0.0\n",
       "0.552429  0.0\n",
       "0.422379  1.0\n",
       "0.129107  0.0\n",
       "0.556009  1.0\n",
       "0.036826  0.0\n",
       "0.911376  0.0\n",
       "0.001089  0.0\n",
       "0.777907  0.0\n",
       "0.017233  1.0\n",
       "0.097123  0.0\n",
       "0.000001  0.0\n",
       "0.034860  0.0\n",
       "0.122783  0.0\n",
       "0.004913  0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ = pd.DataFrame(predict)\n",
    "\n",
    "predict_.iloc[:,0]\n",
    "\n",
    "pd.DataFrame(val_y_pd, predict_.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn_loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f2559e346f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_loss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"trn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trn_loss_list' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,9))\n",
    "x_range = range(len(trn_loss_list))\n",
    "plt.plot(x_range, trn_loss_list, label=\"trn\")\n",
    "plt.plot(x_range, val_loss_list, label=\"val\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"training steps\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결론적으로 이미 잘 훈련된 모델이 있고, 특히 해당 모델과 유사한 문제를 해결시 transfer learining을 사용합니다.\n",
    "실질적 조언\n",
    "새로 훈련할 데이터가 적지만 original 데이터와 유사할 경우\n",
    "\n",
    "데이터의 양이 적어 fine-tune (전체 모델에 대해서 backpropagation을 진행하는 것) 은 over-fitting의 위험이 있기에 하지 않습니다.\n",
    "새로 학습할 데이터는 original 데이터와 유사하기 때문에 이 경우 최종 linear classfier 레이어만 학습을 합니다.\n",
    "새로 훈련할 데이터가 매우 많으며 original 데이터와 유사할 경우\n",
    "\n",
    "새로 학습할 데이터의 양이 많다는 것은 over-fitting의 위험이 낮다는 뜻이므로, 전체 레이어에 대해서 fine-tune을 합니다.\n",
    "새로 훈련할 데이터가 적으며 original 데이터와 다른 경우\n",
    "\n",
    "데이터의 양이 적기 때문에 최종 단계의 linear classifier 레이어를 학습하는 것이 좋을 것입니다. 반면서 데이터가 서로 다르기 때문에 거의 마지막부분 (the top of the network)만 학습하는 것은 좋지 않습니다. 서로 상충이 되는데.. 이 경우에는 네트워크 초기 부분 어딘가 activation 이후에 특정 레이어를 학습시키는게 좋습니다.\n",
    "새로 훈련할 데이터가 많지만 original 데이터와와 다른 경우\n",
    "\n",
    "데이터가 많기 때문에 아예 새로운 ConvNet을 만들수도 있지만, 실적적으로 transfer learning이 더 효율이 좋습니다. 전체 네트워크에 대해서 fine-tune을 해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = DNN_seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.classifier = model_2.classifier    \n",
    "model.classifier2 = model_2.classifier2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/171 (0%)]\tLoss: 0.746858\t Accuracy:50.000%\n",
      "Epoch : 0 [32/171 (18%)]\tLoss: 0.662493\t Accuracy:60.417%\n",
      "Epoch : 0 [64/171 (36%)]\tLoss: 0.704260\t Accuracy:60.000%\n",
      "Epoch : 0 [96/171 (55%)]\tLoss: 0.674394\t Accuracy:66.071%\n",
      "Epoch : 0 [128/171 (73%)]\tLoss: 0.722818\t Accuracy:67.361%\n",
      "Epoch : 0 [110/171 (91%)]\tLoss: 0.599336\t Accuracy:65.909%\n",
      "Epoch : 1 [0/171 (0%)]\tLoss: 0.575366\t Accuracy:87.500%\n",
      "Epoch : 1 [32/171 (18%)]\tLoss: 0.667310\t Accuracy:70.833%\n",
      "Epoch : 1 [64/171 (36%)]\tLoss: 0.673750\t Accuracy:68.750%\n",
      "Epoch : 1 [96/171 (55%)]\tLoss: 0.751240\t Accuracy:67.857%\n",
      "Epoch : 1 [128/171 (73%)]\tLoss: 0.740712\t Accuracy:67.361%\n",
      "Epoch : 1 [110/171 (91%)]\tLoss: 0.710288\t Accuracy:65.909%\n",
      "Epoch : 2 [0/171 (0%)]\tLoss: 0.641428\t Accuracy:62.500%\n",
      "Epoch : 2 [32/171 (18%)]\tLoss: 0.618767\t Accuracy:68.750%\n",
      "Epoch : 2 [64/171 (36%)]\tLoss: 0.619703\t Accuracy:65.000%\n",
      "Epoch : 2 [96/171 (55%)]\tLoss: 0.579154\t Accuracy:65.179%\n",
      "Epoch : 2 [128/171 (73%)]\tLoss: 0.667362\t Accuracy:66.667%\n",
      "Epoch : 2 [110/171 (91%)]\tLoss: 0.572492\t Accuracy:65.909%\n",
      "Epoch : 3 [0/171 (0%)]\tLoss: 0.709065\t Accuracy:75.000%\n",
      "Epoch : 3 [32/171 (18%)]\tLoss: 0.596966\t Accuracy:70.833%\n",
      "Epoch : 3 [64/171 (36%)]\tLoss: 0.615786\t Accuracy:72.500%\n",
      "Epoch : 3 [96/171 (55%)]\tLoss: 0.585047\t Accuracy:68.750%\n",
      "Epoch : 3 [128/171 (73%)]\tLoss: 0.710601\t Accuracy:70.139%\n",
      "Epoch : 3 [110/171 (91%)]\tLoss: 0.893020\t Accuracy:65.909%\n",
      "Epoch : 4 [0/171 (0%)]\tLoss: 0.663931\t Accuracy:68.750%\n",
      "Epoch : 4 [32/171 (18%)]\tLoss: 0.728086\t Accuracy:60.417%\n",
      "Epoch : 4 [64/171 (36%)]\tLoss: 0.655770\t Accuracy:62.500%\n",
      "Epoch : 4 [96/171 (55%)]\tLoss: 0.606156\t Accuracy:65.179%\n",
      "Epoch : 4 [128/171 (73%)]\tLoss: 0.622089\t Accuracy:66.667%\n",
      "Epoch : 4 [110/171 (91%)]\tLoss: 0.579138\t Accuracy:65.909%\n",
      "Epoch : 5 [0/171 (0%)]\tLoss: 0.675125\t Accuracy:68.750%\n",
      "Epoch : 5 [32/171 (18%)]\tLoss: 0.662640\t Accuracy:64.583%\n",
      "Epoch : 5 [64/171 (36%)]\tLoss: 0.550371\t Accuracy:71.250%\n",
      "Epoch : 5 [96/171 (55%)]\tLoss: 0.596231\t Accuracy:69.643%\n",
      "Epoch : 5 [128/171 (73%)]\tLoss: 0.657763\t Accuracy:69.444%\n",
      "Epoch : 5 [110/171 (91%)]\tLoss: 0.628837\t Accuracy:65.909%\n",
      "Epoch : 6 [0/171 (0%)]\tLoss: 0.709476\t Accuracy:62.500%\n",
      "Epoch : 6 [32/171 (18%)]\tLoss: 0.679773\t Accuracy:72.917%\n",
      "Epoch : 6 [64/171 (36%)]\tLoss: 0.579446\t Accuracy:67.500%\n",
      "Epoch : 6 [96/171 (55%)]\tLoss: 0.582037\t Accuracy:68.750%\n",
      "Epoch : 6 [128/171 (73%)]\tLoss: 0.705310\t Accuracy:67.361%\n",
      "Epoch : 6 [110/171 (91%)]\tLoss: 0.729313\t Accuracy:65.909%\n",
      "Epoch : 7 [0/171 (0%)]\tLoss: 0.688270\t Accuracy:62.500%\n",
      "Epoch : 7 [32/171 (18%)]\tLoss: 0.753611\t Accuracy:68.750%\n",
      "Epoch : 7 [64/171 (36%)]\tLoss: 0.588925\t Accuracy:62.500%\n",
      "Epoch : 7 [96/171 (55%)]\tLoss: 0.562787\t Accuracy:65.179%\n",
      "Epoch : 7 [128/171 (73%)]\tLoss: 0.592404\t Accuracy:66.667%\n",
      "Epoch : 7 [110/171 (91%)]\tLoss: 0.673879\t Accuracy:65.909%\n",
      "Epoch : 8 [0/171 (0%)]\tLoss: 0.641790\t Accuracy:81.250%\n",
      "Epoch : 8 [32/171 (18%)]\tLoss: 0.659684\t Accuracy:68.750%\n",
      "Epoch : 8 [64/171 (36%)]\tLoss: 0.469823\t Accuracy:75.000%\n",
      "Epoch : 8 [96/171 (55%)]\tLoss: 0.649886\t Accuracy:68.750%\n",
      "Epoch : 8 [128/171 (73%)]\tLoss: 0.584355\t Accuracy:68.750%\n",
      "Epoch : 8 [110/171 (91%)]\tLoss: 0.712025\t Accuracy:65.909%\n",
      "Epoch : 9 [0/171 (0%)]\tLoss: 0.726692\t Accuracy:56.250%\n",
      "Epoch : 9 [32/171 (18%)]\tLoss: 0.564370\t Accuracy:62.500%\n",
      "Epoch : 9 [64/171 (36%)]\tLoss: 0.594889\t Accuracy:58.750%\n",
      "Epoch : 9 [96/171 (55%)]\tLoss: 0.599691\t Accuracy:63.393%\n",
      "Epoch : 9 [128/171 (73%)]\tLoss: 0.662696\t Accuracy:65.972%\n",
      "Epoch : 9 [110/171 (91%)]\tLoss: 0.608411\t Accuracy:65.909%\n"
     ]
    }
   ],
   "source": [
    "#model = DNN_seq()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "fit(model, trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Test ********************\n",
      "Loss: 0.5934396982192993, Accuracy: 0.7291666865348816 %\n",
      "**********************************************\n",
      "Val accuracy:0.729\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#predict = []\n",
    "#y_val = val_y\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(val_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model(val_X)\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        val_loss = criterion(val_pred, val_y)\n",
    "        val_loss_summary += val_loss\n",
    "        predicted = torch.max(val_pred.data, 1)[1] \n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(val_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(val_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeClassifier\n",
    "# VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# ensemble 할 model 정의\n",
    "models = [\n",
    "    ('ada', AdaBoostClassifier()),\n",
    "    ('bc', BaggingClassifier()),\n",
    "    ('etc',ExtraTreesClassifier()),\n",
    "    ('gbc', GradientBoostingClassifier()),\n",
    "    ('rfc', RandomForestClassifier()),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('xgb', XGBClassifier()),\n",
    "    ('lgbm', LGBMClassifier()),\n",
    "    ('dtc', DecisionTreeClassifier()),\n",
    "    ('lr', LogisticRegressionCV()),\n",
    "    ('ridge', RidgeClassifier()),\n",
    "]\n",
    "\n",
    "# hard vote\n",
    "hard_vote  = VotingClassifier(models, voting='hard')\n",
    "hard_vote_cv = cross_validate(hard_vote, x_train, y_train, cv=k_fold)\n",
    "hard_vote.fit(x_train, y_train)\n",
    "\n",
    "# soft vote\n",
    "soft_vote  = VotingClassifier(models, voting='soft')\n",
    "soft_vote_cv = cross_validate(soft_vote, x_train, y_train, cv=k_fold)\n",
    "soft_vote.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/171 (0%)]\tLoss: 0.935273\t Accuracy:68.750%\n",
      "Epoch : 0 [32/171 (18%)]\tLoss: 0.791408\t Accuracy:70.833%\n",
      "Epoch : 0 [64/171 (36%)]\tLoss: 0.752347\t Accuracy:68.750%\n",
      "Epoch : 0 [96/171 (55%)]\tLoss: 0.723812\t Accuracy:63.393%\n",
      "Epoch : 0 [128/171 (73%)]\tLoss: 0.811310\t Accuracy:65.972%\n",
      "Epoch : 0 [110/171 (91%)]\tLoss: 0.819974\t Accuracy:65.909%\n",
      "Epoch : 1 [0/171 (0%)]\tLoss: 0.823073\t Accuracy:62.500%\n",
      "Epoch : 1 [32/171 (18%)]\tLoss: 0.663486\t Accuracy:64.583%\n",
      "Epoch : 1 [64/171 (36%)]\tLoss: 0.554099\t Accuracy:66.250%\n",
      "Epoch : 1 [96/171 (55%)]\tLoss: 0.667068\t Accuracy:66.071%\n",
      "Epoch : 1 [128/171 (73%)]\tLoss: 0.624170\t Accuracy:65.278%\n",
      "Epoch : 1 [110/171 (91%)]\tLoss: 0.637554\t Accuracy:65.909%\n",
      "Epoch : 2 [0/171 (0%)]\tLoss: 0.651228\t Accuracy:75.000%\n",
      "Epoch : 2 [32/171 (18%)]\tLoss: 0.534523\t Accuracy:81.250%\n",
      "Epoch : 2 [64/171 (36%)]\tLoss: 0.607727\t Accuracy:71.250%\n",
      "Epoch : 2 [96/171 (55%)]\tLoss: 0.625725\t Accuracy:69.643%\n",
      "Epoch : 2 [128/171 (73%)]\tLoss: 0.518599\t Accuracy:68.750%\n",
      "Epoch : 2 [110/171 (91%)]\tLoss: 0.623615\t Accuracy:65.909%\n",
      "Epoch : 3 [0/171 (0%)]\tLoss: 0.721605\t Accuracy:62.500%\n",
      "Epoch : 3 [32/171 (18%)]\tLoss: 0.700559\t Accuracy:62.500%\n",
      "Epoch : 3 [64/171 (36%)]\tLoss: 0.640351\t Accuracy:62.500%\n",
      "Epoch : 3 [96/171 (55%)]\tLoss: 0.522688\t Accuracy:65.179%\n",
      "Epoch : 3 [128/171 (73%)]\tLoss: 0.591321\t Accuracy:67.361%\n",
      "Epoch : 3 [110/171 (91%)]\tLoss: 0.585958\t Accuracy:65.909%\n",
      "Epoch : 4 [0/171 (0%)]\tLoss: 0.535764\t Accuracy:68.750%\n",
      "Epoch : 4 [32/171 (18%)]\tLoss: 0.641071\t Accuracy:66.667%\n",
      "Epoch : 4 [64/171 (36%)]\tLoss: 0.745152\t Accuracy:63.750%\n",
      "Epoch : 4 [96/171 (55%)]\tLoss: 0.596616\t Accuracy:66.071%\n",
      "Epoch : 4 [128/171 (73%)]\tLoss: 0.489455\t Accuracy:68.750%\n",
      "Epoch : 4 [110/171 (91%)]\tLoss: 1.087884\t Accuracy:65.909%\n",
      "Epoch : 5 [0/171 (0%)]\tLoss: 0.492926\t Accuracy:81.250%\n",
      "Epoch : 5 [32/171 (18%)]\tLoss: 0.597117\t Accuracy:66.667%\n",
      "Epoch : 5 [64/171 (36%)]\tLoss: 0.585361\t Accuracy:70.000%\n",
      "Epoch : 5 [96/171 (55%)]\tLoss: 0.607225\t Accuracy:68.750%\n",
      "Epoch : 5 [128/171 (73%)]\tLoss: 0.816338\t Accuracy:66.667%\n",
      "Epoch : 5 [110/171 (91%)]\tLoss: 0.549977\t Accuracy:65.909%\n",
      "Epoch : 6 [0/171 (0%)]\tLoss: 0.777337\t Accuracy:50.000%\n",
      "Epoch : 6 [32/171 (18%)]\tLoss: 0.587489\t Accuracy:62.500%\n",
      "Epoch : 6 [64/171 (36%)]\tLoss: 0.539594\t Accuracy:66.250%\n",
      "Epoch : 6 [96/171 (55%)]\tLoss: 0.654489\t Accuracy:65.179%\n",
      "Epoch : 6 [128/171 (73%)]\tLoss: 0.592911\t Accuracy:65.972%\n",
      "Epoch : 6 [110/171 (91%)]\tLoss: 0.484829\t Accuracy:65.909%\n",
      "Epoch : 7 [0/171 (0%)]\tLoss: 0.581097\t Accuracy:62.500%\n",
      "Epoch : 7 [32/171 (18%)]\tLoss: 0.598890\t Accuracy:66.667%\n",
      "Epoch : 7 [64/171 (36%)]\tLoss: 0.490318\t Accuracy:72.500%\n",
      "Epoch : 7 [96/171 (55%)]\tLoss: 0.669338\t Accuracy:71.429%\n",
      "Epoch : 7 [128/171 (73%)]\tLoss: 0.590307\t Accuracy:69.444%\n",
      "Epoch : 7 [110/171 (91%)]\tLoss: 0.956334\t Accuracy:65.909%\n",
      "Epoch : 8 [0/171 (0%)]\tLoss: 0.554228\t Accuracy:68.750%\n",
      "Epoch : 8 [32/171 (18%)]\tLoss: 0.985561\t Accuracy:64.583%\n",
      "Epoch : 8 [64/171 (36%)]\tLoss: 0.583143\t Accuracy:65.000%\n",
      "Epoch : 8 [96/171 (55%)]\tLoss: 0.484694\t Accuracy:70.536%\n",
      "Epoch : 8 [128/171 (73%)]\tLoss: 0.619994\t Accuracy:68.750%\n",
      "Epoch : 8 [110/171 (91%)]\tLoss: 0.591878\t Accuracy:65.909%\n",
      "Epoch : 9 [0/171 (0%)]\tLoss: 0.595703\t Accuracy:62.500%\n",
      "Epoch : 9 [32/171 (18%)]\tLoss: 0.504482\t Accuracy:68.750%\n",
      "Epoch : 9 [64/171 (36%)]\tLoss: 0.598189\t Accuracy:67.500%\n",
      "Epoch : 9 [96/171 (55%)]\tLoss: 0.609455\t Accuracy:67.857%\n",
      "Epoch : 9 [128/171 (73%)]\tLoss: 0.594306\t Accuracy:67.361%\n",
      "Epoch : 9 [110/171 (91%)]\tLoss: 0.475993\t Accuracy:65.909%\n"
     ]
    }
   ],
   "source": [
    "model_1 = DNN_seq_()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    model_1 = model_1.cuda()\n",
    "    \n",
    "fit(model_1, trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/171 (0%)]\tLoss: 0.745150\t Accuracy:56.250%\n",
      "Epoch : 0 [32/171 (18%)]\tLoss: 0.593750\t Accuracy:70.833%\n",
      "Epoch : 0 [64/171 (36%)]\tLoss: 0.609681\t Accuracy:72.500%\n",
      "Epoch : 0 [96/171 (55%)]\tLoss: 0.811276\t Accuracy:70.536%\n",
      "Epoch : 0 [128/171 (73%)]\tLoss: 0.909858\t Accuracy:68.750%\n",
      "Epoch : 0 [110/171 (91%)]\tLoss: 0.555978\t Accuracy:65.909%\n",
      "Epoch : 1 [0/171 (0%)]\tLoss: 0.671668\t Accuracy:62.500%\n",
      "Epoch : 1 [32/171 (18%)]\tLoss: 0.751559\t Accuracy:60.417%\n",
      "Epoch : 1 [64/171 (36%)]\tLoss: 0.629498\t Accuracy:66.250%\n",
      "Epoch : 1 [96/171 (55%)]\tLoss: 0.660346\t Accuracy:67.857%\n",
      "Epoch : 1 [128/171 (73%)]\tLoss: 0.670158\t Accuracy:68.056%\n",
      "Epoch : 1 [110/171 (91%)]\tLoss: 0.560989\t Accuracy:65.909%\n",
      "Epoch : 2 [0/171 (0%)]\tLoss: 0.624824\t Accuracy:68.750%\n",
      "Epoch : 2 [32/171 (18%)]\tLoss: 0.593675\t Accuracy:70.833%\n",
      "Epoch : 2 [64/171 (36%)]\tLoss: 0.510769\t Accuracy:67.500%\n",
      "Epoch : 2 [96/171 (55%)]\tLoss: 0.542457\t Accuracy:65.179%\n",
      "Epoch : 2 [128/171 (73%)]\tLoss: 0.449139\t Accuracy:68.056%\n",
      "Epoch : 2 [110/171 (91%)]\tLoss: 0.709045\t Accuracy:65.909%\n",
      "Epoch : 3 [0/171 (0%)]\tLoss: 0.510405\t Accuracy:81.250%\n",
      "Epoch : 3 [32/171 (18%)]\tLoss: 0.566522\t Accuracy:75.000%\n",
      "Epoch : 3 [64/171 (36%)]\tLoss: 0.568372\t Accuracy:73.750%\n",
      "Epoch : 3 [96/171 (55%)]\tLoss: 0.822826\t Accuracy:68.750%\n",
      "Epoch : 3 [128/171 (73%)]\tLoss: 0.632761\t Accuracy:68.056%\n",
      "Epoch : 3 [110/171 (91%)]\tLoss: 0.728441\t Accuracy:65.909%\n",
      "Epoch : 4 [0/171 (0%)]\tLoss: 0.511926\t Accuracy:81.250%\n",
      "Epoch : 4 [32/171 (18%)]\tLoss: 0.588146\t Accuracy:72.917%\n",
      "Epoch : 4 [64/171 (36%)]\tLoss: 0.601966\t Accuracy:68.750%\n",
      "Epoch : 4 [96/171 (55%)]\tLoss: 0.555080\t Accuracy:71.429%\n",
      "Epoch : 4 [128/171 (73%)]\tLoss: 0.604517\t Accuracy:69.444%\n",
      "Epoch : 4 [110/171 (91%)]\tLoss: 0.809859\t Accuracy:65.909%\n",
      "Epoch : 5 [0/171 (0%)]\tLoss: 0.629632\t Accuracy:62.500%\n",
      "Epoch : 5 [32/171 (18%)]\tLoss: 0.562846\t Accuracy:77.083%\n",
      "Epoch : 5 [64/171 (36%)]\tLoss: 0.527351\t Accuracy:70.000%\n",
      "Epoch : 5 [96/171 (55%)]\tLoss: 0.754989\t Accuracy:68.750%\n",
      "Epoch : 5 [128/171 (73%)]\tLoss: 0.674207\t Accuracy:68.056%\n",
      "Epoch : 5 [110/171 (91%)]\tLoss: 0.581754\t Accuracy:65.909%\n",
      "Epoch : 6 [0/171 (0%)]\tLoss: 0.519321\t Accuracy:75.000%\n",
      "Epoch : 6 [32/171 (18%)]\tLoss: 0.661274\t Accuracy:68.750%\n",
      "Epoch : 6 [64/171 (36%)]\tLoss: 0.487016\t Accuracy:70.000%\n",
      "Epoch : 6 [96/171 (55%)]\tLoss: 0.697098\t Accuracy:66.071%\n",
      "Epoch : 6 [128/171 (73%)]\tLoss: 0.612715\t Accuracy:65.972%\n",
      "Epoch : 6 [110/171 (91%)]\tLoss: 0.501077\t Accuracy:65.909%\n",
      "Epoch : 7 [0/171 (0%)]\tLoss: 0.706766\t Accuracy:62.500%\n",
      "Epoch : 7 [32/171 (18%)]\tLoss: 0.713934\t Accuracy:64.583%\n",
      "Epoch : 7 [64/171 (36%)]\tLoss: 0.643361\t Accuracy:63.750%\n",
      "Epoch : 7 [96/171 (55%)]\tLoss: 0.527158\t Accuracy:67.857%\n",
      "Epoch : 7 [128/171 (73%)]\tLoss: 0.764433\t Accuracy:65.972%\n",
      "Epoch : 7 [110/171 (91%)]\tLoss: 0.495314\t Accuracy:65.909%\n",
      "Epoch : 8 [0/171 (0%)]\tLoss: 0.657935\t Accuracy:75.000%\n",
      "Epoch : 8 [32/171 (18%)]\tLoss: 0.593164\t Accuracy:70.833%\n",
      "Epoch : 8 [64/171 (36%)]\tLoss: 0.572450\t Accuracy:67.500%\n",
      "Epoch : 8 [96/171 (55%)]\tLoss: 0.509525\t Accuracy:71.429%\n",
      "Epoch : 8 [128/171 (73%)]\tLoss: 0.577141\t Accuracy:70.139%\n",
      "Epoch : 8 [110/171 (91%)]\tLoss: 0.661615\t Accuracy:65.909%\n",
      "Epoch : 9 [0/171 (0%)]\tLoss: 0.616295\t Accuracy:62.500%\n",
      "Epoch : 9 [32/171 (18%)]\tLoss: 0.658520\t Accuracy:66.667%\n",
      "Epoch : 9 [64/171 (36%)]\tLoss: 0.734764\t Accuracy:71.250%\n",
      "Epoch : 9 [96/171 (55%)]\tLoss: 0.587277\t Accuracy:66.964%\n",
      "Epoch : 9 [128/171 (73%)]\tLoss: 0.617130\t Accuracy:67.361%\n",
      "Epoch : 9 [110/171 (91%)]\tLoss: 0.577146\t Accuracy:65.909%\n"
     ]
    }
   ],
   "source": [
    "model_2 = DNN_seq_()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    model_2 = model_2.cuda()\n",
    "    \n",
    "fit(model_2, trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Test ********************\n",
      "Loss: 0.5453603863716125, Accuracy: 0.7291666865348816 %\n",
      "**********************************************\n",
      "Val accuracy:0.729\n"
     ]
    }
   ],
   "source": [
    "model_1.eval()\n",
    "predict_1 = []\n",
    "#y_val = val_y\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(val_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model_1(val_X)\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        for i in val_pred:\n",
    "            predict_1.append(i.numpy())\n",
    "        val_loss = criterion(val_pred, val_y)\n",
    "        val_loss_summary += val_loss\n",
    "        predicted = torch.max(val_pred.data, 1)[1] \n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(val_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(val_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Test ********************\n",
      "Loss: 0.586574375629425, Accuracy: 0.7291666865348816 %\n",
      "**********************************************\n",
      "Val accuracy:0.729\n"
     ]
    }
   ],
   "source": [
    "model_2.eval()\n",
    "predict_2 = []\n",
    "#y_val = val_y\n",
    "\n",
    "correct_val = 0.\n",
    "with torch.no_grad():\n",
    "    val_loss_summary = 0.0\n",
    "    for j, val in enumerate(val_loader):\n",
    "        val_X, val_y = val['X'], val['y']\n",
    "        if use_cuda:\n",
    "            val_X, val_y = val_X.cuda(), val_y.cuda()\n",
    "        val_X, val_y = Variable(val_X).float(), Variable(val_y).float()\n",
    "        val_pred = model_2(val_X)\n",
    "        val_pred = val_pred.type_as(torch.FloatTensor())\n",
    "        for i in val_pred:\n",
    "            predict_2.append(i.numpy())\n",
    "        val_loss = criterion(val_pred, val_y)\n",
    "        val_loss_summary += val_loss\n",
    "        predicted = torch.max(val_pred.data, 1)[1] \n",
    "        correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(val_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(val_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.39712372], dtype=float32),\n",
       " array([0.20998392], dtype=float32),\n",
       " array([0.32124352], dtype=float32),\n",
       " array([0.34580824], dtype=float32),\n",
       " array([0.43426463], dtype=float32),\n",
       " array([0.43412134], dtype=float32),\n",
       " array([0.39131775], dtype=float32),\n",
       " array([0.38226905], dtype=float32),\n",
       " array([0.42771617], dtype=float32),\n",
       " array([0.2733672], dtype=float32),\n",
       " array([0.42271107], dtype=float32),\n",
       " array([0.4628345], dtype=float32),\n",
       " array([0.4519838], dtype=float32),\n",
       " array([0.3947924], dtype=float32),\n",
       " array([0.39574006], dtype=float32),\n",
       " array([0.4404809], dtype=float32),\n",
       " array([0.3974393], dtype=float32),\n",
       " array([0.48102662], dtype=float32),\n",
       " array([0.42520103], dtype=float32),\n",
       " array([0.43733662], dtype=float32),\n",
       " array([0.3043311], dtype=float32),\n",
       " array([0.4567577], dtype=float32),\n",
       " array([0.36690694], dtype=float32),\n",
       " array([0.38817948], dtype=float32),\n",
       " array([0.5215086], dtype=float32),\n",
       " array([0.4337628], dtype=float32),\n",
       " array([0.40996504], dtype=float32),\n",
       " array([0.6179651], dtype=float32),\n",
       " array([0.06799946], dtype=float32),\n",
       " array([0.35044378], dtype=float32),\n",
       " array([0.4207713], dtype=float32),\n",
       " array([0.24543233], dtype=float32),\n",
       " array([0.31436154], dtype=float32),\n",
       " array([0.32930988], dtype=float32),\n",
       " array([0.24549559], dtype=float32),\n",
       " array([0.42242727], dtype=float32),\n",
       " array([0.08231714], dtype=float32),\n",
       " array([0.4540262], dtype=float32),\n",
       " array([0.18898232], dtype=float32),\n",
       " array([0.4693117], dtype=float32),\n",
       " array([0.3819803], dtype=float32),\n",
       " array([0.41919783], dtype=float32),\n",
       " array([0.35521805], dtype=float32)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.40936574], dtype=float32),\n",
       " array([0.30449998], dtype=float32),\n",
       " array([0.37039232], dtype=float32),\n",
       " array([0.37293124], dtype=float32),\n",
       " array([0.45267642], dtype=float32),\n",
       " array([0.44899222], dtype=float32),\n",
       " array([0.41215253], dtype=float32),\n",
       " array([0.40887272], dtype=float32),\n",
       " array([0.4442977], dtype=float32),\n",
       " array([0.39285985], dtype=float32),\n",
       " array([0.4360027], dtype=float32),\n",
       " array([0.48552424], dtype=float32),\n",
       " array([0.46931365], dtype=float32),\n",
       " array([0.40514487], dtype=float32),\n",
       " array([0.41182923], dtype=float32),\n",
       " array([0.42791894], dtype=float32),\n",
       " array([0.405836], dtype=float32),\n",
       " array([0.4981986], dtype=float32),\n",
       " array([0.43440622], dtype=float32),\n",
       " array([0.44471112], dtype=float32),\n",
       " array([0.37168515], dtype=float32),\n",
       " array([0.47441038], dtype=float32),\n",
       " array([0.3651678], dtype=float32),\n",
       " array([0.40067512], dtype=float32),\n",
       " array([0.5199345], dtype=float32),\n",
       " array([0.4233134], dtype=float32),\n",
       " array([0.4351335], dtype=float32),\n",
       " array([0.4555768], dtype=float32),\n",
       " array([0.03253645], dtype=float32),\n",
       " array([0.38686517], dtype=float32),\n",
       " array([0.43364474], dtype=float32),\n",
       " array([0.35556954], dtype=float32),\n",
       " array([0.3455017], dtype=float32),\n",
       " array([0.36210445], dtype=float32),\n",
       " array([0.3429039], dtype=float32),\n",
       " array([0.4352731], dtype=float32),\n",
       " array([0.17092553], dtype=float32),\n",
       " array([0.47549853], dtype=float32),\n",
       " array([0.34219885], dtype=float32),\n",
       " array([0.48880357], dtype=float32),\n",
       " array([0.38187575], dtype=float32),\n",
       " array([0.42263123], dtype=float32),\n",
       " array([0.31459165], dtype=float32)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_3 = predict_1 + predict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-072387173aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_3' is not defined"
     ]
    }
   ],
   "source": [
    "len(predict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "predict_3 = map(operator.add, predict_1, predict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x7fc040081c50>\n"
     ]
    }
   ],
   "source": [
    "print(predict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43645966]\n",
      "[array([0.43645966], dtype=float32)]\n",
      "[0.34106642]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32)]\n",
      "[0.4075713]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32)]\n",
      "[0.40122908]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32)]\n",
      "[0.44226646]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32)]\n",
      "[0.44394046]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32)]\n",
      "[0.41578606]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32)]\n",
      "[0.41548812]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32)]\n",
      "[0.4436235]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32)]\n",
      "[0.357646]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32)]\n",
      "[0.43614274]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32)]\n",
      "[0.4559007]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32)]\n",
      "[0.44684273]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32)]\n",
      "[0.42056525]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32)]\n",
      "[0.42621326]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32)]\n",
      "[0.42557824]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32)]\n",
      "[0.4176554]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32)]\n",
      "[0.45774207]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32)]\n",
      "[0.43780085]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32)]\n",
      "[0.4308337]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32)]\n",
      "[0.4050982]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32)]\n",
      "[0.4504068]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32)]\n",
      "[0.39789623]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32)]\n",
      "[0.41764146]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32)]\n",
      "[0.4750628]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32)]\n",
      "[0.4315881]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32)]\n",
      "[0.4379266]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32)]\n",
      "[0.4739846]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32)]\n",
      "[0.14909385]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32)]\n",
      "[0.38376015]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32)]\n",
      "[0.43800506]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32)]\n",
      "[0.35712954]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32)]\n",
      "[0.37910074]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32)]\n",
      "[0.35794306]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32)]\n",
      "[0.3569919]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32)]\n",
      "[0.4402965]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32)]\n",
      "[0.23215562]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32)]\n",
      "[0.45525098]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32)]\n",
      "[0.32845485]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32)]\n",
      "[0.45887935]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32), array([0.45887935], dtype=float32)]\n",
      "[0.41872162]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32), array([0.45887935], dtype=float32), array([0.41872162], dtype=float32)]\n",
      "[0.42732608]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32), array([0.45887935], dtype=float32), array([0.41872162], dtype=float32), array([0.42732608], dtype=float32)]\n",
      "[0.41365343]\n",
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32), array([0.45887935], dtype=float32), array([0.41872162], dtype=float32), array([0.42732608], dtype=float32), array([0.41365343], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "predict = []\n",
    "\n",
    "for i in predict_3:\n",
    "    print (i/2)\n",
    "    predict.append(i/2)\n",
    "    print (predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.43645966], dtype=float32), array([0.34106642], dtype=float32), array([0.4075713], dtype=float32), array([0.40122908], dtype=float32), array([0.44226646], dtype=float32), array([0.44394046], dtype=float32), array([0.41578606], dtype=float32), array([0.41548812], dtype=float32), array([0.4436235], dtype=float32), array([0.357646], dtype=float32), array([0.43614274], dtype=float32), array([0.4559007], dtype=float32), array([0.44684273], dtype=float32), array([0.42056525], dtype=float32), array([0.42621326], dtype=float32), array([0.42557824], dtype=float32), array([0.4176554], dtype=float32), array([0.45774207], dtype=float32), array([0.43780085], dtype=float32), array([0.4308337], dtype=float32), array([0.4050982], dtype=float32), array([0.4504068], dtype=float32), array([0.39789623], dtype=float32), array([0.41764146], dtype=float32), array([0.4750628], dtype=float32), array([0.4315881], dtype=float32), array([0.4379266], dtype=float32), array([0.4739846], dtype=float32), array([0.14909385], dtype=float32), array([0.38376015], dtype=float32), array([0.43800506], dtype=float32), array([0.35712954], dtype=float32), array([0.37910074], dtype=float32), array([0.35794306], dtype=float32), array([0.3569919], dtype=float32), array([0.4402965], dtype=float32), array([0.23215562], dtype=float32), array([0.45525098], dtype=float32), array([0.32845485], dtype=float32), array([0.45887935], dtype=float32), array([0.41872162], dtype=float32), array([0.42732608], dtype=float32), array([0.41365343], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predict)\n",
    "type(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y_pd_ = val_y_pd.to_numpy()\n",
    "val_y_pd_ = torch.from_numpy(val_y_pd_)\n",
    "val_y_pd_ = val_y_pd_.type_as(torch.FloatTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = criterion(predict, val_y)\n",
    "val_loss_summary += val_loss\n",
    "predicted = torch.max(val_pred.data, 1)[1] \n",
    "correct_val += (predicted == val_y).sum()\n",
    "\n",
    "print('*'*20, 'Test', '*'*20)\n",
    "print('Loss: {}, Accuracy: {} %'.format(val_loss.item(), correct_val/(len(val_loader)*batch_size)))\n",
    "print('*'*46)\n",
    "print(\"Val accuracy:{:.3f}\".format(float(correct_val) / (len(val_loader)*batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     1.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     1.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    0.0\n",
       "13    1.0\n",
       "14    0.0\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    1.0\n",
       "18    0.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    0.0\n",
       "23    0.0\n",
       "24    0.0\n",
       "25    0.0\n",
       "26    1.0\n",
       "27    0.0\n",
       "28    0.0\n",
       "29    1.0\n",
       "30    0.0\n",
       "31    0.0\n",
       "32    0.0\n",
       "33    0.0\n",
       "34    0.0\n",
       "35    0.0\n",
       "36    1.0\n",
       "37    1.0\n",
       "38    0.0\n",
       "39    0.0\n",
       "40    0.0\n",
       "41    0.0\n",
       "42    0.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.0.weight tensor([[-0.0565, -0.1205,  0.0296,  ...,  0.2230, -0.0025,  0.0114],\n",
      "        [-0.0879, -0.0202, -0.0235,  ...,  0.0587,  0.0370, -0.0111],\n",
      "        [-0.0381, -0.0511, -0.0141,  ..., -0.0142,  0.0329,  0.0550],\n",
      "        ...,\n",
      "        [ 0.0349, -0.0490, -0.0410,  ..., -0.0243, -0.0495,  0.0048],\n",
      "        [ 0.0487,  0.1016, -0.0085,  ..., -0.1036,  0.0225, -0.0505],\n",
      "        [-0.0129,  0.1087,  0.0454,  ..., -0.1197,  0.0375,  0.0101]])\n",
      "layer1.0.bias tensor([-0.0296, -0.0339,  0.0066, -0.0166, -0.0347, -0.0489,  0.0233,  0.0351,\n",
      "         0.0348,  0.0116,  0.0404, -0.0197, -0.0154,  0.0126,  0.0236,  0.0361,\n",
      "        -0.0178, -0.0001, -0.0028, -0.0274, -0.0495, -0.0317,  0.0020,  0.0040,\n",
      "         0.0019,  0.0077,  0.0134, -0.0460,  0.0494,  0.0400, -0.0072, -0.0119,\n",
      "         0.0044, -0.0115,  0.0237, -0.0051, -0.0136, -0.0101,  0.0195,  0.0419,\n",
      "        -0.0333, -0.0286,  0.0231, -0.0157,  0.0131,  0.0034, -0.0038,  0.0113,\n",
      "        -0.0342,  0.0022, -0.0403,  0.0045,  0.0368, -0.0412, -0.0265,  0.0073,\n",
      "         0.0281,  0.0489, -0.0224, -0.0353, -0.0270,  0.0293, -0.0182,  0.0238,\n",
      "         0.0492,  0.0268,  0.0054, -0.0453, -0.0368, -0.0456, -0.0042, -0.0114,\n",
      "         0.0184, -0.0176,  0.0122, -0.0008,  0.0443, -0.0175, -0.0142,  0.0456,\n",
      "         0.0210, -0.0015, -0.0053,  0.0494, -0.0356, -0.0446,  0.0353, -0.0413,\n",
      "        -0.0138,  0.0264, -0.0138,  0.0239,  0.0239, -0.0406, -0.0066,  0.0318,\n",
      "        -0.0107,  0.0155, -0.0385, -0.0457, -0.0217, -0.0321,  0.0310, -0.0050,\n",
      "        -0.0381, -0.0156,  0.0157, -0.0302,  0.0393,  0.0008,  0.0229, -0.0228,\n",
      "        -0.0309,  0.0328,  0.0005,  0.0439,  0.0028,  0.0360, -0.0042,  0.0088,\n",
      "        -0.0314, -0.0466, -0.0220, -0.0228,  0.0237,  0.0239, -0.0307,  0.0453,\n",
      "         0.0329,  0.0349, -0.0221, -0.0098,  0.0226,  0.0481,  0.0167,  0.0323,\n",
      "        -0.0268,  0.0228,  0.0485, -0.0443,  0.0335,  0.0312,  0.0197, -0.0286,\n",
      "         0.0466, -0.0496,  0.0195, -0.0330,  0.0122, -0.0012,  0.0474, -0.0334,\n",
      "         0.0289,  0.0292,  0.0017,  0.0107,  0.0175, -0.0181, -0.0057,  0.0273,\n",
      "         0.0200,  0.0319, -0.0083,  0.0171,  0.0426,  0.0274, -0.0409,  0.0243,\n",
      "        -0.0078,  0.0461,  0.0331, -0.0404,  0.0284,  0.0241, -0.0382, -0.0323,\n",
      "        -0.0196, -0.0103, -0.0421,  0.0310, -0.0475, -0.0364, -0.0091, -0.0065,\n",
      "        -0.0075,  0.0139,  0.0052,  0.0198,  0.0273,  0.0429,  0.0285, -0.0189,\n",
      "         0.0003,  0.0293, -0.0074,  0.0034, -0.0308, -0.0453, -0.0052,  0.0491,\n",
      "        -0.0164, -0.0174, -0.0105,  0.0064,  0.0330, -0.0178, -0.0432, -0.0326,\n",
      "        -0.0172,  0.0131, -0.0105,  0.0036, -0.0133, -0.0358,  0.0205,  0.0050,\n",
      "         0.0117,  0.0358, -0.0050, -0.0465,  0.0437,  0.0382, -0.0406,  0.0342,\n",
      "        -0.0039, -0.0102, -0.0305,  0.0462, -0.0189,  0.0109,  0.0156,  0.0486,\n",
      "        -0.0352,  0.0466, -0.0362,  0.0174,  0.0249,  0.0121,  0.0045, -0.0139,\n",
      "        -0.0131, -0.0221,  0.0172, -0.0261, -0.0400,  0.0163, -0.0023, -0.0367,\n",
      "         0.0451, -0.0103,  0.0202, -0.0446, -0.0080,  0.0331, -0.0087, -0.0047])\n",
      "layer1.1.weight tensor([1.0543, 1.0026, 0.9529, 0.9930, 0.9804, 0.9381, 0.9887, 1.0181, 1.3591,\n",
      "        0.9947, 0.9440, 0.9238, 1.0188, 0.9941, 0.9750, 0.9654, 1.0311, 1.0246,\n",
      "        0.9704, 0.9845, 1.0102, 0.9843, 0.9939, 0.9649, 1.0927, 1.1654, 0.9758,\n",
      "        0.9636, 1.0126, 0.9536, 1.0806, 0.9525, 0.9579, 0.9856, 0.9407, 0.9693,\n",
      "        0.9402, 1.0998, 0.9559, 0.9616, 1.0285, 0.9483, 1.0569, 0.9598, 0.9758,\n",
      "        0.9606, 0.9784, 0.9570, 0.9713, 0.9745, 1.0181, 1.0555, 0.9997, 0.9530,\n",
      "        0.9576, 0.9488, 0.9400, 0.9601, 0.9809, 0.9516, 0.9940, 0.9563, 1.0968,\n",
      "        0.9425, 0.9743, 1.0133, 0.9653, 1.1313, 1.0063, 0.9513, 1.2053, 0.9754,\n",
      "        0.9650, 0.9459, 0.9965, 0.9641, 0.9772, 1.0243, 0.9510, 0.9320, 0.9907,\n",
      "        0.9788, 1.0122, 1.0071, 0.9641, 0.9579, 1.1537, 0.9829, 0.9348, 1.0536,\n",
      "        0.9752, 0.9476, 0.9320, 1.0961, 0.9682, 0.9551, 1.0997, 0.9738, 0.9502,\n",
      "        0.9723, 0.9532, 0.9421, 1.0103, 0.9597, 1.0276, 0.9726, 0.9488, 0.9493,\n",
      "        0.9718, 0.9464, 0.9359, 1.0518, 0.9688, 0.9973, 0.9829, 0.9552, 0.9926,\n",
      "        0.9318, 1.1189, 0.9734, 1.0136, 1.0211, 1.1543, 1.0242, 0.9966, 0.9609,\n",
      "        0.9532, 0.9632, 0.9638, 0.9995, 1.0706, 1.2656, 1.0072, 1.0146, 1.0994,\n",
      "        0.9740, 0.9531, 1.0132, 0.9401, 1.0987, 0.9823, 1.0166, 1.0076, 0.9821,\n",
      "        0.9629, 0.9700, 1.0205, 0.9578, 1.0034, 0.9603, 0.9256, 0.9741, 0.9436,\n",
      "        1.1408, 0.9683, 0.9890, 0.9576, 0.9858, 0.9450, 0.9762, 0.9716, 0.9857,\n",
      "        0.9722, 0.9662, 1.1388, 1.0447, 0.9543, 0.9899, 0.9534, 1.0293, 0.9659,\n",
      "        0.9652, 1.0391, 0.9915, 0.9734, 1.0190, 0.9628, 0.9587, 0.9835, 0.9557,\n",
      "        0.9662, 0.9700, 0.9721, 0.9751, 0.9466, 1.0051, 0.9608, 0.9418, 0.9616,\n",
      "        0.9540, 0.9386, 0.9793, 0.9455, 0.9494, 0.9596, 0.9577, 1.1870, 0.9387,\n",
      "        1.0832, 0.9497, 1.0929, 0.9469, 0.9594, 0.9605, 1.0027, 0.9616, 0.9803,\n",
      "        0.9703, 1.0022, 0.9896, 0.9997, 1.0361, 0.9539, 0.9467, 0.9919, 0.9524,\n",
      "        0.9626, 0.9502, 0.9668, 1.1326, 0.9875, 1.0050, 0.9409, 1.0002, 0.9510,\n",
      "        0.9608, 0.9515, 0.9672, 0.9675, 1.0145, 1.0126, 1.0117, 0.9585, 0.9675,\n",
      "        0.9777, 0.9710, 0.9834, 1.1106, 0.9546, 0.9559, 0.9482, 0.9359, 0.9625,\n",
      "        0.9448, 0.9875, 0.9419, 0.9797, 0.9734, 1.0407, 0.9971, 0.9410, 0.9882,\n",
      "        0.9700, 0.9617, 0.9896, 0.9808])\n",
      "layer1.1.bias tensor([ 0.0453,  0.0241, -0.0505, -0.0232, -0.0577, -0.0721,  0.0315, -0.0061,\n",
      "         0.0808,  0.0042, -0.0511, -0.0356,  0.0082,  0.0235, -0.0111,  0.0091,\n",
      "        -0.0469,  0.0067, -0.0420, -0.0269, -0.0116, -0.0002, -0.0145, -0.0298,\n",
      "         0.0468,  0.0831, -0.0057, -0.0144,  0.0346, -0.0472,  0.0046, -0.0278,\n",
      "        -0.0359, -0.0035, -0.0414, -0.0530, -0.0214,  0.0057, -0.0362, -0.0383,\n",
      "         0.0049, -0.0249,  0.0879, -0.0336,  0.0092, -0.0274, -0.0124, -0.0407,\n",
      "         0.0249, -0.0224,  0.0245, -0.0011, -0.0500, -0.0545, -0.0306, -0.0362,\n",
      "        -0.0262, -0.0363, -0.0222, -0.0485, -0.0457, -0.0340,  0.0623, -0.0656,\n",
      "        -0.0472, -0.0040,  0.0202,  0.0939,  0.0504, -0.0124,  0.1581, -0.0275,\n",
      "        -0.0311, -0.0313, -0.0377, -0.0105, -0.0219,  0.0396, -0.0215, -0.0541,\n",
      "         0.0313, -0.0159,  0.0051, -0.0322, -0.0650, -0.0638,  0.1269,  0.0325,\n",
      "        -0.0127,  0.0025, -0.0383, -0.0019, -0.0304,  0.0603, -0.0517, -0.0490,\n",
      "         0.0615, -0.0521, -0.0420, -0.0156, -0.0182, -0.0318, -0.0394, -0.0332,\n",
      "         0.0085, -0.0176, -0.0462, -0.0274,  0.0113, -0.0159, -0.0646,  0.0320,\n",
      "        -0.0337, -0.0111, -0.0506, -0.0191, -0.0149, -0.0349,  0.0042, -0.0751,\n",
      "         0.0237,  0.0079,  0.0560,  0.0476, -0.0440, -0.0315, -0.0526, -0.0280,\n",
      "        -0.0255, -0.0052,  0.0083,  0.1634, -0.0207,  0.0299,  0.0531,  0.0486,\n",
      "        -0.0296, -0.0142, -0.0345,  0.0608, -0.0170, -0.0334,  0.0234, -0.0233,\n",
      "        -0.0080, -0.0628, -0.0103, -0.0211, -0.0157, -0.0268, -0.0607, -0.0041,\n",
      "        -0.0442,  0.0705,  0.0504, -0.0203, -0.0289, -0.0262, -0.0366, -0.0557,\n",
      "        -0.0434,  0.0295, -0.0221, -0.0399,  0.1607,  0.0627, -0.0258,  0.0372,\n",
      "        -0.0028,  0.0355, -0.0461, -0.0278,  0.0041, -0.0111, -0.0156, -0.0463,\n",
      "        -0.0400, -0.0635, -0.0304, -0.0536, -0.0209, -0.0195, -0.0341, -0.0342,\n",
      "        -0.0113, -0.0032, -0.0328, -0.0393, -0.0565,  0.0103, -0.0485, -0.0362,\n",
      "         0.0448, -0.0292, -0.0124, -0.0273,  0.1589, -0.0610,  0.0671, -0.0247,\n",
      "         0.0505, -0.0319, -0.0130, -0.0454,  0.0191, -0.0244, -0.0111, -0.0171,\n",
      "        -0.0051, -0.0271, -0.0062,  0.0734, -0.0318, -0.0160, -0.0424, -0.0499,\n",
      "        -0.0272, -0.0263,  0.0187,  0.1053, -0.0019, -0.0242, -0.0582,  0.0288,\n",
      "        -0.0535, -0.0423, -0.0635, -0.0212, -0.0191,  0.0121,  0.0152, -0.0035,\n",
      "        -0.0330, -0.0343, -0.0404, -0.0321, -0.0270,  0.0617, -0.0283, -0.0453,\n",
      "        -0.0607, -0.0292, -0.0565, -0.0464, -0.0083, -0.0198, -0.0132, -0.0766,\n",
      "         0.0538, -0.0385, -0.0541, -0.0003, -0.0083, -0.0426, -0.0276, -0.0277])\n",
      "layer2.0.weight tensor([[-0.0163,  0.0263,  0.0218,  ..., -0.0967,  0.0156,  0.0105],\n",
      "        [-0.0522, -0.0449,  0.0215,  ..., -0.0324, -0.0184,  0.0182],\n",
      "        [ 0.0422,  0.0070,  0.0411,  ...,  0.0558,  0.0299,  0.0019],\n",
      "        ...,\n",
      "        [ 0.0493, -0.0322, -0.0337,  ...,  0.0173,  0.0147, -0.0171],\n",
      "        [-0.0296, -0.0210, -0.0163,  ...,  0.0227,  0.0137, -0.0562],\n",
      "        [ 0.0282,  0.0394,  0.0259,  ...,  0.0094,  0.0067,  0.0486]])\n",
      "layer2.0.bias tensor([-0.0604, -0.0613,  0.0348,  0.0436,  0.0475,  0.0515,  0.0059, -0.0128,\n",
      "         0.0378, -0.0207,  0.0542,  0.0261,  0.0211, -0.0375, -0.0479,  0.0064,\n",
      "         0.0352, -0.0484,  0.0122,  0.0089,  0.0133,  0.0003,  0.0068, -0.0451,\n",
      "         0.0169, -0.0488,  0.0247, -0.0605, -0.0118,  0.0411, -0.0161,  0.0565,\n",
      "         0.0277, -0.0389, -0.0478,  0.0508,  0.0215, -0.0234,  0.0101,  0.0033,\n",
      "        -0.0417, -0.0411,  0.0051,  0.0259,  0.0112,  0.0247,  0.0465, -0.0558,\n",
      "         0.0354, -0.0163, -0.0328, -0.0269, -0.0410, -0.0317,  0.0026, -0.0495,\n",
      "         0.0258, -0.0097,  0.0296,  0.0282,  0.0211,  0.0254,  0.0217, -0.0031,\n",
      "         0.0474, -0.0321, -0.0401, -0.0512,  0.0529,  0.0175, -0.0365,  0.0139,\n",
      "         0.0285, -0.0031,  0.0229,  0.0554, -0.0087, -0.0225,  0.0534,  0.0102,\n",
      "        -0.0117,  0.0120, -0.0551,  0.0136,  0.0420,  0.0340, -0.0566,  0.0161,\n",
      "        -0.0286,  0.0448,  0.0400,  0.0561,  0.0053, -0.0277, -0.0146,  0.0201,\n",
      "         0.0278,  0.0577,  0.0026,  0.0097, -0.0232, -0.0103,  0.0562, -0.0150,\n",
      "         0.0318,  0.0545, -0.0133,  0.0257,  0.0521, -0.0492, -0.0415,  0.0575,\n",
      "         0.0273, -0.0348,  0.0407,  0.0224, -0.0134,  0.0508,  0.0162, -0.0108,\n",
      "        -0.0385, -0.0458, -0.0352, -0.0646,  0.0572,  0.0406,  0.0331,  0.0130])\n",
      "layer2.1.weight tensor([0.9613, 1.0475, 1.0010, 0.9392, 1.0344, 0.9671, 1.0034, 1.1226, 0.9615,\n",
      "        1.0508, 0.9742, 1.0172, 0.9995, 0.9541, 0.9533, 0.9548, 0.9846, 1.1078,\n",
      "        1.1053, 1.0107, 0.9783, 0.9653, 1.0068, 1.0774, 0.9704, 1.0177, 0.9810,\n",
      "        0.9845, 0.9522, 1.0674, 0.9781, 0.9977, 0.9818, 1.0031, 0.9531, 1.0444,\n",
      "        1.0160, 1.0373, 1.0434, 0.9564, 1.0378, 0.9935, 1.0403, 0.9438, 0.9588,\n",
      "        0.9968, 0.9936, 1.0114, 1.0069, 0.9975, 1.0479, 1.0201, 0.9579, 1.0324,\n",
      "        1.0037, 0.9983, 0.9907, 1.0427, 0.9711, 0.9804, 1.0222, 0.9770, 1.0041,\n",
      "        0.9864, 0.9818, 0.9704, 0.9547, 0.9659, 1.0392, 1.0374, 0.9591, 0.9856,\n",
      "        1.0427, 0.9606, 0.9982, 0.9646, 1.0630, 0.9772, 0.9811, 0.9855, 0.9293,\n",
      "        1.0613, 1.0292, 1.0194, 1.0508, 0.9637, 1.1035, 0.9961, 1.0145, 1.0209,\n",
      "        0.9505, 1.0620, 0.9405, 0.9742, 0.9636, 1.0114, 1.0882, 1.0284, 1.0017,\n",
      "        1.0713, 0.9807, 1.0086, 0.9554, 1.0239, 1.0211, 0.9505, 1.0052, 1.0249,\n",
      "        0.9842, 1.0019, 0.9609, 1.0182, 0.9800, 1.0274, 1.0270, 0.9745, 1.0085,\n",
      "        0.9902, 0.9659, 0.9994, 1.0481, 0.9465, 0.9692, 1.0124, 1.0340, 0.9958,\n",
      "        0.9650, 0.9584])\n",
      "layer2.1.bias tensor([-3.3632e-02, -1.0531e-02, -3.9815e-02, -5.3454e-02,  3.4553e-03,\n",
      "        -4.2636e-02, -3.5241e-02,  6.7848e-02, -2.7361e-02,  2.4047e-02,\n",
      "        -1.6313e-02, -2.8308e-02, -3.9380e-02, -1.7013e-02, -1.2474e-02,\n",
      "        -1.6568e-02,  2.9685e-02,  5.9898e-02,  8.8914e-02,  8.4402e-03,\n",
      "        -3.1797e-02, -2.5944e-02,  1.3087e-02,  3.0514e-02, -2.9099e-02,\n",
      "        -3.4053e-02, -1.0561e-02, -3.3698e-02, -1.6890e-02, -2.2441e-02,\n",
      "        -2.8737e-02,  1.4771e-02,  1.2317e-03, -3.8425e-03, -6.0187e-03,\n",
      "        -2.0330e-02,  1.3631e-03,  1.1908e-03, -4.2749e-02, -1.9610e-02,\n",
      "        -5.1234e-03, -1.1312e-02,  5.1386e-02, -2.8814e-02, -5.9600e-02,\n",
      "        -6.9483e-03,  2.6689e-03, -1.9948e-02, -2.7281e-02,  1.8556e-02,\n",
      "        -2.7163e-02, -7.9423e-02, -5.0906e-02, -1.5404e-02, -3.7304e-02,\n",
      "        -4.5451e-03, -6.8602e-03, -3.7263e-02, -1.3598e-02,  8.3878e-03,\n",
      "         1.0625e-02, -1.2431e-02,  2.4046e-03,  8.8591e-03,  3.5623e-03,\n",
      "        -2.1075e-02, -5.0911e-02,  3.3220e-03,  7.3397e-03,  1.2624e-02,\n",
      "        -2.7113e-02, -9.7818e-03,  3.8295e-02, -3.5996e-02, -4.4027e-03,\n",
      "        -6.1831e-03,  7.9379e-05, -6.9035e-03, -3.7248e-03, -2.9304e-02,\n",
      "        -3.3609e-02, -4.9656e-02,  2.8775e-02,  2.0694e-02,  3.1142e-02,\n",
      "        -3.4996e-02, -5.2912e-02, -2.7226e-02, -8.7165e-03, -7.9831e-02,\n",
      "        -3.4923e-02,  1.6893e-02, -1.9217e-02, -1.2025e-04, -2.4480e-02,\n",
      "         8.3395e-03, -2.0882e-02,  7.1040e-02,  9.8776e-03,  8.4546e-02,\n",
      "        -4.6718e-03, -1.2601e-02, -3.4672e-02,  4.7202e-02, -7.7692e-03,\n",
      "        -3.0968e-02, -2.4136e-02,  4.0197e-02,  1.8163e-03, -8.8145e-03,\n",
      "        -4.8762e-02, -2.5213e-02, -1.8892e-02, -3.4188e-02,  1.4136e-02,\n",
      "        -9.4315e-03, -7.7451e-03,  7.3673e-03,  2.9620e-03, -8.7451e-03,\n",
      "         5.1112e-02, -2.6812e-02,  1.3600e-02,  1.1149e-02, -6.7495e-03,\n",
      "        -9.1601e-03, -4.1967e-02, -2.4559e-02])\n",
      "layer3.0.weight tensor([[-0.0475,  0.0049, -0.0305,  ..., -0.0959, -0.0193, -0.0498],\n",
      "        [ 0.0476,  0.0125, -0.0632,  ...,  0.0559, -0.0873, -0.0563],\n",
      "        [-0.0611,  0.0562,  0.0944,  ...,  0.0271, -0.0053,  0.0391],\n",
      "        ...,\n",
      "        [-0.0332,  0.1086, -0.0952,  ...,  0.0282, -0.0768, -0.0400],\n",
      "        [-0.0533,  0.0318,  0.0123,  ...,  0.0516, -0.0466,  0.0648],\n",
      "        [-0.0028, -0.0263, -0.0079,  ...,  0.0050, -0.0584, -0.0270]])\n",
      "layer3.0.bias tensor([-0.0864,  0.0066,  0.0272,  0.0414,  0.0265, -0.0724,  0.0081, -0.0026,\n",
      "         0.0090, -0.0017, -0.0632,  0.0474,  0.0010,  0.0513, -0.0701,  0.0224,\n",
      "         0.0710,  0.0793,  0.0045, -0.0487,  0.0904, -0.0718, -0.0645,  0.0604,\n",
      "         0.0616,  0.0063, -0.0180, -0.0622, -0.0654, -0.0706,  0.0485,  0.0171,\n",
      "         0.0422,  0.0428, -0.0145, -0.0604, -0.0029,  0.0437, -0.0610, -0.0750,\n",
      "        -0.0723,  0.0333,  0.0454,  0.0449, -0.0565, -0.0309,  0.0858, -0.0418,\n",
      "         0.0134, -0.0809,  0.0819, -0.0303, -0.0396,  0.0419, -0.0036, -0.0205,\n",
      "         0.0124,  0.0358,  0.0826,  0.0011, -0.0844,  0.0698,  0.0577,  0.0164])\n",
      "layer3.1.weight tensor([1.0830, 0.9978, 0.9785, 1.2189, 1.0479, 1.2179, 1.1423, 1.0221, 1.2209,\n",
      "        1.1106, 1.1230, 1.1783, 1.2140, 1.0997, 1.1747, 1.1660, 0.9775, 1.1345,\n",
      "        1.2364, 1.2392, 1.1082, 1.0455, 1.0523, 1.1933, 1.1867, 1.2126, 1.1887,\n",
      "        1.1772, 1.1870, 1.1890, 1.2267, 1.1849, 1.1846, 1.1480, 1.2154, 1.0959,\n",
      "        1.1951, 1.0215, 1.2021, 1.2693, 1.2102, 1.0501, 1.2439, 1.1928, 1.1395,\n",
      "        1.0154, 1.2521, 1.2279, 1.2349, 1.1956, 1.0306, 1.2408, 1.0883, 1.0951,\n",
      "        1.0982, 1.1461, 1.1568, 1.1664, 1.1719, 1.1948, 1.0316, 1.2075, 1.1764,\n",
      "        1.1313])\n",
      "layer3.1.bias tensor([ 0.0915, -0.0282, -0.0143,  0.2714,  0.0145,  0.2964,  0.2684,  0.0075,\n",
      "         0.2234,  0.1543,  0.1794,  0.1890,  0.2182,  0.0831,  0.2497,  0.1692,\n",
      "        -0.0144,  0.1800,  0.2716,  0.2873,  0.1167,  0.1014,  0.1085,  0.2057,\n",
      "         0.1829,  0.2182,  0.1975,  0.2033,  0.2191,  0.2082,  0.2647,  0.1941,\n",
      "         0.2544,  0.1868,  0.2324,  0.1946,  0.2205,  0.0303,  0.2813,  0.2636,\n",
      "         0.2980,  0.0259,  0.2997,  0.2090,  0.1250, -0.0026,  0.2421,  0.2573,\n",
      "         0.2519,  0.2493,  0.0357,  0.2008,  0.0534,  0.0487,  0.1670,  0.2083,\n",
      "         0.2069,  0.2459,  0.1904,  0.2156,  0.0678,  0.1993,  0.2226,  0.1382])\n",
      "layer4.0.weight tensor([[ 0.1443, -0.1018, -0.1090, -0.0516,  0.1599,  0.0069, -0.0503,  0.1055,\n",
      "         -0.0097, -0.0815, -0.1210, -0.1320,  0.0117,  0.1893,  0.0297, -0.0609,\n",
      "         -0.0963, -0.0788,  0.0810,  0.0670,  0.1692,  0.0684,  0.0730, -0.0411,\n",
      "          0.1759,  0.1943,  0.1316, -0.0388,  0.0772,  0.0503, -0.0200,  0.0197,\n",
      "         -0.0622, -0.0458, -0.0191,  0.0823,  0.1046,  0.1087, -0.0157,  0.0328,\n",
      "          0.0674, -0.1792,  0.0546, -0.0750,  0.2092,  0.0876,  0.1790, -0.0397,\n",
      "          0.1453,  0.0945,  0.0643,  0.1934,  0.0981,  0.1405,  0.0046, -0.1102,\n",
      "         -0.1080, -0.1053,  0.0836, -0.0286,  0.1281,  0.1765,  0.1460,  0.1653],\n",
      "        [ 0.0217,  0.0608,  0.0180,  0.1182, -0.0015,  0.2358,  0.0999, -0.0263,\n",
      "          0.2130,  0.0464,  0.1344,  0.1936,  0.1836,  0.0360,  0.2525,  0.0794,\n",
      "          0.0240,  0.2377,  0.0799,  0.0862,  0.0153,  0.0383,  0.0203,  0.2627,\n",
      "          0.0624,  0.1321,  0.2048,  0.1786,  0.1144,  0.1500,  0.1790,  0.2333,\n",
      "          0.1601,  0.2412,  0.1343,  0.0168,  0.2571, -0.0316,  0.1852,  0.1524,\n",
      "          0.1819,  0.0625,  0.1196,  0.2069,  0.0415, -0.0076,  0.1371,  0.1301,\n",
      "          0.1420,  0.1877,  0.0073,  0.0249, -0.0140, -0.0378,  0.0512,  0.2081,\n",
      "          0.1792,  0.1329,  0.2212,  0.1911,  0.0125,  0.0667,  0.0923,  0.0203],\n",
      "        [-0.2432, -0.0389, -0.0607, -0.2514, -0.1295, -0.0640, -0.2343, -0.1205,\n",
      "         -0.0664, -0.1287, -0.1257, -0.1201, -0.1826, -0.1296, -0.0727, -0.2364,\n",
      "         -0.0779, -0.0961, -0.2272, -0.1283, -0.1555, -0.1959,  0.0120, -0.0102,\n",
      "         -0.2502, -0.1883, -0.1268, -0.2563, -0.1923, -0.1318, -0.0212,  0.0008,\n",
      "         -0.2428, -0.1623, -0.0560, -0.2609, -0.1249, -0.1706, -0.0733, -0.0552,\n",
      "         -0.0518,  0.0199, -0.2394, -0.1281, -0.1758, -0.1558, -0.2302, -0.2144,\n",
      "         -0.1794, -0.1492, -0.1079, -0.1032, -0.1590, -0.1594, -0.1735, -0.0209,\n",
      "         -0.0855, -0.0201, -0.2071, -0.0804, -0.0605, -0.2281, -0.1177, -0.1835],\n",
      "        [-0.1199, -0.0040, -0.0171, -0.1126, -0.0389, -0.1439, -0.0756, -0.2350,\n",
      "         -0.2176, -0.1180, -0.2137, -0.1639, -0.2511, -0.1544, -0.1507, -0.2416,\n",
      "         -0.1334, -0.2039, -0.2148, -0.1279, -0.2169, -0.0966, -0.2507, -0.1037,\n",
      "         -0.0338, -0.2607, -0.0781, -0.0964, -0.0657, -0.1267, -0.2049, -0.1176,\n",
      "         -0.2286, -0.0985, -0.2631, -0.1282, -0.1944, -0.1586, -0.0471, -0.1824,\n",
      "         -0.1434, -0.1002, -0.1454, -0.1895, -0.2000, -0.0785, -0.0276, -0.0718,\n",
      "         -0.1264, -0.1293, -0.2575, -0.0849, -0.1897, -0.1408, -0.1570, -0.2139,\n",
      "         -0.1875, -0.2081, -0.0471, -0.0203, -0.2226, -0.1819, -0.1165, -0.1302],\n",
      "        [-0.1802, -0.0633, -0.0637, -0.2384, -0.0146, -0.0645, -0.0368, -0.2012,\n",
      "         -0.0591, -0.1984, -0.2079, -0.0333, -0.1293, -0.0126, -0.0276, -0.2091,\n",
      "         -0.0411, -0.1115, -0.1910, -0.1666, -0.2572, -0.1108, -0.0301, -0.0069,\n",
      "         -0.0419, -0.1471, -0.2321, -0.2270, -0.2011, -0.0748, -0.2039, -0.1080,\n",
      "         -0.1286, -0.0987, -0.0976, -0.1672, -0.1203, -0.1282, -0.0689, -0.0554,\n",
      "         -0.1317, -0.0058, -0.0384,  0.0061, -0.0375, -0.0419, -0.0470, -0.1376,\n",
      "         -0.1174, -0.2775, -0.0460, -0.2670, -0.0307, -0.2332, -0.2090, -0.1205,\n",
      "          0.0200, -0.2760, -0.0058, -0.1297, -0.1080, -0.1665, -0.2090, -0.2020],\n",
      "        [-0.1231, -0.0062, -0.0950, -0.1043, -0.2140,  0.0014, -0.0336, -0.0853,\n",
      "         -0.2615, -0.0879, -0.0022, -0.0751, -0.2024, -0.1064, -0.2189, -0.1478,\n",
      "         -0.0348, -0.0073, -0.2251, -0.0484, -0.2678, -0.2492, -0.2124, -0.1391,\n",
      "         -0.1951, -0.1726, -0.2075, -0.2298, -0.0884, -0.1018, -0.2566, -0.0414,\n",
      "          0.0069, -0.0555, -0.0833, -0.1223, -0.1051, -0.0751, -0.0328, -0.2043,\n",
      "         -0.1451, -0.0688, -0.1671, -0.2221, -0.1884, -0.1681, -0.2421, -0.1808,\n",
      "         -0.0997, -0.1051, -0.0809, -0.2211, -0.1743, -0.1355, -0.2134, -0.1541,\n",
      "         -0.1121, -0.0627, -0.2451, -0.0142, -0.1448, -0.0595, -0.0637, -0.2183],\n",
      "        [-0.1407, -0.0914, -0.0005, -0.1951, -0.0161, -0.0542, -0.1097, -0.0301,\n",
      "         -0.0765, -0.1972, -0.0196, -0.2088, -0.1064, -0.1356, -0.0803, -0.0849,\n",
      "          0.0189, -0.0439, -0.0596, -0.1871, -0.1199, -0.0753, -0.2501, -0.2427,\n",
      "         -0.1096, -0.1046, -0.0102, -0.1465, -0.1557, -0.1363, -0.1542, -0.0851,\n",
      "         -0.1840, -0.1841, -0.2426, -0.1027, -0.0040, -0.0706, -0.2566, -0.1660,\n",
      "         -0.1931, -0.1065, -0.1912, -0.1641, -0.2157, -0.0099, -0.2577, -0.0814,\n",
      "         -0.1111, -0.1409, -0.0185, -0.2288, -0.1723, -0.0902, -0.0752, -0.0525,\n",
      "         -0.0377, -0.0278, -0.0338, -0.1065, -0.1842, -0.1288, -0.2489, -0.2255],\n",
      "        [-0.2539, -0.1380, -0.1654, -0.0267, -0.1212, -0.1274, -0.2463, -0.0753,\n",
      "         -0.2290, -0.0399, -0.0709, -0.2486, -0.1969, -0.0137, -0.2001, -0.2162,\n",
      "         -0.0443, -0.2057, -0.1781, -0.2061, -0.1792, -0.2439, -0.1128, -0.0377,\n",
      "         -0.1224, -0.2723, -0.1398, -0.1423, -0.1756, -0.0747, -0.2065, -0.2079,\n",
      "         -0.0225, -0.0912, -0.2301, -0.0589, -0.1865, -0.2143, -0.0564, -0.1112,\n",
      "         -0.0200, -0.0838, -0.1945, -0.0198, -0.2092, -0.0651, -0.0361, -0.1678,\n",
      "         -0.1863, -0.1500, -0.2503, -0.2740, -0.1245, -0.0233, -0.0282, -0.1324,\n",
      "         -0.1591, -0.2734, -0.0080, -0.2291, -0.2594, -0.1609, -0.1763, -0.2036],\n",
      "        [-0.0516, -0.0618, -0.0515, -0.1324, -0.0758, -0.0121, -0.1110,  0.0086,\n",
      "         -0.0043, -0.2348, -0.0616, -0.0385, -0.1168, -0.0838, -0.0131, -0.1502,\n",
      "         -0.0839,  0.0026, -0.1464, -0.2231, -0.0360,  0.0006, -0.1124, -0.0058,\n",
      "         -0.1015, -0.0259, -0.2408, -0.1184, -0.2530, -0.2854, -0.0473, -0.2345,\n",
      "         -0.1317, -0.1904, -0.1330, -0.0268, -0.0028, -0.0418, -0.2312, -0.1631,\n",
      "         -0.1685, -0.0413, -0.1153, -0.2217, -0.2219, -0.0316, -0.1949, -0.1124,\n",
      "         -0.0946, -0.2711, -0.2002, -0.2090, -0.0699, -0.1576, -0.0864, -0.1298,\n",
      "         -0.0196, -0.0162, -0.0367, -0.1147, -0.1285, -0.0883, -0.0282, -0.1284],\n",
      "        [-0.2205, -0.1128, -0.2114, -0.1163, -0.0732, -0.0474, -0.0949, -0.1668,\n",
      "         -0.2371, -0.2560, -0.0541, -0.0704, -0.0962, -0.2574, -0.2749, -0.0283,\n",
      "         -0.0677, -0.2434, -0.1809, -0.0916, -0.2321, -0.1687, -0.0626, -0.1199,\n",
      "         -0.2002, -0.1164, -0.2182, -0.1223, -0.2658, -0.0749, -0.0277, -0.2505,\n",
      "         -0.1637, -0.1010, -0.2258, -0.1584, -0.0216, -0.0381, -0.0874, -0.1867,\n",
      "         -0.2840, -0.1811, -0.1091, -0.1530, -0.0389, -0.1132, -0.0818, -0.1548,\n",
      "         -0.0786, -0.2039, -0.0594, -0.2796, -0.2199, -0.0509, -0.0241, -0.0649,\n",
      "         -0.0618, -0.0783, -0.1577, -0.0774, -0.0268, -0.0769, -0.2652, -0.1091]])\n",
      "layer4.0.bias tensor([ 0.1278,  0.0571, -0.1977, -0.2206, -0.1804, -0.0446, -0.1893, -0.0693,\n",
      "        -0.1943, -0.1235])\n"
     ]
    }
   ],
   "source": [
    "#num_ftrs = model.forward.in_features\n",
    " \n",
    "for name, param in model.named_parameters():\n",
    "    print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-cd914773920e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.layer1 = Sequential(\n\u001b[0m\u001b[1;32m      2\u001b[0m                       Linear(4096, 2))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model.layer1 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'out_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-d6ee396a1192>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'out_features'"
     ]
    }
   ],
   "source": [
    "nn.Linear(num_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'parameter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ea8074fb84b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'parameter'"
     ]
    }
   ],
   "source": [
    "list(model.children())[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-45e4dc8164de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-3c96f51ab486>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLPRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mh1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mh3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_features' is not defined"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-d5aee46402fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-558e02a0941d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrn_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_X' is not defined"
     ]
    }
   ],
   "source": [
    "trn = data_utils.TensorDataset(trn_X, trn_y)\n",
    "trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val = data_utils.TensorDataset(val_X, val_y)\n",
    "val_loader = data_utils.DataLoader(val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_X_pd = df2_mod.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ID</th>\n",
       "      <th>ENSG00000069482</th>\n",
       "      <th>ENSG00000072657</th>\n",
       "      <th>ENSG00000078399</th>\n",
       "      <th>ENSG00000080572</th>\n",
       "      <th>ENSG00000100678</th>\n",
       "      <th>ENSG00000104435</th>\n",
       "      <th>ENSG00000104888</th>\n",
       "      <th>ENSG00000105146</th>\n",
       "      <th>ENSG00000109321</th>\n",
       "      <th>ENSG00000112499</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000274576</th>\n",
       "      <th>ENSG00000275756</th>\n",
       "      <th>ENSG00000276775</th>\n",
       "      <th>ENSG00000277247</th>\n",
       "      <th>ENSG00000278196</th>\n",
       "      <th>ENSG00000278698</th>\n",
       "      <th>ENSG00000279834</th>\n",
       "      <th>ENSG00000279970</th>\n",
       "      <th>ENSG00000280411</th>\n",
       "      <th>ENSG00000281880</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-61-1910</th>\n",
       "      <td>0.970585</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.044476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043732</td>\n",
       "      <td>2.308592</td>\n",
       "      <td>1.014494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.920597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.604301</td>\n",
       "      <td>0.299376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894232</td>\n",
       "      <td>1.612154</td>\n",
       "      <td>0.761720</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-0982</th>\n",
       "      <td>0.395276</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.090384</td>\n",
       "      <td>0.007062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>0.242661</td>\n",
       "      <td>0.691196</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>...</td>\n",
       "      <td>24.797152</td>\n",
       "      <td>0.259035</td>\n",
       "      <td>4.625172</td>\n",
       "      <td>0.188089</td>\n",
       "      <td>4.211878</td>\n",
       "      <td>0.270091</td>\n",
       "      <td>0.034947</td>\n",
       "      <td>0.311310</td>\n",
       "      <td>0.357217</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-36-1580</th>\n",
       "      <td>1.403594</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.133845</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.041762</td>\n",
       "      <td>0.074384</td>\n",
       "      <td>0.984290</td>\n",
       "      <td>2.329158</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>...</td>\n",
       "      <td>4.017149</td>\n",
       "      <td>0.289083</td>\n",
       "      <td>0.893372</td>\n",
       "      <td>0.314861</td>\n",
       "      <td>4.817979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707253</td>\n",
       "      <td>15.996040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-25-1321</th>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.162223</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101272</td>\n",
       "      <td>0.240456</td>\n",
       "      <td>1.740308</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>...</td>\n",
       "      <td>2.576079</td>\n",
       "      <td>0.166843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121147</td>\n",
       "      <td>1.356422</td>\n",
       "      <td>0.521892</td>\n",
       "      <td>0.157563</td>\n",
       "      <td>2.033770</td>\n",
       "      <td>1.495528</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-30-1892</th>\n",
       "      <td>0.206074</td>\n",
       "      <td>0.133216</td>\n",
       "      <td>0.119614</td>\n",
       "      <td>0.056072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055381</td>\n",
       "      <td>0.280458</td>\n",
       "      <td>0.592872</td>\n",
       "      <td>0.914734</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>...</td>\n",
       "      <td>1.058604</td>\n",
       "      <td>0.114269</td>\n",
       "      <td>2.825069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.716018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294278</td>\n",
       "      <td>1.890974</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-04-1347</th>\n",
       "      <td>0.319288</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.033696</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>0.060742</td>\n",
       "      <td>0.663423</td>\n",
       "      <td>0.094262</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.038608</td>\n",
       "      <td>0.567030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>4.616723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-24-0968</th>\n",
       "      <td>0.237050</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>0.185222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307004</td>\n",
       "      <td>0.213121</td>\n",
       "      <td>1.291373</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>...</td>\n",
       "      <td>15.221570</td>\n",
       "      <td>0.525782</td>\n",
       "      <td>4.332951</td>\n",
       "      <td>2.720169</td>\n",
       "      <td>31.845646</td>\n",
       "      <td>0.205584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710875</td>\n",
       "      <td>6.117782</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-30-1891</th>\n",
       "      <td>0.772034</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.110194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.200678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098616</td>\n",
       "      <td>2.959271</td>\n",
       "      <td>0.077290</td>\n",
       "      <td>...</td>\n",
       "      <td>47.331214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.631492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.568652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.395413</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-09-0366</th>\n",
       "      <td>0.195435</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.631170</td>\n",
       "      <td>0.026487</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.006339</td>\n",
       "      <td>0.303848</td>\n",
       "      <td>0.703636</td>\n",
       "      <td>5.424154</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225023</td>\n",
       "      <td>0.534375</td>\n",
       "      <td>0.100086</td>\n",
       "      <td>1.481522</td>\n",
       "      <td>3.712525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058985</td>\n",
       "      <td>2.477118</td>\n",
       "      <td>0.602935</td>\n",
       "      <td>0.001573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-13-0884</th>\n",
       "      <td>0.784894</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.035967</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.023577</td>\n",
       "      <td>0.643764</td>\n",
       "      <td>0.967456</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>...</td>\n",
       "      <td>2.586317</td>\n",
       "      <td>0.074447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162171</td>\n",
       "      <td>7.989302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060262</td>\n",
       "      <td>0.191723</td>\n",
       "      <td>3.849928</td>\n",
       "      <td>0.000402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 395 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ID            ENSG00000069482  ENSG00000072657  ENSG00000078399  \\\n",
       "TCGA-61-1910         0.970585         0.003561         0.044476   \n",
       "TCGA-24-0982         0.395276         0.005010         0.090384   \n",
       "TCGA-36-1580         1.403594         0.008641         0.133845   \n",
       "TCGA-25-1321         0.308600         0.003129         0.004478   \n",
       "TCGA-30-1892         0.206074         0.133216         0.119614   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-04-1347         0.319288         0.000491         0.033696   \n",
       "TCGA-24-0968         0.237050         0.009708         0.185222   \n",
       "TCGA-30-1891         0.772034         0.000481         0.110194   \n",
       "TCGA-09-0366         0.195435         0.000085         1.631170   \n",
       "TCGA-13-0884         0.784894         0.000393         0.035967   \n",
       "\n",
       "ID            ENSG00000080572  ENSG00000100678  ENSG00000104435  \\\n",
       "TCGA-61-1910         0.000000         0.000000         0.000000   \n",
       "TCGA-24-0982         0.007062         0.000000         0.006438   \n",
       "TCGA-36-1580         0.001970         0.002559         0.041762   \n",
       "TCGA-25-1321         0.162223         0.000788         0.000000   \n",
       "TCGA-30-1892         0.056072         0.000000         0.055381   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-04-1347         0.005704         0.000988         0.011701   \n",
       "TCGA-24-0968         0.000000         0.000000         0.000000   \n",
       "TCGA-30-1891         0.000000         0.000646         0.200678   \n",
       "TCGA-09-0366         0.026487         0.001376         0.006339   \n",
       "TCGA-13-0884         0.012177         0.001055         0.004163   \n",
       "\n",
       "ID            ENSG00000104888  ENSG00000105146  ENSG00000109321  \\\n",
       "TCGA-61-1910         0.043732         2.308592         1.014494   \n",
       "TCGA-24-0982         0.082034         0.242661         0.691196   \n",
       "TCGA-36-1580         0.074384         0.984290         2.329158   \n",
       "TCGA-25-1321         0.101272         0.240456         1.740308   \n",
       "TCGA-30-1892         0.280458         0.592872         0.914734   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-04-1347         0.060742         0.663423         0.094262   \n",
       "TCGA-24-0968         0.307004         0.213121         1.291373   \n",
       "TCGA-30-1891         0.000000         0.098616         2.959271   \n",
       "TCGA-09-0366         0.303848         0.703636         5.424154   \n",
       "TCGA-13-0884         0.023577         0.643764         0.967456   \n",
       "\n",
       "ID            ENSG00000112499  ...  ENSG00000274576  ENSG00000275756  \\\n",
       "TCGA-61-1910         0.000000  ...         0.000000         0.920597   \n",
       "TCGA-24-0982         0.004156  ...        24.797152         0.259035   \n",
       "TCGA-36-1580         0.001391  ...         4.017149         0.289083   \n",
       "TCGA-25-1321         0.004819  ...         2.576079         0.166843   \n",
       "TCGA-30-1892         0.004400  ...         1.058604         0.114269   \n",
       "...                       ...  ...              ...              ...   \n",
       "TCGA-04-1347         0.000671  ...         0.000000         0.000000   \n",
       "TCGA-24-0968         0.003796  ...        15.221570         0.525782   \n",
       "TCGA-30-1891         0.077290  ...        47.331214         0.000000   \n",
       "TCGA-09-0366         0.008418  ...         0.225023         0.534375   \n",
       "TCGA-13-0884         0.005017  ...         2.586317         0.074447   \n",
       "\n",
       "ID            ENSG00000276775  ENSG00000277247  ENSG00000278196  \\\n",
       "TCGA-61-1910         0.000000         1.604301         0.299376   \n",
       "TCGA-24-0982         4.625172         0.188089         4.211878   \n",
       "TCGA-36-1580         0.893372         0.314861         4.817979   \n",
       "TCGA-25-1321         0.000000         0.121147         1.356422   \n",
       "TCGA-30-1892         2.825069         0.000000         3.716018   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-04-1347         0.000000         3.038608         0.567030   \n",
       "TCGA-24-0968         4.332951         2.720169        31.845646   \n",
       "TCGA-30-1891         2.631492         0.000000        65.568652   \n",
       "TCGA-09-0366         0.100086         1.481522         3.712525   \n",
       "TCGA-13-0884         0.000000         0.162171         7.989302   \n",
       "\n",
       "ID            ENSG00000278698  ENSG00000279834  ENSG00000279970  \\\n",
       "TCGA-61-1910         0.000000         0.894232         1.612154   \n",
       "TCGA-24-0982         0.270091         0.034947         0.311310   \n",
       "TCGA-36-1580         0.000000         0.000000         0.707253   \n",
       "TCGA-25-1321         0.521892         0.157563         2.033770   \n",
       "TCGA-30-1892         0.000000         0.000000         0.294278   \n",
       "...                       ...              ...              ...   \n",
       "TCGA-04-1347         0.000000         0.000000         0.071847   \n",
       "TCGA-24-0968         0.205584         0.000000         0.710875   \n",
       "TCGA-30-1891         0.000000         0.000000         0.000000   \n",
       "TCGA-09-0366         0.000000         0.058985         2.477118   \n",
       "TCGA-13-0884         0.000000         0.060262         0.191723   \n",
       "\n",
       "ID            ENSG00000280411  ENSG00000281880  \n",
       "TCGA-61-1910         0.761720         0.000000  \n",
       "TCGA-24-0982         0.357217         0.000000  \n",
       "TCGA-36-1580        15.996040         0.000000  \n",
       "TCGA-25-1321         1.495528         0.000000  \n",
       "TCGA-30-1892         1.890974         0.000000  \n",
       "...                       ...              ...  \n",
       "TCGA-04-1347         4.616723         0.000000  \n",
       "TCGA-24-0968         6.117782         0.000000  \n",
       "TCGA-30-1891        80.395413         0.000000  \n",
       "TCGA-09-0366         0.602935         0.001573  \n",
       "TCGA-13-0884         3.849928         0.000402  \n",
       "\n",
       "[214 rows x 395 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_X_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_y_pd = df2_mod.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCGA-61-1910    0.007666\n",
       "TCGA-24-0982    0.007190\n",
       "TCGA-36-1580    0.027081\n",
       "TCGA-25-1321    0.002315\n",
       "TCGA-30-1892    0.057091\n",
       "                  ...   \n",
       "TCGA-04-1347    0.000000\n",
       "TCGA-24-0968    0.013682\n",
       "TCGA-30-1891    0.034186\n",
       "TCGA-09-0366    0.032361\n",
       "TCGA-13-0884    0.018597\n",
       "Name: ENSG00000048545, Length: 214, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_y_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_X = torch.from_numpy(trn_X_pd.astype(float).values)\n",
    "trn_y = torch.from_numpy(trn_y_pd.astype(float).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = data_utils.TensorDataset(trn_X, trn_y)\n",
    "trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = next(iter(trn_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dictionary batch\n",
    "class Dataset(data_utils.Dataset):\n",
    "   \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        return {'X': self.X[idx], 'y': self.y[idx]}\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = Dataset(trn_X, trn_y)\n",
    "trn_loader = data_utils.DataLoader(trn, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
